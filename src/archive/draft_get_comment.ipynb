{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import traceback\n",
    "import re\n",
    "import undetected_chromedriver as uc\n",
    "import argparse\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Constants\n",
    "# BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "# DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "# os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "def random_sleep(mean=1.0, std=0.3):\n",
    "    \"\"\"Sleep for a random duration with normal distribution.\"\"\"\n",
    "    delay = max(0, random.normalvariate(mean, std))\n",
    "    time.sleep(delay)\n",
    "\n",
    "def print_progress(current, total, prefix='', bar_length=40):\n",
    "    \"\"\"Print a progress bar.\"\"\"\n",
    "    fraction = current / total if total else 1\n",
    "    arrow = int(fraction * bar_length) * '='\n",
    "    spaces = (bar_length - len(arrow)) * ' '\n",
    "    print(f'\\r{prefix}[{arrow}{spaces}] {current}/{total}', end='', flush=True)\n",
    "    if current >= total:\n",
    "        print()  # New line when complete\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Initialize undetected_chromedriver with options.\"\"\"\n",
    "    options = uc.ChromeOptions()\n",
    "    # Uncomment to run headless (may be less reliable with Kaggle)\n",
    "    # options.add_argument('--headless')\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                         \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36\")\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    return uc.Chrome(options=options)\n",
    "\n",
    "def save_json(data, filepath):\n",
    "    \"\"\"Save data to a JSON file.\"\"\"\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"✅ Saved data to {filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap comment meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = setup_driver()\n",
    "url = \"https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch/comments\"\n",
    "# comment_data = scraper.scrape_comments(url)\n",
    "driver.get(url)\n",
    "info = {\n",
    "    \"title\": \"\",\n",
    "    \"fork_count\": 0,\n",
    "    \"comments_count\":0\n",
    "}\n",
    "\n",
    "random_sleep(1, 0.3)\n",
    "\n",
    "try:\n",
    "    # Try to get title\n",
    "    title_elem = driver.find_element(By.XPATH, \"//h1\")\n",
    "    info[\"title\"] = title_elem.text.strip()\n",
    "except NoSuchElementException:\n",
    "    print(\"Could not find notebook title.\")\n",
    "    \n",
    "try:\n",
    "    # Try to get fork count\n",
    "    fork_elem = driver.find_element(By.XPATH, \"//span[contains(@aria-label, 'copies')]\")\n",
    "    fork_text = fork_elem.text\n",
    "    fork_match = re.search(r\"(\\d+)\", fork_text)\n",
    "    info[\"fork_count\"] = int(fork_match.group(1)) if fork_match else 0\n",
    "except NoSuchElementException:\n",
    "    print(\"Could not find fork count.\")\n",
    "    \n",
    "try:\n",
    "    # try to get comments count\n",
    "    comment_elem = driver.find_element(By.XPATH, \"//h2[contains(text(), 'Comments')]\")\n",
    "    comment_text = comment_elem.text\n",
    "    comment_match = re.search(r\"(\\d+)\\s*Comments\", comment_text)\n",
    "    info[\"comments_count\"] = int(comment_match.group(1)) if comment_match else 0\n",
    "except NoSuchElementException:\n",
    "    print(\"Could not find comments count.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Linear model and neural net from scratch',\n",
       " 'fork_count': 4691,\n",
       " 'comments_count': 54}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap comments content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = setup_driver()\n",
    "url = \"https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch/comments\"\n",
    "# comment_data = scraper.scrape_comments(url)\n",
    "driver.get(url)\n",
    "info = {\n",
    "    \"title\": \"\",\n",
    "    \"fork_count\": 0,\n",
    "    \"comments_count\":0\n",
    "}\n",
    "\n",
    "random_sleep(1, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected = []\n",
    "last_count = 0\n",
    "scroll_attempts = 0\n",
    "max_attempts = 3  # Maxim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for comments to load\n",
    "WebDriverWait(driver, 5).until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, \"//div[contains(@data-testid, 'discussions-comment')]\"))\n",
    ")\n",
    "\n",
    "# Random wait to ensure the page has loaded properly\n",
    "random_sleep(1, 0.5)\n",
    "\n",
    "# Get all comments\n",
    "comment_elements = driver.find_elements(By.XPATH, \"//div[contains(@data-testid, 'discussions-comment')]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div data-testid=\"discussions-comment\" class=\"sc-hifXeo fEcaKb\"><div id=\"2442279\" class=\"sc-jSOf hNXJXP\"><div class=\"sc-hdBiUU jQlFUD\"><div class=\"sc-fNaani hYZtOz\"><a href=\"/mendhak\" class=\"sc-ehIYnC jNnqAS sc-fdUNyB freEyA\" aria-label=\"mendhak's profile\"><div data-testid=\"avatar-image\" title=\"mendhak\" class=\"sc-iDAWOb kjKwxb\" style=\"background-image: url(&quot;https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png&quot;);\"></div><svg width=\"48\" height=\"48\" viewBox=\"0 0 48 48\"><circle r=\"22.5\" cx=\"24\" cy=\"24\" fill=\"none\" stroke-width=\"3\" style=\"stroke: rgb(241, 243, 244);\"></circle><path d=\"M 45.39877161664096 17.047117626563683 A 22.5 22.5 0 0 0 24 1.5\" fill=\"none\" stroke-width=\"3\" style=\"stroke: rgb(31, 166, 65);\"></path></svg></a><div class=\"sc-chAcSA iLlRjp\"><div class=\"sc-cdUTjK hVvTQB\"><div class=\"sc-dIOQHv ceKzfG\"><div class=\"sc-Mugbu kinlRl\"><a href=\"/mendhak\" target=\"_blank\" class=\"sc-iJuKTj grUMoV\"><h3 class=\"sc-eOzmre sc-gknnfs iyFMKB bpLtdP\">mendhak</h3></a></div><div class=\"sc-jgHXLt eNUmAe\"><p class=\"sc-gQaihK sc-dzaQaQ iUbclf hINEtN\">Posted <span title=\"Sat Sep 16 2023 14:09:00 GMT-0700 (Mountain Standard Time)\" aria-label=\"2 years ago\">2 years ago</span></p><div><p class=\"sc-gQaihK iUbclf\">  ·  Posted on Version 13 of \n",
      "        13</p></div></div></div></div></div><div class=\"sc-ERqrx evVzjC\"><div class=\"sc-cdUTjK bopueC\"><div class=\"sc-iDUbhT kKtxue\"><span class=\"\"><button mode=\"default\" data-testid=\"upvotebutton__upvote\" aria-label=\"Upvote\" title=\"Upvote\" class=\"sc-izGKmE sc-fFxkDl jeeXfL kpZLDc\"><span class=\"google-symbols notranslate MuiIcon-root MuiIcon-fontSizeMedium sc-FFETS jdzuMt notranslate css-1jgtvd5\" aria-hidden=\"true\">arrow_drop_up</span></button></span><button mode=\"default\" aria-label=\"4 votes\" aria-live=\"polite\" class=\"sc-izGKmE sc-heANvy jeeXfL ijeTUO\">4</button></div><button aria-label=\"More Options for this Comment\" data-testid=\"options-menu-button\" title=\"More Options for this Comment\" class=\"sc-cwJYja kWGtZT google-symbols notranslate\">more_vert</button></div></div><div class=\"sc-gwSMPs fAUzeg\"><div class=\"sc-bLgkCX evQBHI\"><div class=\"sc-ePpfBx hvYpEH\"><p>Despite copying cell for cell, on the independent colums line, I get this error below. Any ideas what could be going wrong? I'm running this in a local Jupyter Notebook. </p>\n",
      "<pre class=\"uc-code-block\"><code>indep_cols = <span class=\"hljs-selector-attr\">[<span class=\"hljs-string\">'Age'</span>, <span class=\"hljs-string\">'SibSp'</span>, <span class=\"hljs-string\">'Parch'</span>, <span class=\"hljs-string\">'LogFare'</span>]</span> + added_cols\n",
      "\n",
      "t_indep = <span class=\"hljs-built_in\">tensor</span>(df<span class=\"hljs-selector-attr\">[indep_cols]</span><span class=\"hljs-selector-class\">.values</span>, dtype=torch.<span class=\"hljs-attribute\">float</span>)\n",
      "t_indep\n",
      "</code><div class=\"uc-code-block-copy-button-wrapper\"><button class=\"uc-code-block-copy-button google-symbols\" aria-label=\"Copy code\">content_copy</button></div></pre>\n",
      "<p>Produces:</p>\n",
      "<pre class=\"uc-code-block\"><code>---------------------------------------------------------------------------\n",
      "<span class=\"hljs-type\">TypeError</span>                                 <span class=\"hljs-type\">Traceback</span> (most recent call last)\n",
      "<span class=\"hljs-type\">Cell</span> <span class=\"hljs-type\">In</span>[<span class=\"hljs-number\">18</span>], line <span class=\"hljs-number\">3</span>\n",
      "      <span class=\"hljs-number\">1</span> indep_cols = ['<span class=\"hljs-type\">Age</span>', '<span class=\"hljs-type\">SibSp</span>', '<span class=\"hljs-type\">Parch</span>', '<span class=\"hljs-type\">LogFare</span>'] + added_cols\n",
      "----&gt; <span class=\"hljs-number\">3</span> t_indep = tensor(df[indep_cols].values, dtype=torch.<span class=\"hljs-type\">float</span>)\n",
      "      <span class=\"hljs-number\">4</span> t_indep\n",
      "\n",
      "<span class=\"hljs-type\">TypeError</span>: can't convert np.ndarray <span class=\"hljs-keyword\">of</span> <span class=\"hljs-keyword\">type</span> numpy.object_. <span class=\"hljs-type\">The</span> only supported types are: <span class=\"hljs-type\">float64</span>, <span class=\"hljs-type\">float32</span>, float16, complex64, complex128, <span class=\"hljs-type\">int64</span>, <span class=\"hljs-type\">int32</span>, <span class=\"hljs-type\">int16</span>, <span class=\"hljs-type\">int8</span>, <span class=\"hljs-type\">uint8</span>, <span class=\"hljs-keyword\">and</span> <span class=\"hljs-type\">bool</span>.\n",
      "</code><div class=\"uc-code-block-copy-button-wrapper\"><button class=\"uc-code-block-copy-button google-symbols\" aria-label=\"Copy code\">content_copy</button></div></pre></div></div></div><div class=\"sc-fbMPYm kCPkxW\"><button tabindex=\"0\" role=\"button\" class=\"sc-edmcci hdHxFO\"><span class=\"google-symbols notranslate MuiIcon-root MuiIcon-fontSizeMedium sc-FFETS jdzuMt notranslate css-1jgtvd5\" aria-hidden=\"true\">reply</span><span class=\"sc-hJRrWL iwZBhE\">Reply</span></button></div><div class=\"sc-duUizX kPbnnr\"><div class=\"sc-lePUEl fZtMFt\"><div data-testid=\"discussions-comment\" class=\"sc-hifXeo fEcaKb\"><div id=\"2454088\" class=\"sc-jSOf VxSOT\"><div class=\"sc-hdBiUU kWQdbY\"><div class=\"sc-fNaani hYZtOz\"><a href=\"/iustingrigoras\" class=\"sc-ehIYnC jNnqAS sc-fdUNyB freEyA\" aria-label=\"Iustin Grigoras's profile\"><div data-testid=\"avatar-image\" title=\"Iustin Grigoras\" class=\"sc-iDAWOb kjKwxb\" style=\"background-image: url(&quot;https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png&quot;);\"></div><svg width=\"48\" height=\"48\" viewBox=\"0 0 48 48\"><circle r=\"22.5\" cx=\"24\" cy=\"24\" fill=\"none\" stroke-width=\"3\" style=\"stroke: rgb(241, 243, 244);\"></circle><path d=\"M 37.225168176580645 42.20288237343632 A 22.5 22.5 0 0 0 24 1.5\" fill=\"none\" stroke-width=\"3\" style=\"stroke: rgb(32, 190, 255);\"></path></svg></a><div class=\"sc-chAcSA iLlRjp\"><div class=\"sc-cdUTjK hVvTQB\"><div class=\"sc-dIOQHv cSnqwH\"><div class=\"sc-Mugbu jJvDwz\"><a href=\"/iustingrigoras\" target=\"_blank\" class=\"sc-iJuKTj grUMoV\"><h3 class=\"sc-eOzmre sc-gknnfs iyFMKB OKjXZ\">Iustin Grigoras</h3></a></div><div class=\"sc-jgHXLt llqacb\"><p class=\"sc-gQaihK sc-dzaQaQ iUbclf hINEtN\">Posted <span title=\"Sun Sep 24 2023 08:15:20 GMT-0700 (Mountain Standard Time)\" aria-label=\"2 years ago\">2 years ago</span></p><div><p class=\"sc-gQaihK iUbclf\">  ·  Posted on Version 13 of \n",
      "        13</p></div></div></div></div></div><div class=\"sc-ERqrx evVzjC\"><div class=\"sc-cdUTjK bopueC\"><img src=\"/static/images/medals/discussion/bronzel@1x.png\" size=\"18\" alt=\"This post earned a bronze medal\" class=\"sc-llULqv jbCptv\"><div class=\"sc-iDUbhT kKtxue\"><span class=\"\"><button mode=\"default\" data-testid=\"upvotebutton__upvote\" aria-label=\"Upvote\" title=\"Upvote\" class=\"sc-izGKmE sc-fFxkDl jeeXfL kpZLDc\"><span class=\"google-symbols notranslate MuiIcon-root MuiIcon-fontSizeMedium sc-FFETS jdzuMt notranslate css-1jgtvd5\" aria-hidden=\"true\">arrow_drop_up</span></button></span><button mode=\"default\" aria-label=\"6 votes\" aria-live=\"polite\" class=\"sc-izGKmE sc-heANvy jeeXfL ijeTUO\">6</button></div><button aria-label=\"More Options for this Comment\" data-testid=\"options-menu-button\" title=\"More Options for this Comment\" class=\"sc-cwJYja kWGtZT google-symbols notranslate\">more_vert</button></div></div><div class=\"sc-gwSMPs fAUzeg\"><div class=\"sc-bLgkCX evQBHI\"><div class=\"sc-ePpfBx hvYpEH\"><p>In the <code>t_indep = tensor(df[indep_cols].values, dtype=torch.float)</code> line I added the <code>astype(float)</code> method to <code>df[indep_cols].values</code> to convert it from np.object to supported data type.</p></div></div></div><div class=\"sc-fbMPYm kCPkxW\"><button tabindex=\"0\" role=\"button\" class=\"sc-edmcci hdHxFO\"><span class=\"google-symbols notranslate MuiIcon-root MuiIcon-fontSizeMedium sc-FFETS jdzuMt notranslate css-1jgtvd5\" aria-hidden=\"true\">reply</span><span class=\"sc-hJRrWL iwZBhE\">Reply</span></button><div class=\"sc-dmAfel bisZiK\"><span class=\"\"><div class=\"sc-hZhVly grbFyW sc-kgdQcI jhdymP\" role=\"presentation\" aria-label=\"\"><span class=\"google-symbols notranslate MuiIcon-root MuiIcon-fontSizeMedium sc-FFETS jdzuMt notranslate sc-ihuPqZ lgenhn css-1jgtvd5\" aria-hidden=\"true\"><img src=\"/static/images/community/reactions/thank_you.svg\" alt=\"thankYou\" class=\"sc-hmSsaj fleChJ\"></span><span class=\"sc-eUlrpB sc-gfdIJj dpOfYN hjvTgj\">3</span></div></span></div></div></div></div></div></div></div><div class=\"sc-lePUEl fZtMFt\"><div data-testid=\"discussions-comment\" class=\"sc-hifXeo fEcaKb\"><div id=\"2565228\" class=\"sc-jSOf VxSOT\"><div class=\"sc-hdBiUU kWQdbY\"><div class=\"sc-fNaani hYZtOz\"><a href=\"/username2000\" class=\"sc-ehIYnC jNnqAS sc-fdUNyB freEyA\" aria-label=\"Steve Armstrong's profile\"><div data-testid=\"avatar-image\" title=\"Steve Armstrong\" class=\"sc-iDAWOb kjKwxb\" style=\"background-image: url(&quot;https://storage.googleapis.com/kaggle-avatars/thumbnails/default-thumb.png&quot;);\"></div><svg width=\"48\" height=\"48\" viewBox=\"0 0 48 48\"><circle r=\"22.5\" cx=\"24\" cy=\"24\" fill=\"none\" stroke-width=\"3\" style=\"stroke: rgb(241, 243, 244);\"></circle><path d=\"M 37.225168176580645 42.20288237343632 A 22.5 22.5 0 0 0 24 1.5\" fill=\"none\" stroke-width=\"3\" style=\"stroke: rgb(32, 190, 255);\"></path></svg></a><div class=\"sc-chAcSA iLlRjp\"><div class=\"sc-cdUTjK hVvTQB\"><div class=\"sc-dIOQHv cSnqwH\"><div class=\"sc-Mugbu jJvDwz\"><a href=\"/username2000\" target=\"_blank\" class=\"sc-iJuKTj grUMoV\"><h3 class=\"sc-eOzmre sc-gknnfs iyFMKB OKjXZ\">Steve Armstrong</h3></a></div><div class=\"sc-jgHXLt llqacb\"><p class=\"sc-gQaihK sc-dzaQaQ iUbclf hINEtN\">Posted <span title=\"Sun Dec 17 2023 12:32:54 GMT-0700 (Mountain Standard Time)\" aria-label=\"a year ago\">a year ago</span></p><div><p class=\"sc-gQaihK iUbclf\">  ·  Posted on Version 13 of \n",
      "        13</p></div></div></div></div></div><div class=\"sc-ERqrx evVzjC\"><div class=\"sc-cdUTjK bopueC\"><div class=\"sc-iDUbhT kKtxue\"><span class=\"\"><button mode=\"default\" data-testid=\"upvotebutton__upvote\" aria-label=\"Upvote\" title=\"Upvote\" class=\"sc-izGKmE sc-fFxkDl jeeXfL kpZLDc\"><span class=\"google-symbols notranslate MuiIcon-root MuiIcon-fontSizeMedium sc-FFETS jdzuMt notranslate css-1jgtvd5\" aria-hidden=\"true\">arrow_drop_up</span></button></span><button mode=\"default\" aria-label=\"3 votes\" aria-live=\"polite\" class=\"sc-izGKmE sc-heANvy jeeXfL ijeTUO\">3</button></div><button aria-label=\"More Options for this Comment\" data-testid=\"options-menu-button\" title=\"More Options for this Comment\" class=\"sc-cwJYja kWGtZT google-symbols notranslate\">more_vert</button></div></div><div class=\"sc-gwSMPs fAUzeg\"><div class=\"sc-bLgkCX evQBHI\"><div class=\"sc-ePpfBx hvYpEH\"><p>An alternative is to use the .to_numpy() method as recommended in the documentation:</p>\n",
      "<p><a rel=\"noreferrer nofollow\" aria-label=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.values.html (opens in a new tab)\" target=\"_blank\" href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.values.html\">https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.values.html</a></p>\n",
      "<p><code>t_indep = tensor(df[indep_cols].to_numpy(dtype=np.float32), dtype=torch.float)</code></p></div></div></div><div class=\"sc-fbMPYm kCPkxW\"><button tabindex=\"0\" role=\"button\" class=\"sc-edmcci hdHxFO\"><span class=\"google-symbols notranslate MuiIcon-root MuiIcon-fontSizeMedium sc-FFETS jdzuMt notranslate css-1jgtvd5\" aria-hidden=\"true\">reply</span><span class=\"sc-hJRrWL iwZBhE\">Reply</span></button><div class=\"sc-dmAfel bisZiK\"><span class=\"\"><div class=\"sc-hZhVly grbFyW sc-kgdQcI jhdymP\" role=\"presentation\" aria-label=\"\"><span class=\"google-symbols notranslate MuiIcon-root MuiIcon-fontSizeMedium sc-FFETS jdzuMt notranslate sc-ihuPqZ lgenhn css-1jgtvd5\" aria-hidden=\"true\"><img src=\"/static/images/community/reactions/thank_you.svg\" alt=\"thankYou\" class=\"sc-hmSsaj fleChJ\"></span><span class=\"sc-eUlrpB sc-gfdIJj dpOfYN hjvTgj\">4</span></div></span></div></div></div></div></div></div></div></div></div></div></div></div>\n"
     ]
    }
   ],
   "source": [
    "def _extract_comment_data(self, comment_element):\n",
    "    \"\"\"Extract data from a single comment element.\"\"\"\n",
    "    comment_data = {\n",
    "    \"content\": \"\",\n",
    "    \"user\": \"\",\n",
    "    \"user_url\": \"\",\n",
    "    \"date\": \"\",\n",
    "    \"votes\": 0\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Get user info using aria-label containing 'profile'\n",
    "        user_elem = comment_element.find_element(By.XPATH, \".//a[contains(@aria-label, \\\"'s profile\\\")]\")\n",
    "        comment_data[\"user\"] = user_elem.get_attribute(\"aria-label\").replace(\"'s profile\", \"\").strip()\n",
    "        comment_data[\"user_url\"] = user_elem.get_attribute(\"href\")\n",
    "    except NoSuchElementException:\n",
    "        comment_data[\"user\"] = \"Anonymous or Deleted User\"\n",
    "\n",
    "    try:\n",
    "        # Get date from element that contains \"Posted\" and a <span> with title\n",
    "        date_elem = comment_element.find_element(By.XPATH, \".//p[contains(text(), 'Posted')]/span[@title]\")\n",
    "        comment_data[\"date\"] = date_elem.get_attribute(\"title\")\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        # Get votes from button with aria-label containing 'votes'\n",
    "        vote_elem = comment_element.find_element(By.XPATH, \".//button[contains(@aria-label, 'votes')]\")\n",
    "        vote_text = vote_elem.get_attribute(\"aria-label\")\n",
    "        vote_match = re.search(r\"(\\d+)\\s*votes?\", vote_text)\n",
    "        comment_data[\"votes\"] = int(vote_match.group(1)) if vote_match else 0\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        # Find the reply button\n",
    "        reply_elem = comment_element.find_element(By.XPATH, \".//span[text()='reply']\")\n",
    "        all_children = comment_element.find_elements(By.XPATH, \".//*\")\n",
    "\n",
    "        content_parts = []\n",
    "        for elem in all_children:\n",
    "            if elem == reply_elem:\n",
    "                break  # Stop once we reach the reply button\n",
    "            tag_name = elem.tag_name.lower()\n",
    "            class_attr = elem.get_attribute(\"class\") or \"\"\n",
    "\n",
    "            if tag_name == \"p\" or \"uc-code-block\" in class_attr:\n",
    "                text = elem.text.strip()\n",
    "                if text:\n",
    "                    content_parts.append(text)\n",
    "\n",
    "        comment_data[\"content\"] = \"\\n\".join(content_parts)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    return comment_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_element = comment_elements[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_data = {\n",
    "    \"content\": \"\",\n",
    "    \"user\": \"\",\n",
    "    \"user_url\": \"\",\n",
    "    \"date\": \"\",\n",
    "    \"votes\": 0\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Get user info using aria-label containing 'profile'\n",
    "    user_elem = comment_element.find_element(By.XPATH, \".//a[contains(@aria-label, \\\"'s profile\\\")]\")\n",
    "    comment_data[\"user\"] = user_elem.get_attribute(\"aria-label\").replace(\"'s profile\", \"\").strip()\n",
    "    comment_data[\"user_url\"] = user_elem.get_attribute(\"href\")\n",
    "except NoSuchElementException:\n",
    "    comment_data[\"user\"] = \"Anonymous or Deleted User\"\n",
    "\n",
    "try:\n",
    "    # Get date from element that contains \"Posted\" and a <span> with title\n",
    "    date_elem = comment_element.find_element(By.XPATH, \".//p[contains(text(), 'Posted')]/span[@title]\")\n",
    "    comment_data[\"date\"] = date_elem.get_attribute(\"title\")\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Get votes from button with aria-label containing 'votes'\n",
    "    vote_elem = comment_element.find_element(By.XPATH, \".//button[contains(@aria-label, 'votes')]\")\n",
    "    vote_text = vote_elem.get_attribute(\"aria-label\")\n",
    "    vote_match = re.search(r\"(\\d+)\\s*votes?\", vote_text)\n",
    "    comment_data[\"votes\"] = int(vote_match.group(1)) if vote_match else 0\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    # Find the reply button\n",
    "    reply_elem = comment_element.find_element(By.XPATH, \".//span[text()='reply']\")\n",
    "    all_children = comment_element.find_elements(By.XPATH, \".//*\")\n",
    "\n",
    "    content_parts = []\n",
    "    for elem in all_children:\n",
    "        if elem == reply_elem:\n",
    "            break  # Stop once we reach the reply button\n",
    "        tag_name = elem.tag_name.lower()\n",
    "        class_attr = elem.get_attribute(\"class\") or \"\"\n",
    "\n",
    "        if tag_name == \"p\" or \"uc-code-block\" in class_attr:\n",
    "            text = elem.text.strip()\n",
    "            if text:\n",
    "                content_parts.append(text)\n",
    "\n",
    "    comment_data[\"content\"] = \"\\n\".join(content_parts)\n",
    "except NoSuchElementException:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"Posted 2 years ago\\n· Posted on Version 13 of 13\\nDespite copying cell for cell, on the independent colums line, I get this error below. Any ideas what could be going wrong? I'm running this in a local Jupyter Notebook.\\nindep_cols = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols\\n\\nt_indep = tensor(df[indep_cols].values, dtype=torch.float)\\nt_indep\\nProduces:\\n---------------------------------------------------------------------------\\nTypeError                                 Traceback (most recent call last)\\nCell In[18], line 3\\n      1 indep_cols = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols\\n----> 3 t_indep = tensor(df[indep_cols].values, dtype=torch.float)\\n      4 t_indep\\n\\nTypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.\",\n",
       " 'user': 'mendhak',\n",
       " 'user_url': 'https://www.kaggle.com/mendhak',\n",
       " 'date': 'Sat Sep 16 2023 14:09:00 GMT-0700 (Mountain Standard Time)',\n",
       " 'votes': 4}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while True:\n",
    "    # Wait for comments to load\n",
    "    WebDriverWait(driver, 5).until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, \"//div[contains(@data-testid, 'discussions-comment')]\"))\n",
    "    )\n",
    "    \n",
    "    # Random wait to ensure the page has loaded properly\n",
    "    random_sleep(1, 0.5)\n",
    "    \n",
    "    # Get all comments\n",
    "    comment_elements = driver.find_elements(By.XPATH, \"//div[contains(@data-testid, 'discussions-comment')]\")\n",
    "    \n",
    "    # Process new comments\n",
    "    for i in range(last_count, len(comment_elements)):\n",
    "        try:\n",
    "            comment_data = _extract_comment_data(comment_elements[i])\n",
    "            collected.append(comment_data)\n",
    "            print_progress(len(collected), expected_total, prefix='Comments collected: ')\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError extracting comment: {str(e)}\")\n",
    "    \n",
    "    # Check if we've reached our expected total\n",
    "    if len(collected) >= expected_total:\n",
    "        print(f\"\\nReached expected comment count. Total collected: {len(collected)}\")\n",
    "        break\n",
    "        \n",
    "    # Check if we found new comments during this iteration\n",
    "    if len(comment_elements) > last_count:\n",
    "        last_count = len(comment_elements)\n",
    "        scroll_attempts = 0  # Reset scroll attempts counter\n",
    "        \n",
    "        # Scroll to the last comment to load more\n",
    "        if comment_elements:\n",
    "            self.driver.execute_script(\n",
    "                \"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\",\n",
    "                comment_elements[-1]\n",
    "            )\n",
    "            \n",
    "        # Also scroll a bit more to trigger loading\n",
    "        driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "        random_sleep(2, 0.5)\n",
    "    else:\n",
    "        # If no new comments were found in this iteration\n",
    "        scroll_attempts += 1\n",
    "        if scroll_attempts >= max_attempts:\n",
    "            print(f\"\\nNo more comments found after {max_attempts} scroll attempts.\")\n",
    "            print(f\"Expected: {expected_total}, Collected: {len(collected)}\")\n",
    "            break\n",
    "            \n",
    "        print(f\"\\nNo new comments found. Scrolling more... (attempt {scroll_attempts}/{max_attempts})\")\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        random_sleep(3, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KaggleCommentsScraper:\n",
    "    def __init__(self, driver):\n",
    "        self.driver = driver\n",
    "        \n",
    "    def scrape_comments(self, url):\n",
    "        \"\"\"Scrape all comments from a Kaggle notebook comments page.\"\"\"\n",
    "        print(f\"Scraping comments from: {url}\")\n",
    "        self.driver.get(url)\n",
    "        \n",
    "        # Wait for page load\n",
    "        WebDriverWait(self.driver, 15).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "        )\n",
    "        random_sleep(1, 0.3)\n",
    "        # Get notebook metadata (title, author, forks)\n",
    "        notebook_info = self._extract_notebook_info()\n",
    "        \n",
    "        # Check if there are comments\n",
    "        if notebook_info[\"comments_count\"] == 0:\n",
    "            print(\"No comments found on this page.\")\n",
    "            return {\n",
    "                \"notebook_url\": url,\n",
    "                \"notebook_info\": notebook_info,\n",
    "                \"comments\": []}\n",
    "\n",
    "        # Scroll to load all comments\n",
    "        comments_collected = self._collect_all_comments(notebook_info[\"comments_count\"])\n",
    "        \n",
    "        result = {\n",
    "            \"notebook_info\": notebook_info,\n",
    "            \"comments\": comments_collected\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _extract_notebook_info(self):\n",
    "        \"\"\"Extract metadata about the notebook itself.\"\"\"\n",
    "        self.driver.get(url)\n",
    "        info = {\n",
    "            \"title\": \"\",\n",
    "            \"fork_count\": 0,\n",
    "            \"comments_count\":0\n",
    "        }\n",
    "\n",
    "        random_sleep(1, 0.3)\n",
    "\n",
    "        try:\n",
    "            # Try to get title\n",
    "            title_elem = self.driver.find_element(By.XPATH, \"//h1\")\n",
    "            info[\"title\"] = title_elem.text.strip()\n",
    "        except NoSuchElementException:\n",
    "            print(\"Could not find notebook title.\")\n",
    "            \n",
    "        try:\n",
    "            # Try to get fork count\n",
    "            fork_elem = self.driver.find_element(By.XPATH, \"//span[contains(@aria-label, 'copies')]\")\n",
    "            fork_text = fork_elem.text\n",
    "            fork_match = re.search(r\"(\\d+)\", fork_text)\n",
    "            info[\"fork_count\"] = int(fork_match.group(1)) if fork_match else 0\n",
    "        except NoSuchElementException:\n",
    "            print(\"Could not find fork count.\")\n",
    "            \n",
    "        try:\n",
    "            # try to get comments count\n",
    "            comment_elem = self.driver.find_element(By.XPATH, \"//h2[contains(text(), 'Comments')]\")\n",
    "            comment_text = comment_elem.text\n",
    "            comment_match = re.search(r\"(\\d+)\\s*Comments\", comment_text)\n",
    "            info[\"comments_count\"] = int(comment_match.group(1)) if comment_match else 0\n",
    "        except NoSuchElementException:\n",
    "            print(\"Could not find comments count.\")\n",
    "            \n",
    "        return info\n",
    "    \n",
    "    def _collect_all_comments(self, expected_total):\n",
    "        \"\"\"Scroll and collect all comments.\"\"\"\n",
    "        collected = []\n",
    "        last_count = 0\n",
    "        scroll_attempts = 0\n",
    "        max_attempts = 3  # Maximum number of attempts if no new comments are found\n",
    "        \n",
    "        while True:\n",
    "            # Wait for comments to load\n",
    "            WebDriverWait(self.driver, 5).until(\n",
    "                EC.presence_of_all_elements_located((By.XPATH, \"//div[contains(@data-testid, 'discussions-comment')]\"))\n",
    "            )\n",
    "            \n",
    "            # Random wait to ensure the page has loaded properly\n",
    "            random_sleep(1, 0.5)\n",
    "            \n",
    "            # Get all comments\n",
    "            comment_elements = self.driver.find_elements(By.XPATH, \"//div[contains(@data-testid, 'discussions-comment')]\")\n",
    "            \n",
    "            # Process new comments\n",
    "            for i in range(last_count, len(comment_elements)):\n",
    "                try:\n",
    "                    comment_data = self._extract_comment_data(comment_elements[i])\n",
    "                    collected.append(comment_data)\n",
    "                    print_progress(len(collected), expected_total, prefix='Comments collected: ')\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError extracting comment: {str(e)}\")\n",
    "            \n",
    "            # Check if we've reached our expected total\n",
    "            if len(collected) >= expected_total:\n",
    "                print(f\"\\nReached expected comment count. Total collected: {len(collected)}\")\n",
    "                break\n",
    "                \n",
    "            # Check if we found new comments during this iteration\n",
    "            if len(comment_elements) > last_count:\n",
    "                last_count = len(comment_elements)\n",
    "                scroll_attempts = 0  # Reset scroll attempts counter\n",
    "                \n",
    "                # Scroll to the last comment to load more\n",
    "                if comment_elements:\n",
    "                    self.driver.execute_script(\n",
    "                        \"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\",\n",
    "                        comment_elements[-1]\n",
    "                    )\n",
    "                    \n",
    "                # Also scroll a bit more to trigger loading\n",
    "                self.driver.execute_script(\"window.scrollBy(0, 500);\")\n",
    "                random_sleep(2, 0.5)\n",
    "            else:\n",
    "                # If no new comments were found in this iteration\n",
    "                scroll_attempts += 1\n",
    "                if scroll_attempts >= max_attempts:\n",
    "                    print(f\"\\nNo more comments found after {max_attempts} scroll attempts.\")\n",
    "                    print(f\"Expected: {expected_total}, Collected: {len(collected)}\")\n",
    "                    break\n",
    "                    \n",
    "                print(f\"\\nNo new comments found. Scrolling more... (attempt {scroll_attempts}/{max_attempts})\")\n",
    "                self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                random_sleep(3, 0.5)\n",
    "        \n",
    "        return collected\n",
    "    \n",
    "    def _extract_comment_data(self, comment_element):\n",
    "        \"\"\"Extract data from a single comment element.\"\"\"\n",
    "        comment_data = {\n",
    "            \"content\": \"\",\n",
    "            \"user\": \"\",\n",
    "            \"user_url\": \"\",\n",
    "            \"date\": \"\",\n",
    "            \"votes\": 0\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Get user info\n",
    "            user_elem = comment_element.find_element(By.XPATH, \".//a[contains(@href, '/profile/')]\")\n",
    "            comment_data[\"user\"] = user_elem.text.strip()\n",
    "            comment_data[\"user_url\"] = user_elem.get_attribute(\"href\")\n",
    "        except NoSuchElementException:\n",
    "            comment_data[\"user\"] = \"Anonymous or Deleted User\"\n",
    "        \n",
    "        try:\n",
    "            # Get date\n",
    "            date_elem = comment_element.find_element(By.XPATH, \".//span[contains(@title, '-') or contains(@title, '/')]\")\n",
    "            comment_data[\"date\"] = date_elem.get_attribute(\"title\")\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            # Get votes\n",
    "            vote_elem = comment_element.find_element(By.XPATH, \".//button[contains(@aria-label, 'votes')]\")\n",
    "            vote_text = vote_elem.get_attribute(\"aria-label\")\n",
    "            vote_match = re.search(r\"(\\d+)\\s*votes?\", vote_text)\n",
    "            comment_data[\"votes\"] = int(vote_match.group(1)) if vote_match else 0\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            # Get comment content\n",
    "            content_elem = comment_element.find_element(By.XPATH, \".//div[contains(@class, 'comment-content')]\")\n",
    "            comment_data[\"content\"] = content_elem.text.strip()\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "            \n",
    "        return comment_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogenstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
