{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48df7f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current notebook's directory\n",
    "notebook_dir = os.path.dirname(os.path.abspath('.'))\n",
    "\n",
    "# Add to Python path\n",
    "if notebook_dir not in sys.path:\n",
    "    sys.path.append(notebook_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c93c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_management.data_manager import DataManager\n",
    "import json\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b10542",
   "metadata": {},
   "source": [
    "# Create Compeition Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7954ffe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported competition: titanic\n",
      "\n",
      "Summary: Successfully imported 1 of 1 competitions\n"
     ]
    }
   ],
   "source": [
    "def import_competitions_from_json(file_path: str):\n",
    "    \"\"\"Import competitions from JSON file using the new class structure\"\"\"\n",
    "    \n",
    "    # Initialize data manager\n",
    "    with DataManager() as dm:\n",
    "        # Load competitions data\n",
    "        with open(file_path, 'r') as file:\n",
    "            competitions_data = json.load(file)\n",
    "\n",
    "        success_count = 0\n",
    "        for competition_id, competition_info in competitions_data.items():\n",
    "            # Prepare competition record\n",
    "            competition_record = {\n",
    "                'competition_id': competition_id,\n",
    "                'title': competition_info.get('Title', competition_id.title()),\n",
    "                'description': competition_info.get('Description', ''),\n",
    "                'evaluation': competition_info.get('Evaluation', ''),\n",
    "                'competition_host': competition_info.get('Competition Host', []),\n",
    "                'price_award': competition_info.get('Prizes & Awards', []),\n",
    "                'entrants': competition_info.get('Entrants', 0),\n",
    "                'participants': competition_info.get('Participants', 0),\n",
    "                'teams': competition_info.get('Teams', 0),\n",
    "                'submissions': competition_info.get('Submissions', 0),\n",
    "                'tags': competition_info.get('Tags', []),\n",
    "                'competition_url': competition_info.get('competition_url', ''),\n",
    "                'last_updated': datetime.datetime.now()  # Automatically set\n",
    "            }\n",
    "            \n",
    "            # Add data description if available\n",
    "            if 'data' in competition_info:\n",
    "                data_info = competition_info['data']\n",
    "                competition_record.update({\n",
    "                    'data_description': data_info.get('Description', ''),\n",
    "                    'data_files_num': data_info.get('Files', ''),\n",
    "                    'data_size': data_info.get('Size', ''),\n",
    "                    'data_type': data_info.get('Type', '')\n",
    "                })\n",
    "            \n",
    "            # Use the CompetitionManager to create/update\n",
    "            try:\n",
    "                result = dm.competitions.create_or_update(competition_record)\n",
    "                if result:\n",
    "                    success_count += 1\n",
    "                    print(f\"Successfully imported competition: {competition_id}\")\n",
    "                else:\n",
    "                    print(f\"Failed to import competition: {competition_id}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error importing competition {competition_id}: {str(e)}\")\n",
    "\n",
    "        print(f\"\\nSummary: Successfully imported {success_count} of {len(competitions_data)} competitions\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    import_competitions_from_json(\n",
    "        '/Users/zhongming/Local Docs/Github/Kaggle_RAG_dataset/data/competitions_metadata.json'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa92524",
   "metadata": {},
   "source": [
    "# Create dataset collection for train and test set of competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eef0b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing competition: titanic\n",
      "Found 3 CSV files\n",
      "Importing test.csv as test dataset...\n",
      "Successfully imported test.csv\n",
      "Importing train.csv as train dataset...\n",
      "Successfully imported train.csv\n",
      "Importing gender_submission.csv as sample_submission dataset...\n",
      "Successfully imported gender_submission.csv\n",
      "Imported 3 of 3 datasets for competition titanic\n",
      "\n",
      "Final Summary:\n",
      "Total datasets found: 3\n",
      "Total datasets imported: 3\n",
      "Success rate: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def import_datasets_from_directory(base_dir: str):\n",
    "    \"\"\"\n",
    "    Import datasets from CSV files in competition directories using the new class structure\n",
    "    \n",
    "    Args:\n",
    "        base_dir: Base directory containing competition folders with CSV files\n",
    "    \"\"\"\n",
    "    # Initialize data manager\n",
    "    with DataManager() as dm:\n",
    "        # Get all competition directories\n",
    "        competition_dirs = [d for d in os.listdir(base_dir) \n",
    "                          if os.path.isdir(os.path.join(base_dir, d))]\n",
    "\n",
    "        total_datasets = 0\n",
    "        total_imported = 0\n",
    "\n",
    "        # Process each competition directory\n",
    "        for competition_id in competition_dirs:\n",
    "            competition_dir = os.path.join(base_dir, competition_id)\n",
    "            \n",
    "            # Check if competition exists using CompetitionManager\n",
    "            if not dm.competitions.exists(competition_id):\n",
    "                print(f\"Competition {competition_id} does not exist in the database, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Find all CSV files in the competition directory\n",
    "            csv_pattern = os.path.join(competition_dir, \"*.csv\")\n",
    "            csv_files = glob.glob(csv_pattern)\n",
    "            \n",
    "            if not csv_files:\n",
    "                print(f\"No CSV files found for competition {competition_id}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\nProcessing competition: {competition_id}\")\n",
    "            print(f\"Found {len(csv_files)} CSV files\")\n",
    "            \n",
    "            # Import each CSV file\n",
    "            imported_count = 0\n",
    "            for csv_file in csv_files:\n",
    "                file_name = os.path.basename(csv_file)\n",
    "                base_name = os.path.splitext(file_name)[0]\n",
    "                \n",
    "                # Determine dataset type based on filename\n",
    "                dataset_type = 'unknown'\n",
    "                if 'train' in base_name.lower():\n",
    "                    dataset_type = 'train'\n",
    "                elif 'test' in base_name.lower():\n",
    "                    dataset_type = 'test'\n",
    "                elif 'submission' in base_name.lower() or 'submission' in base_name.lower():\n",
    "                    dataset_type = 'sample_submission'\n",
    "                \n",
    "                print(f\"Importing {file_name} as {dataset_type} dataset...\")\n",
    "                \n",
    "                # Use DatasetManager to import\n",
    "                try:\n",
    "                    if dm.datasets.import_csv(csv_file, competition_id, dataset_type):\n",
    "                        imported_count += 1\n",
    "                        print(f\"Successfully imported {file_name}\")\n",
    "                    else:\n",
    "                        print(f\"Failed to import {file_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error importing {file_name}: {str(e)}\")\n",
    "            \n",
    "            print(f\"Imported {imported_count} of {len(csv_files)} datasets for competition {competition_id}\")\n",
    "            \n",
    "            total_datasets += len(csv_files)\n",
    "            total_imported += imported_count\n",
    "\n",
    "        print(f\"\\nFinal Summary:\")\n",
    "        print(f\"Total datasets found: {total_datasets}\")\n",
    "        print(f\"Total datasets imported: {total_imported}\")\n",
    "        print(f\"Success rate: {(total_imported/total_datasets)*100:.2f}%\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    base_directory = '/Users/zhongming/Local Docs/Github/Kaggle_RAG_dataset/data/dataset'\n",
    "    import_datasets_from_directory(base_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ac4d75",
   "metadata": {},
   "source": [
    "# Create notebook collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06665262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Processed vladimirsydor_add-leak\n",
      "✓ Processed yunishi0716_best-weight-searching3\n",
      "✓ Processed aleksthegreat_public-blend\n",
      "✓ Processed yamsam_ashrae-leak-validation-and-more\n",
      "✓ Processed wuliaokaola_ashrae-maybe-this-can-make-public-lb-some-useful\n",
      "✓ Processed vladimirsydor_bland-lgbm-on-leaks\n",
      "✓ Processed vladimirsydor_bland-by-leak\n",
      "✓ Processed rohanrao_ashrae-divide-and-conquer\n",
      "✓ Processed teeyee314_best-single-half-half-lgbm-1-07\n",
      "✓ Processed vladimirsydor_bland-lgbm-folds\n",
      "✓ Processed mimoudata_ashrae-2-lightgbm-without-leak-data\n",
      "✓ Processed aitude_ashrae-kfold-lightgbm-without-leak-1-08\n",
      "✓ Processed purist1024_ashrae-simple-data-cleanup-lb-1-08-no-leaks\n",
      "✓ Processed ragnar123_another-1-08-lb-no-leak\n",
      "✓ Processed mimoudata_ashrae-lightgbm-without-leak\n",
      "✓ Processed yunishi0716_k-folds-model\n",
      "✓ Processed hmendonca_4-ashrae-blended\n",
      "✓ Processed grapestone5321_ashrae-stacking-method\n",
      "✓ Processed mimoudata_ashrae-lightgbm-without-leak-data\n",
      "✓ Processed iwatatakuya_ashrae-kfold-lightgbm-without-building-id\n",
      "✓ Processed remisharoon_ashrae-gep-iii-rms-nb\n",
      "⚠️ File not found: kailex_ac-dc.ipynb\n",
      "✓ Processed rohanrao_ashrae-half-and-half\n",
      "✓ Processed litemort_implicit-merge-operation-by-litemort\n",
      "✓ Processed kulkarnivishwanath_ashrae-great-energy-predictor-iii-eda-model\n",
      "✓ Processed starl1ght_ashrae-stacked-regression-lasso-ridge-lgbm\n",
      "✓ Processed hiteshsom_ashrae-3-lightgbm\n",
      "✓ Processed nz0722_aligned-timestamp-lgbm-by-meter-type\n",
      "✓ Processed yunishi0716_3-folds-by-each-meter-type\n",
      "✓ Processed kaushal2896_ashrae-eda-fe-lightgbm-1-12\n",
      "✓ Processed viswajithkn_great-energy-prediction\n",
      "⚠️ File not found: wittmannf_keras-embedding-read-k-folds.ipynb\n",
      "✓ Processed corochann_ashrae-training-lgbm-by-meter-type\n",
      "✓ Processed amaity0_ashrae-fifth-try\n",
      "✓ Processed isaienkov_keras-nn-with-embeddings-for-cat-features-1-15\n",
      "✓ Processed patelatharva_prediction\n",
      "✓ Processed zeynepkurban_ashrae-2\n",
      "✓ Processed enigola_ashrae-ml-hw6-lgbm\n",
      "✓ Processed clementut_kernel4e51c0227f\n",
      "✓ Processed morituri_lgbm-baseline\n",
      "✓ Processed shukla84manish_energy-consumption\n",
      "✓ Processed madisj_kernel3377148266\n",
      "✓ Processed darisdzakwanhoesien2_ashrae-great-energy-predictor-iii\n",
      "✓ Processed kimtaegwan_what-s-your-cv-method\n",
      "✓ Processed vladimirsydor_randomforestbaseline\n",
      "✓ Processed mayer79_ashrae-lgb-starter-for-r\n",
      "✓ Processed jiaofenx_ashrae-great-energy-predictor-iii\n",
      "✓ Processed gouherdanishiitkgp_ashrae-basic-eda-and-feature-engineering\n",
      "✓ Processed yshiml_ashrae-simple-lgbm-optuna-baseline\n",
      "✓ Processed michelezoccali_ashrae-with-fast-ai-part-3\n",
      "✓ Processed cuijamm_allstate-claims-severity-score-1113-12994\n",
      "⚠️ File not found: nitink12_prog-pyth2.ipynb\n",
      "⚠️ File not found: vishallakha_all-trump-state.ipynb\n",
      "⚠️ File not found: casalicchio_tuning-the-parameter-of-a-custom-objective-1120.ipynb\n",
      "⚠️ File not found: aliajouz_singel-model-lb-1117.ipynb\n",
      "✓ Processed deepdreamx_lgbm-only-featureinteraction-selected\n",
      "⚠️ File not found: xingobar_simple-xgboost-1120-769.ipynb\n",
      "⚠️ File not found: doanducqui_msubx.ipynb\n",
      "✓ Processed emilyanderson304326_allstateclaims\n",
      "⚠️ File not found: aliajouz_xgb-model.ipynb\n",
      "⚠️ File not found: nitink12_prog-python.ipynb\n",
      "✓ Processed tushvjti_eda-allstate\n",
      "⚠️ File not found: tobikaggle_h2o-dnn-averaging-in-r.ipynb\n",
      "✓ Processed harshitt21_allstate-claims-severity-eda-and-baseline\n",
      "✓ Processed aakash2121995_new-ensemble\n",
      "✓ Processed aakash2121995_notebookccc577aa6b\n",
      "✓ Processed venkateshprabhug_severity-of-insurance-claim\n",
      "⚠️ File not found: vecxoz_vecstack-demo.ipynb\n",
      "⚠️ File not found: andreylarionov_simple-gradientboostingregressor-lb-1139.ipynb\n",
      "⚠️ File not found: nirupamkar_xgb-run1.ipynb\n",
      "✓ Processed raviprakash438_allstate-claims-severity\n",
      "⚠️ File not found: akki0206_xgboost-submission-1.ipynb\n",
      "⚠️ File not found: hbhargava2_xgboost-parameter-tuned-feature-engineering.ipynb\n",
      "✓ Processed christianrorholtmoe_all-state-claim-severity-neural-net\n",
      "✓ Processed bradyheinig_byu-stat-348-final-project\n",
      "⚠️ File not found: praveenhegde_xgboost-starter.ipynb\n",
      "⚠️ File not found: rrkc00_xgboost.ipynb\n",
      "✓ Processed nightshade7_allstate-severity-test\n",
      "✓ Processed summershan_allstate-car-claims-severity\n",
      "✓ Processed rahulpawade_allstate-claims-severity-xgboost-regression\n",
      "✓ Processed bradenmcritchfield_allstate-claims-severity-boosted-tree\n",
      "✓ Processed nathanchantry_acs-boosted-trees\n",
      "⚠️ File not found: kevinpalm_bumbling-around-in-tensorflow.ipynb\n",
      "✓ Processed floser_five-minute-model\n",
      "✓ Processed julienpantz_regression\n",
      "⚠️ File not found: mountaindata_allstate-randomforest.ipynb\n",
      "⚠️ File not found: victorwang_rf-model.ipynb\n",
      "⚠️ File not found: victorwang_rf-model-trial2.ipynb\n",
      "✓ Processed zachsabey_allstate-claims-rf\n",
      "✓ Processed natercox_acs-random-forest\n",
      "✓ Processed alazark_allstateclaims\n",
      "✓ Processed wjnkerst_notebookc186b1607b\n",
      "⚠️ File not found: samuelhaberthuer_how-about-a-linear-model.ipynb\n",
      "⚠️ File not found: andrecn_allstate-challenge-boosting-gbm.ipynb\n",
      "✓ Processed victoriarigby_allstate-linear\n",
      "✓ Processed arpytanshu_allstate-claims-severity-1260-mae\n",
      "⚠️ File not found: xingobar_keras-starer.ipynb\n",
      "⚠️ File not found: victorwang_rd-model.ipynb\n",
      "✓ Processed mohammadmehdizare_notebooke9568e0edb\n",
      "✓ Processed samarthpujari_cibmtr-competition\n",
      "✓ Processed youssefelzahar_cibmtr-survival-forest-c-index-test-data-0-806\n",
      "✓ Processed vrushabhbidari_predict-1\n",
      "✓ Processed brianedwards_hct-loo-2\n",
      "✓ Processed akelsayed_ak-prediction-8\n",
      "✓ Processed ahmedsamir1598_cibmtr-2ndnote\n",
      "✓ Processed pedromaiorano_teste\n",
      "✓ Processed chaki18081999_eda-in-detail-and-random-forest-baseline\n",
      "✓ Processed yashsahu02_1-cibmtr-equity-in-post-hct-survival-predictions\n",
      "✓ Processed jaehun123_allogeneic-hct-survival-prediction\n",
      "✓ Processed trantraa_xgb-with-cross-validation\n",
      "✓ Processed abhinov037_cibmtr\n",
      "✓ Processed sheikhomerkashmiri_testing\n",
      "✓ Processed rohitdileep_lightgbm-kaplanmierfitter\n",
      "✓ Processed lordxerxes_benchmark-model\n",
      "✓ Processed claramagdyghaly_cibmttr\n",
      "✓ Processed shrishh_cibmtr-catboost\n",
      "✓ Processed muhammadimran112233_cibmtr-baseline-code\n",
      "✓ Processed inabower_cibmtr-submission-test\n",
      "✓ Processed sabyrbazarymbetov_cibmtr-baseline\n",
      "✓ Processed mhkamangoviii_lightgbm-catboost\n",
      "✓ Processed alicsahmed_cibmtr-machine-learning\n",
      "✓ Processed noorizzatnassar_noor-nassar\n",
      "✓ Processed garrickchinnis_equity-in-post-hct-survival-predictions\n",
      "✓ Processed polygot13_hct-medical-analysis\n",
      "✓ Processed akelsayed_ak-1-equity-in-post-hct-survival-predictions\n",
      "✓ Processed nyeinchansoe_cibmtr-xgboost-regression-0-558\n",
      "✓ Processed livaikira_cibmtr-equity-in-post-hct-survival-predictions\n",
      "✓ Processed jainilspatel_cibmtr-research-easy\n",
      "✓ Processed youssefelzahar_cibmtr-random-forest\n",
      "✓ Processed nabinoli2004_cibmtr\n",
      "✓ Processed gaganbajwaa_cimbtr-ensemble-kfold\n",
      "✓ Processed udaken10_classification-regression\n",
      "✓ Processed jonatanf_cibmtr-neural-network-jonatanf\n",
      "✓ Processed tomeverson_notebook87e39b37ea\n",
      "✓ Processed dianalionel_post-hct-survival-prediction\n",
      "✓ Processed rukmaltharaka_survival-prediction\n",
      "✓ Processed shresthajeevan_survival-analysis\n",
      "✓ Processed sheershsrivas_survival-analysis-with-nn\n",
      "✓ Processed steve179_submission-csv\n",
      "✓ Processed omarsalah123_notebookeb25fbb1d2\n",
      "✓ Processed javierojeda71_cibmtr-equity-in-post-hct-survival-predictions\n",
      "✓ Processed garvio282003_submission-nn-deepsurv-race-mlip26\n",
      "✓ Processed wjones3668_cibmtr-equity-in-post-hct-survival-predictions\n",
      "✓ Processed forgetish_cibmtr-simple-eda-and-data-cleaning\n",
      "✓ Processed nikitalemon_cibmtr\n",
      "✓ Processed codewithab_testing-hct-survival\n",
      "✓ Processed tianlulee_xgboost-solution-starter\n",
      "✓ Processed benjenkins96_understanding-survival-analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from typing import Dict\n",
    "\n",
    "def import_notebooks_from_directory(base_dir: str):\n",
    "    \"\"\"\n",
    "    Import notebooks from competition directories using DataManager and NotebookManager\n",
    "    Args:\n",
    "        base_dir: Base directory containing competition folders\n",
    "    \"\"\"\n",
    "    with DataManager() as dm:\n",
    "\n",
    "        competition_dirs = [d for d in os.listdir(base_dir) \n",
    "                          if os.path.isdir(os.path.join(base_dir, d))]\n",
    "\n",
    "        for competition_id in competition_dirs:\n",
    "            notebook_folder_path = os.path.join(base_dir, competition_id)\n",
    "            metadata_file = os.path.join(notebook_folder_path, \"metadata\", \"all_notebooks_metadata.json\")\n",
    "            \n",
    "            if not os.path.exists(metadata_file):\n",
    "                print(f\"⚠️ No metadata found for {competition_id}\")\n",
    "                continue\n",
    "\n",
    "            with open(metadata_file, 'r') as f:\n",
    "                metadata_dict = json.load(f)\n",
    "\n",
    "            for url, notebook_metadata in metadata_dict.items():\n",
    "                notebook_name = notebook_metadata.get('notebook_name')\n",
    "                if not notebook_name:\n",
    "                    print(f\"⚠️ Missing notebook_name in {url}\")\n",
    "                    continue\n",
    "\n",
    "                notebook_file = os.path.join(notebook_folder_path, f\"{notebook_name}.ipynb\")\n",
    "                if not os.path.isfile(notebook_file):\n",
    "                    print(f\"⚠️ File not found: {notebook_name}.ipynb\")\n",
    "                    continue\n",
    "\n",
    "                # Convert date string to datetime\n",
    "                try:\n",
    "                    input_str.split(\" (\")[0]\n",
    "                    created_at = datetime.datetime.strptime(\n",
    "                        notebook_metadata['date_created'].split(\" (\")[0],\n",
    "                        \"%a %b %d %Y %H:%M:%S GMT%z\"\n",
    "                    ).astimezone(datetime.timezone.utc)\n",
    "                except (KeyError, ValueError):\n",
    "                    created_at = None\n",
    "\n",
    "                # Prepare metrics (as expected by NotebookManager)\n",
    "                metrics = {\n",
    "                    'score': float(notebook_metadata.get('score', 0)),\n",
    "                    'votes': int(notebook_metadata.get('votes', 0)),\n",
    "                    'comments': int(notebook_metadata.get('comments', 0))\n",
    "                }\n",
    "\n",
    "                # Prepare metadata\n",
    "                metadata = {\n",
    "                    'url': url,\n",
    "                    'created_at': created_at,\n",
    "                    'downloaded': notebook_metadata.get('downloaded', False)\n",
    "                }\n",
    "\n",
    "                # Import with error handling using NotebookManager's method\n",
    "                try:\n",
    "                    success = dm.notebooks.import_from_file(\n",
    "                        file_path=notebook_file,\n",
    "                        competition_id=competition_id,\n",
    "                        metrics=metrics,\n",
    "                        **metadata\n",
    "                    )\n",
    "                    \n",
    "                    if success:\n",
    "                        print(f\"✓ Processed {notebook_name}\")\n",
    "                    else:\n",
    "                        print(f\"✗ Failed to import {notebook_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"✗ Failed {notebook_name}: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    notebooks_base_dir = '/Users/zhongming/Local Docs/Github/Kaggle_RAG_dataset/data/notebooks'\n",
    "    import_notebooks_from_directory(notebooks_base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9adf1",
   "metadata": {},
   "source": [
    "# Create User Profile Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8843515",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DataManager() as dm:\n",
    "    # Create a user\n",
    "    user_id = dm.users.create(\n",
    "        username='data_scientist',\n",
    "        email='ds@example.com',\n",
    "        experience_level='intermediate'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de354b3",
   "metadata": {},
   "source": [
    "# Create History Tracking Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2aa2706",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 'cf1f30a8-e334-4674-a860-1386963a0b50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04bead98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Setting up user cc8216f9-dd78-4e73-a707-7c8def40d666 for competition titanic ===\n",
      "\n",
      "=== Phase 1: Initial Chatbot Interactions ===\n",
      "\n",
      "=== Phase 2: First Notebook Recommendation ===\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 134\u001b[0m\n\u001b[1;32m    131\u001b[0m     user_id \u001b[38;5;241m=\u001b[39m dm\u001b[38;5;241m.\u001b[39musers\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_user\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest@example.com\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Run the simulation\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[43msimulate_user_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 33\u001b[0m, in \u001b[0;36msimulate_user_workflow\u001b[0;34m(user_id, competition_id)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 3. Chatbot sends first notebook (based on quality scores)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Phase 2: First Notebook Recommendation ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m notebook \u001b[38;5;241m=\u001b[39m \u001b[43mdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotebooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_by_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompetition_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquality\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     34\u001b[0m dm\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mlog_interaction(\n\u001b[1;32m     35\u001b[0m     user_id, \n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHere\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms a high-quality notebook to get you started: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnotebook[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnotebook_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnotebook[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     37\u001b[0m     is_user\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 4. User digests and submits first submission\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "def create_sample_submission_file(round_num: int, score: float) -> str:\n",
    "    \"\"\"Helper to create temporary submission files for demo purposes\"\"\"\n",
    "    filename = f\"temp_submission_round_{round_num}.csv\"\n",
    "    # Create a simple CSV file that would pass validation\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"PassengerId,Survived\\n\")\n",
    "        for i in range(892, 1310):\n",
    "            f.write(f\"{i},{random.random()}\\n\")\n",
    "    return filename\n",
    "\n",
    "def simulate_user_workflow(user_id: str, competition_id: str = 'titanic'):\n",
    "    \"\"\"\n",
    "    Simulates a complete user interaction workflow with the competition system\n",
    "    using DataManager's prepare_submission method\n",
    "    \"\"\"\n",
    "    with DataManager() as dm:\n",
    "        # 1. Set up user and competition\n",
    "        print(f\"\\n=== Setting up user {user_id} for competition {competition_id} ===\")\n",
    "        dm.users.set_active_competition(user_id, competition_id)\n",
    "        dm.history.initialize_history(user_id, competition_id)\n",
    "        \n",
    "        # 2. Initial interactions with chatbot\n",
    "        print(\"\\n=== Phase 1: Initial Chatbot Interactions ===\")\n",
    "        dm.history.log_interaction(user_id, \"Hi, I want to participate in the Titanic competition\", is_user=True)\n",
    "        dm.history.log_interaction(user_id, \"Welcome! Let me help you get started with some basic concepts.\", is_user=False)\n",
    "        dm.history.log_interaction(user_id, \"What's the first step I should take?\", is_user=True)\n",
    "        \n",
    "        # 3. Chatbot sends first notebook (based on quality scores)\n",
    "        print(\"\\n=== Phase 2: First Notebook Recommendation ===\")\n",
    "        notebook = dm.notebooks.get_by_score(competition_id, 'quality', min_score=0.8, limit=1)[0]\n",
    "        dm.history.log_interaction(\n",
    "            user_id, \n",
    "            f\"Here's a high-quality notebook to get you started: {notebook['notebook_id']} (Score: {notebook['scores']['quality']:.2f})\", \n",
    "            is_user=False\n",
    "        )\n",
    "        \n",
    "        # 4. User digests and submits first submission\n",
    "        print(\"\\n=== Phase 3: First Submission ===\")\n",
    "        dm.history.log_interaction(user_id, \"I've reviewed the notebook and ready to submit!\", is_user=True)\n",
    "        \n",
    "        # Create a sample submission file\n",
    "        submission_file = create_sample_submission_file(1, 0.0)\n",
    "        first_score = round(random.uniform(0.7, 0.85), 4)\n",
    "        \n",
    "        # Use prepare_submission which handles validation and proper submission logging\n",
    "        result = dm.prepare_submission(\n",
    "            user_id=user_id,\n",
    "            submission_file=submission_file,\n",
    "            message=\"First submission based on recommended notebook\"\n",
    "        )\n",
    "        \n",
    "        # Clean up temporary file\n",
    "        os.remove(submission_file)\n",
    "        \n",
    "        if result['status'] != 'success':\n",
    "            print(f\"First submission failed: {result['message']}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"First submission result: {result}\")\n",
    "        \n",
    "        # 5-6. Continue interactions and improvements through 6 rounds\n",
    "        current_round = 2\n",
    "        while current_round <= 6:\n",
    "            print(f\"\\n=== Round {current_round}: Improvement Cycle ===\")\n",
    "            \n",
    "            # Chatbot interaction\n",
    "            dm.history.log_interaction(\n",
    "                user_id, \n",
    "                f\"What should I focus on to improve beyond my current score?\", \n",
    "                is_user=True\n",
    "            )\n",
    "            \n",
    "            # Chatbot recommends another notebook\n",
    "            notebook = dm.notebooks.get_by_score(\n",
    "                competition_id, \n",
    "                'quality', \n",
    "                min_score=0.8 + (current_round * 0.02),\n",
    "                limit=1\n",
    "            )[0]\n",
    "            dm.history.log_interaction(\n",
    "                user_id, \n",
    "                f\"Check out this notebook for advanced techniques: {notebook['notebook_id']}\", \n",
    "                is_user=False\n",
    "            )\n",
    "            \n",
    "            # Create improved submission file\n",
    "            submission_file = create_sample_submission_file(current_round, 0.0)\n",
    "            \n",
    "            # Use prepare_submission for proper handling\n",
    "            result = dm.prepare_submission(\n",
    "                user_id=user_id,\n",
    "                submission_file=submission_file,\n",
    "                message=f\"Improved submission after round {current_round}\"\n",
    "            )\n",
    "            \n",
    "            # Clean up temporary file\n",
    "            os.remove(submission_file)\n",
    "            \n",
    "            if result['status'] != 'success':\n",
    "                print(f\"Round {current_round} submission failed: {result['message']}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Round {current_round} submission result: {result}\")\n",
    "            current_round += 1\n",
    "        \n",
    "        # 7. Complete the competition\n",
    "        print(\"\\n=== Final Phase: Competition Completion ===\")\n",
    "        final_score = result.get('score', 0)\n",
    "        dm.history.complete_competition(user_id, final_score=final_score, notes=\"Completed all 6 rounds\")\n",
    "        dm.users.clear_active_competition(user_id)\n",
    "        \n",
    "        # Get final history\n",
    "        history = dm.history.get_history(user_id)\n",
    "        print(\"\\n=== Competition Summary ===\")\n",
    "        print(f\"User: {user_id}\")\n",
    "        print(f\"Competition: {history['competition_id']}\")\n",
    "        print(f\"Final Score: {final_score}\")\n",
    "        print(f\"Total Submissions: {len(history['submission_history'])}\")\n",
    "        print(\"Round Scores:\")\n",
    "        for i in range(1, 7):\n",
    "            round_data = history['round_history'].get(f'round_{i}', {})\n",
    "            print(f\"  Round {i}: Best Score = {round_data.get('best_score')}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a test user\n",
    "    with DataManager() as dm:\n",
    "        user_id = dm.users.create(\"test_user\", \"test@example.com\")\n",
    "    \n",
    "    # Run the simulation\n",
    "    simulate_user_workflow(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6309c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DataManager() as dm:\n",
    "    # Set active competition\n",
    "    dm.users.set_active_competition(user_id, 'titanic')\n",
    "    dm.history.initialize_history(user_id, 'titanic')\n",
    "\n",
    "    # Log some interactions\n",
    "    dm.history.log_interaction(user_id, \"Starting Titanic analysis\", is_user=True)\n",
    "    dm.history.log_interaction(user_id, \"Here's some initial guidance\", is_user=False)\n",
    "\n",
    "    # Log a submission\n",
    "    dm.history.log_submission(user_id, {\n",
    "        'notebook_id': 'initial_analysis',\n",
    "        'score': 0.85,\n",
    "        'notes': 'First submission with basic model'\n",
    "    })\n",
    "    \n",
    "    # advance the user\n",
    "    dm.history.advance_user(user_id, 'titanic', 'advanced')\n",
    "    # Log a new interaction\n",
    "    dm.history.log_interaction(user_id, \"Advanced analysis on Titanic dataset\", is_user=True)\n",
    "    # Log a new submission\n",
    "    dm.history.log_submission(user_id, {\n",
    "        'notebook_id': 'advanced_analysis',\n",
    "        'score': 0.90,\n",
    "        'notes': 'Improved model with feature engineering'\n",
    "    })\n",
    "    #complete the history\n",
    "    dm.history.complete_competition(user_id, 'titanic')\n",
    "    \n",
    "    # exit the competition\n",
    "    dm.users.clear_active_competition(user_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogenstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
