{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "# Assuming your original JSON is stored in a variable called original_json\n",
    "def load_checkpoint():\n",
    "    \"\"\"Load competitions data from the checkpoint file if it exists.\"\"\"\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        with open(CHECKPOINT_FILE, 'r') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                print(f\"Loaded checkpoint with {len(data)} entries.\")\n",
    "                return data\n",
    "            except Exception as e:\n",
    "                print(\"Error loading checkpoint:\", e)\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_FILE = '../data/competition_list.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint with 552 entries.\n"
     ]
    }
   ],
   "source": [
    "json_data= load_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data_url to each competition\n",
    "for competition in json_data:\n",
    "    base_url = competition[\"competition_url\"]\n",
    "    competition[\"data_url\"] = f\"{base_url}/data\"\n",
    "    # rename slug to competition_name\n",
    "    if \"slug\" in competition:\n",
    "        competition[\"competition_name\"] = competition.pop(\"slug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved modified data with 552 entries.\n"
     ]
    }
   ],
   "source": [
    "# Save the modified JSON back to the file\n",
    "with open(CHECKPOINT_FILE, 'w') as f:\n",
    "    try:\n",
    "        json.dump(json_data, f, indent=4)\n",
    "        print(f\"Saved modified data with {len(json_data)} entries.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error saving modified data:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.kaggle.com/competitions/titanic/overview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure undetected_chromedriver options\n",
    "options = uc.ChromeOptions()\n",
    "\n",
    "# Enable headless mode if desired (note: some sites may behave differently in headless mode)\n",
    "options.headless = True\n",
    "\n",
    "# Disable automation flags that could hint at scraping\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "# Optionally, set a randomized user-agent\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)\"\n",
    "    \" Chrome/92.0.4515.107 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko)\"\n",
    "    \" Version/14.0.3 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko)\"\n",
    "    \" Chrome/91.0.4472.114 Safari/537.36\"\n",
    "]\n",
    "options.add_argument(f'--user-agent={random.choice(user_agents)}')\n",
    "\n",
    "# Initialize undetected_chromedriver\n",
    "driver = uc.Chrome(options=options)\n",
    "driver.get(url)\n",
    "\n",
    "# Use explicit wait for dynamic content to load\n",
    "wait = WebDriverWait(driver, 15)\n",
    "data = {}\n",
    "\n",
    "# find a div with id = description\n",
    "desc_header = wait.until(EC.presence_of_element_located((By.ID, \"description\")))\n",
    "description_content = desc_header.text.strip()\n",
    "data['Description'] = description_content\n",
    "\n",
    "# find a div with id = description\n",
    "eval_header = wait.until(EC.presence_of_element_located((By.ID, \"evaluation\")))\n",
    "evaluation_content = eval_header.text.strip()\n",
    "data['Evaluation'] = evaluation_content\n",
    "\n",
    "# search a div with class = \"sc-ipAaKu blEaCU\"\n",
    "sidebar_container = wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"sc-ipAaKu.blEaCU\")))\n",
    "\n",
    "def extract_fields(text):\n",
    "    # Define the desired and ignored fields.\n",
    "    desired_fields = {\"Competition Host\", \"Prizes & Awards\", \"Participation\", \"Tags\",\"Files\", \"Size\", \"Type\"}\n",
    "    ignore_fields = {\"Table of Contents\", \"Description\", \"Evaluation\", \"Frequently Asked Questions\", \"Citation\",\"License\"}\n",
    "    \n",
    "    # Initialize the extracted data.\n",
    "    extracted = {}\n",
    "    for field in desired_fields:\n",
    "        # For Participation, we want a nested dict; otherwise, use a list.\n",
    "        if field == \"Participation\":\n",
    "            extracted[field] = {}\n",
    "        else:\n",
    "            extracted[field] = []\n",
    "    \n",
    "    current_field = None\n",
    "    for line in text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # skip empty lines\n",
    "        \n",
    "        # If the line is a header for a desired field, switch context.\n",
    "        if line in desired_fields:\n",
    "            current_field = line\n",
    "            continue\n",
    "        \n",
    "        # If the line is an ignore field, stop capturing data.\n",
    "        if line in ignore_fields:\n",
    "            current_field = None\n",
    "            continue\n",
    "        \n",
    "        if current_field:\n",
    "            if current_field == \"Participation\":\n",
    "                # Expected format: \"1,363,292 Entrants\" -> split into number and label.\n",
    "                parts = line.split(\" \", 1)\n",
    "                if len(parts) == 2:\n",
    "                    num_str, label = parts\n",
    "                    try:\n",
    "                        # Remove commas and convert to integer.\n",
    "                        number = int(num_str.replace(\",\", \"\"))\n",
    "                        extracted[current_field][label] = number\n",
    "                    except ValueError:\n",
    "                        # In case conversion fails, store the raw value.\n",
    "                        extracted[current_field][label] = num_str\n",
    "                else:\n",
    "                    # If the format is unexpected, skip this line.\n",
    "                    continue\n",
    "            else:\n",
    "                extracted[current_field].append(line)\n",
    "    \n",
    "    return extracted\n",
    "# display the sidebar container\n",
    "sidebar_content = extract_fields(sidebar_container.text)\n",
    "\n",
    "data['Competition Host'] = sidebar_content.get(\"Competition Host\", [])\n",
    "data['Prizes & Awards'] = sidebar_content.get(\"Prizes & Awards\", [])\n",
    "data['Participants'] = sidebar_content.get('Participation', {}).get('Participants', 0)\n",
    "data['Entrants'] = sidebar_content.get('Participation', {}).get('Entrants', 0)\n",
    "data['Submissions'] = sidebar_content.get('Participation', {}).get('Submissions', 0)\n",
    "data['Teams'] = sidebar_content.get('Participation', {}).get('Teams', 0)\n",
    "data['Tags'] = sidebar_content.get(\"Tags\", [])\n",
    "\n",
    "# Optional: Random sleep before closing to mimic human behavior\n",
    "time.sleep(random.uniform(2, 5))\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fields(text,desired_fields = {\"Competition Host\", \"Prizes & Awards\", \"Participation\", \"Tags\"},ignore_fields = {\"Table of Contents\", \"Description\", \"Evaluation\", \"Frequently Asked Questions\", \"Citation\",\"License\"}):\n",
    "    # Initialize the extracted data.\n",
    "    extracted = {}\n",
    "    for field in desired_fields:\n",
    "        # For Participation, we want a nested dict; otherwise, use a list.\n",
    "        if field == \"Participation\":\n",
    "            extracted[field] = {}\n",
    "        else:\n",
    "            extracted[field] = []\n",
    "    \n",
    "    current_field = None\n",
    "    for line in text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # skip empty lines\n",
    "        \n",
    "        # If the line is a header for a desired field, switch context.\n",
    "        if line in desired_fields:\n",
    "            current_field = line\n",
    "            continue\n",
    "        \n",
    "        # If the line is an ignore field, stop capturing data.\n",
    "        if line in ignore_fields:\n",
    "            current_field = None\n",
    "            continue\n",
    "        \n",
    "        if current_field:\n",
    "            if current_field == \"Participation\":\n",
    "                # Expected format: \"1,363,292 Entrants\" -> split into number and label.\n",
    "                parts = line.split(\" \", 1)\n",
    "                if len(parts) == 2:\n",
    "                    num_str, label = parts\n",
    "                    try:\n",
    "                        # Remove commas and convert to integer.\n",
    "                        number = int(num_str.replace(\",\", \"\"))\n",
    "                        extracted[current_field][label] = number\n",
    "                    except ValueError:\n",
    "                        # In case conversion fails, store the raw value.\n",
    "                        extracted[current_field][label] = num_str\n",
    "                else:\n",
    "                    # If the format is unexpected, skip this line.\n",
    "                    continue\n",
    "            else:\n",
    "                extracted[current_field].append(line)\n",
    "    \n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.kaggle.com/competitions/titanic/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure undetected_chromedriver options\n",
    "options = uc.ChromeOptions()\n",
    "\n",
    "# Enable headless mode if desired (note: some sites may behave differently in headless mode)\n",
    "options.headless = True\n",
    "\n",
    "# Disable automation flags that could hint at scraping\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "# Optionally, set a randomized user-agent\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)\"\n",
    "    \" Chrome/92.0.4515.107 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko)\"\n",
    "    \" Version/14.0.3 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko)\"\n",
    "    \" Chrome/91.0.4472.114 Safari/537.36\"\n",
    "]\n",
    "options.add_argument(f'--user-agent={random.choice(user_agents)}')\n",
    "\n",
    "# Initialize undetected_chromedriver\n",
    "driver = uc.Chrome(options=options)\n",
    "driver.get(url)\n",
    "\n",
    "# Use explicit wait for dynamic content to load\n",
    "wait = WebDriverWait(driver, 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a div with id = description\n",
    "desc_header = wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"sc-fqpjkJ.xUjLo\")))\n",
    "description_content = desc_header.text.strip()\n",
    "data['Description'] = description_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Description\n",
      "Overview\n",
      "The data has been split into two groups:\n",
      "training set (train.csv)\n",
      "test set (test.csv)\n",
      "The training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use feature engineering to create new features.\n",
      "The test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n",
      "We also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\n",
      "Data Dictionary\n",
      "Variable Definition Key\n",
      "survival Survival 0 = No, 1 = Yes\n",
      "pclass Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\n",
      "sex Sex\n",
      "Age Age in years\n",
      "sibsp # of siblings / spouses aboard the Titanic\n",
      "parch # of parents / children aboard the Titanic\n",
      "ticket Ticket number\n",
      "fare Passenger fare\n",
      "cabin Cabin number\n",
      "embarked Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n",
      "Variable Notes\n",
      "pclass: A proxy for socio-economic status (SES)\n",
      "1st = Upper\n",
      "2nd = Middle\n",
      "3rd = Lower\n",
      "\n",
      "age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
      "\n",
      "sibsp: The dataset defines family relations in this way...\n",
      "Sibling = brother, sister, stepbrother, stepsister\n",
      "Spouse = husband, wife (mistresses and fiancés were ignored)\n",
      "\n",
      "parch: The dataset defines family relations in this way...\n",
      "Parent = mother, father\n",
      "Child = daughter, son, stepdaughter, stepson\n",
      "Some children travelled only with a nanny, therefore parch=0 for them.\n"
     ]
    }
   ],
   "source": [
    "print(description_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a div with id = description\n",
    "sidebar_header = wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"sc-sgxPq.fEgtle\")))\n",
    "sidebar_content = sidebar_header.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files\n",
      "3 files\n",
      "Size\n",
      "93.08 kB\n",
      "Type\n",
      "csv\n",
      "License\n",
      "Subject to Competition Rules\n"
     ]
    }
   ],
   "source": [
    "print(sidebar_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = extract_fields(sidebar_content,desired_fields={\"Files\", \"Size\", \"Type\"},\n",
    "            ignore_fields={\"License\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Files': ['3 files'], 'Size': ['93.08 kB'], 'Type': ['csv']}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'Files': extracted.get(\"Files\", []),\n",
    "'Size': extracted.get(\"Size\", []),\n",
    "'Type': extracted.get(\"Type\", [])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "class CompetitionScraper:\n",
    "    def __init__(self, headless=True):\n",
    "        self.user_agent = self._get_random_user_agent()\n",
    "        self.driver = self._init_driver(headless)\n",
    "        self.wait = WebDriverWait(self.driver, 15)\n",
    "    \n",
    "    def _get_random_user_agent(self):\n",
    "        user_agents = [\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15\",\n",
    "            \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0\",\n",
    "            \"Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Mobile/15E148 Safari/604.1\"\n",
    "        ]\n",
    "        return random.choice(user_agents)\n",
    "    \n",
    "    def _init_driver(self, headless):\n",
    "        options = uc.ChromeOptions()\n",
    "        options.headless = headless\n",
    "        options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        options.add_argument(f'--user-agent={self.user_agent}')\n",
    "        return uc.Chrome(options=options)\n",
    "\n",
    "    def refresh_driver(self, headless):\n",
    "        self.close()\n",
    "        self.user_agent = self._get_random_user_agent()\n",
    "        self.driver = self._init_driver(headless)\n",
    "        self.wait = WebDriverWait(self.driver, 15)\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_fields(text, desired_fields=None, ignore_fields=None):\n",
    "        if desired_fields is None:\n",
    "            desired_fields = {\"Competition Host\", \"Prizes & Awards\", \"Participation\", \"Tags\"}\n",
    "        if ignore_fields is None:\n",
    "            ignore_fields = {\"Table of Contents\", \"Description\", \"Evaluation\", \n",
    "                           \"Frequently Asked Questions\", \"Citation\"}\n",
    "        \n",
    "        extracted = {}\n",
    "        for field in desired_fields:\n",
    "            extracted[field] = {} if field == \"Participation\" else []\n",
    "        \n",
    "        current_field = None\n",
    "        for line in text.splitlines():\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            if line in desired_fields:\n",
    "                current_field = line\n",
    "                continue\n",
    "            \n",
    "            if line in ignore_fields:\n",
    "                current_field = None\n",
    "                continue\n",
    "            \n",
    "            if current_field:\n",
    "                if current_field == \"Participation\":\n",
    "                    parts = line.split(\" \", 1)\n",
    "                    if len(parts) == 2:\n",
    "                        num_str, label = parts\n",
    "                        try:\n",
    "                            extracted[current_field][label] = int(num_str.replace(\",\", \"\"))\n",
    "                        except ValueError:\n",
    "                            extracted[current_field][label] = num_str\n",
    "                else:\n",
    "                    extracted[current_field].append(line)\n",
    "        return extracted\n",
    "    \n",
    "    def extract_competition_data(self, url):\n",
    "        self.driver.get(url)\n",
    "        \n",
    "        desc_header = self.wait.until(EC.presence_of_element_located((By.ID, \"description\")))\n",
    "        evaluation = self.wait.until(EC.presence_of_element_located((By.ID, \"evaluation\"))).text.strip()\n",
    "        sidebar = self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"sc-ipAaKu.blEaCU\"))).text\n",
    "        \n",
    "        sidebar_content = self.extract_fields(sidebar)\n",
    "        participation = sidebar_content.get(\"Participation\", {})\n",
    "        \n",
    "        return {\n",
    "            'Description': desc_header.text.strip(),\n",
    "            'Evaluation': evaluation,\n",
    "            'Competition Host': sidebar_content.get(\"Competition Host\", []),\n",
    "            'Prizes & Awards': sidebar_content.get(\"Prizes & Awards\", []),\n",
    "            'Entrants': participation.get('Entrants', 0),\n",
    "            'Participants': participation.get('Participants', 0),\n",
    "            'Teams': participation.get('Teams', 0),\n",
    "            'Submissions': participation.get('Submissions', 0),\n",
    "            'Tags': sidebar_content.get(\"Tags\", [])\n",
    "        }\n",
    "        \n",
    "    def extract_data_metadata(self, url):\n",
    "        self.driver.get(url)\n",
    "        \n",
    "        try:\n",
    "            desc_element = self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"sc-fqpjkJ.xUjLo\")))\n",
    "            description = desc_element.text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting data description from {url}: {str(e)}\")\n",
    "            description = \"\"\n",
    "\n",
    "        try:\n",
    "            sidebar_element = self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"sc-sgxPq.fEgtle\")))\n",
    "            sidebar_content = sidebar_element.text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting data sidebar from {url}: {str(e)}\")\n",
    "            sidebar_content = \"\"\n",
    "        \n",
    "        extracted = self.extract_fields(\n",
    "            sidebar_content,\n",
    "            desired_fields={\"Files\", \"Size\", \"Type\"},\n",
    "            ignore_fields={\"License\"}\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'Description': description,\n",
    "            'Files': extracted.get(\"Files\", []),\n",
    "            'Size': extracted.get(\"Size\", []),\n",
    "            'Type': extracted.get(\"Type\", [])\n",
    "        }\n",
    "        \n",
    "    def close(self):\n",
    "        self.driver.quit()\n",
    "# Modified main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogenstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
