{"cells":[{"metadata":{"_uuid":"700f230e4e8d96e91e5db099b71cafe47bfedc23","_cell_guid":"2b061fce-be91-4b4c-a962-130cd332ff70"},"cell_type":"markdown","source":"In this kernel we compare the prediction accuracy of the machine learning method \"Random Forest\" (default) with penalized linear models (tuned).\n\n\n\n**1. Five Minute Model: Random Forest with ranger**\n\nTo show how easy, quick and yet powerful machine learning methods can be we start with the R-package ranger, a fast implementation of Leo Breimans original random forest algorithm. We read the data, overwrite loss by log(loss), build the model on training data, make predictions on test data and finally create a well formatted submission file."},{"metadata":{"_uuid":"cd0842538ed80aca9ff4553b71f8db2cdfa95ca8","trusted":false,"_cell_guid":"615040e2-6fbf-4a94-a6e6-7fc0124d25df"},"cell_type":"code","source":"tic <- proc.time() # start time. Sparse code (just 5 min ..):\n\nd=read.csv(\"../input/train.csv\")\nv=read.csv(\"../input/test.csv\")\nd$loss <- log(d$loss) \nlibrary(ranger)\nm <- ranger(loss~., data=d, importance='impurity', verbose=F)\np=predict(m,dat=v)\nwrite.csv(data.frame(id=v$id,loss=exp(p$predictions)),\"subm.csv\",row.names=F)\n\nprint(proc.time() - tic)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"350c60acaf30b6a6def480a03c74422316afed98","_cell_guid":"aef5502d-2c22-4abb-be5c-437bcf963cfe"},"cell_type":"markdown","source":"A late submission of this file (no upload required) will result in a score of 1191 (MAE) on the public leaderboard.\n\nTo get a clue about the model we can display the importance of the variables [top ten]: "},{"metadata":{"_uuid":"65da3622200c6d2ef1288e2e372a371811266c01","trusted":false,"_cell_guid":"9f545352-f319-44ec-80a7-cc2e05d1ed91"},"cell_type":"code","source":"sort(m$variable.importance, decreasing = TRUE)[1:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af3772878f0131ae388276ef056e79a8b22d028e","_cell_guid":"9d7a1901-2b38-4175-b8c4-8613e1016076"},"cell_type":"markdown","source":"The most important features seem to be cat80 and cat79, both categorial. Interestingly the id is listed in the top 10. Either there is some meaning in it or it is an indicator for over-fitting. It shouldn't be there. Thus we exclude id in the next steps. "},{"metadata":{"_uuid":"18f6509bf67ae630a2d94c46c236df68de2b05b7","_cell_guid":"6d89275a-91c8-456b-8788-b2a2783af610"},"cell_type":"markdown","source":"\n**2.  Split data and play with settings**\n\nNow we split the training data in two halfs. We train the model on the first half and evaluate on the second half and vice versa.   The evaluation metric is the mean absolute error (MAE)."},{"metadata":{"_uuid":"d0272a0be8d4b8b1069b32177496266e63717813","trusted":false,"_cell_guid":"b1c2e938-e914-425f-bdf1-accef1a2ebce"},"cell_type":"code","source":"# split training data based on row number (to get same samples on any system)\nd1 <- d[seq(1,188318) %% 10 <5,-1] #-1: without id\nd2 <- d[seq(1,188318) %% 10 >=5,-1] #-1: without id\ny1 <- d1$loss\ny2 <- d2$loss\n\n# print number of claims and variables\ndim(d); dim(d1); dim(d2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf387e0542d59efda8ea15371ff85a53e1af4560","_cell_guid":"308d852f-145a-4ef3-8390-b98053d061bd"},"cell_type":"markdown","source":"Again we use ranger with default settings."},{"metadata":{"_uuid":"c7e61bbaf1defc3ab28ea7dd9d07272c72d8300c","trusted":false,"_cell_guid":"3a2703c7-1230-4a6a-90c4-a204a5bfdabc"},"cell_type":"code","source":"# ranger tuning parameters: default values\n# mtry = 11. Number of variables to possibly split at in each node. Default is the (rounded down) square root of the number of variables.\n# num.trees = 500. Number of trees.\ntic <- proc.time()        # timer: start\n\nrg1 <- ranger(loss ~ ., data = d1, importance='impurity',verbose=F) \nsort(rg1$variable.importance, decreasing = TRUE)[1:10] # display top10 variables\nrgpred12 <- predict(rg1, dat = d2)\nprint(paste(\"MAE Ranger,12 = \",mean(abs(exp(rgpred12$predictions)-exp(y2)))))\n\nprint(proc.time() - tic)  # timer: stop","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a51b192750c74a67bc227b0e2182c2ecea0a705f","trusted":false,"_cell_guid":"f69c4a55-1765-40df-8e2d-344a09ef23de"},"cell_type":"code","source":"rg2 <- ranger(loss ~ ., data = d2, importance='impurity',verbose=F)\nsort(rg2$variable.importance, decreasing = TRUE)[1:10] # display top10 variables\nrgpred21 <- predict(rg2, dat = d1)\nprint(paste(\"MAE Ranger,21 = \",mean(abs(exp(rgpred21$predictions)-exp(y1)))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22a77dde822020031b4001316fa361ce15fe31f2","_cell_guid":"b684e0e5-b3f4-4d58-9f79-6701b5acd3ff"},"cell_type":"markdown","source":"Result: \nThe mean average error of the models trained on just half of the claims is quite similar, yet higher than the MAE based on all claims. As expected, more data allows for more model complexity and thus better predictions.\n\nWe can take these results as a benchmark and try to improve the model and get a lower MAE.  To speed up we start with less trees and guess a reasonable number of split-variables. "},{"metadata":{"_uuid":"b11a880cdcff3d711119d9d06ae3ffac848eed79","trusted":false,"_cell_guid":"ff22a33e-805c-4e50-90b4-bb9ccbb382ce"},"cell_type":"code","source":"rg1 <- ranger(loss ~ ., data = d1, num.trees =  400, mtry = 40, importance='impurity',verbose=F)\nrgpred12 <- predict(rg1, dat = d2)\nprint(paste(\"MAE Ranger,12 = \",mean(abs(exp(rgpred12$predictions)-exp(y2)))))\n\nrg2 <- ranger(loss ~ ., data = d2, num.trees =  400, mtry = 40, importance='impurity',verbose=F)\nrgpred21 <- predict(rg2, dat = d1)\nprint(paste(\"MAE Ranger,21 = \",mean(abs(exp(rgpred21$predictions)-exp(y1)))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9758efe097c11f527dc45eaaaa74d9b7cb63d305","_cell_guid":"34952f5a-c99b-471c-8522-24026ae61325"},"cell_type":"markdown","source":"A bit better. Since two parameters where changed at the same time we don't know how to continue. Performing a grid search might help here. \n\nAnyway, how thus this compare to linear models?"},{"metadata":{"_uuid":"7870234fffd3dd88354ad547639e4450e5eab0b6","_cell_guid":"7920c5d4-1b6e-46fa-a8a3-ed85ab20f925"},"cell_type":"markdown","source":"**3. Regularized Linear Models: LASSO**\n\nIn machine learning, the term \"linear models\" refers to the newer, regularized variants of linear models such as Ridge regression or LASSO. These methods are well implemented in the R-package glmnet. Let's try LASSO, as this method performs automatic variable selection. \n"},{"metadata":{"_uuid":"fad93dfd97d4593ed0329e19bf594bac1a65760f","trusted":false,"_cell_guid":"83b9cd47-bf02-4ef5-8d6e-e15886c0391c"},"cell_type":"code","source":"library(glmnet) \n# create matrix with dummy variables for factors (one-hot-encoding)\nx1 <- model.matrix(loss~.-1,data=d1) \nx2 <- model.matrix(loss~.-1,data=d2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63c1c6f8c98450899bebf00b0ea7136430ce1b31","_cell_guid":"22a39cee-9df7-43e1-a37b-28a1870052a5"},"cell_type":"markdown","source":"Fortunately there are no missing values in the records. This allows us to directly apply linear models without further preprocessing.\n\nIn the following we calculate a set of linear models for a grid of lambdas (the complexity-parameter). Then we determine the best model by using cross validation (default: 10-fold) and make the predictions."},{"metadata":{"_uuid":"8f807253a53a93fdcc73e355875762098c203ddc","trusted":false,"_cell_guid":"b301c706-a51e-469f-9e3c-9a1fe37eb9f3"},"cell_type":"code","source":"tic <- proc.time()        # timer: start\n\nfit.lasso=glmnet(x1,y1) # Lasso with default-grid\nplot(fit.lasso ,xvar=\"lambda\",main=\"Lasso\")\ncv1=cv.glmnet(x1,y1) \npred12=predict(fit.lasso, s = cv1$lambda.min,newx = x2)\n\nprint(proc.time() - tic)  # timer: stop","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d827490f7d8992e97b01596d8ba68a03faa0cf35"},"cell_type":"markdown","source":"On the left hand side there is no penalty. We can see the coefficients of the usually overfitting full model. On the right hand side the penalty is very high and all coefficients are set to zero, just the intercept (average) remains. This model usually underfits.  \n\nThe best lambda and thus the best model complexity is determined by cross-validation. The results:"},{"metadata":{"trusted":true,"_uuid":"8c78e178e0898fd11ae28ff49cf131710076f22f"},"cell_type":"code","source":"print(paste(\"Best Log(Lambda),1 = \",log(cv1$lambda.min)))\nprint(paste(\"MAE Lasso,12 = \",mean(abs(exp(pred12)-exp(y2)))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b81e731b4efc2ad41aff3bcddad1d89579d7620","_cell_guid":"0e3ab91e-f080-403a-a211-fd4a9d61576f"},"cell_type":"markdown","source":"The MAE is substancially worse."},{"metadata":{"_uuid":"2e6af7e9a374b26731173d553bb8d49fddf572ac","_cell_guid":"004d1806-7e37-44fe-a424-6e05f711cdce"},"cell_type":"markdown","source":"**4.Summary**\n\nBased on this claims data set a default random forest model outperforms an optimized regularized linear model in precision (and speed).\n\n"},{"metadata":{"_uuid":"e0c16739ceeed558c78ee9a9442dc39cc8bb6921","_cell_guid":"773906c1-cf60-4ec8-9ae2-7f4cb4c4c830"},"cell_type":"markdown","source":"**Extensions**\n\na) Gradient boosting: Gradient boosting machines like xgboost and lightgbm need to be carefully tuned (settings, called “hyperparameters”). Despite that a default gbm-model is even better than random forest, see https://www.kaggle.com/floser/r-starter-lightgbm-regression, which is based on the same data set.\n\nb) Neural nets: Neural nets became recently very successful in claim prediction competitions. \nUnfortunately, training with large data sets requires a lot of computing power. Here you can find an introduction based on small datasets:  https://www.kaggle.com/floser/neuralnet-plots-and-deeper-learning .\n\nc) Generalized Linear Mixed Models (GLMM): There are further extensions of linear models available. In case you are interested in how to apply Generalized Linear Models (GLMs) and Generalized Linear Mixed Models (GLMMs) to claims data with R see  https://www.kaggle.com/floser/claim-frequency-glms-and-glmms .\n"}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}