{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some more practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ashrae-energy-prediction/sample_submission.csv\n",
      "/kaggle/input/ashrae-energy-prediction/building_metadata.csv\n",
      "/kaggle/input/ashrae-energy-prediction/weather_test.csv\n",
      "/kaggle/input/ashrae-energy-prediction/train.csv\n",
      "/kaggle/input/ashrae-energy-prediction/test.csv\n",
      "/kaggle/input/ashrae-energy-prediction/weather_train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from dask import dataframe as dd\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some functions to fill data, add features and reduce memory usage\n",
    "\n",
    "def fill_weather_dataset(weather_df):\n",
    "    \n",
    "    # Find Missing Dates\n",
    "    time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start_date = datetime.datetime.strptime(weather_df['timestamp'].min(),time_format)\n",
    "    end_date = datetime.datetime.strptime(weather_df['timestamp'].max(),time_format)\n",
    "    total_hours = int(((end_date - start_date).total_seconds() + 3600) / 3600)\n",
    "    hours_list = [(end_date - datetime.timedelta(hours=x)).strftime(time_format) for x in range(total_hours)]\n",
    "\n",
    "    missing_hours = []\n",
    "    for site_id in range(16):\n",
    "        site_hours = np.array(weather_df[weather_df['site_id'] == site_id]['timestamp'])\n",
    "        new_rows = pd.DataFrame(np.setdiff1d(hours_list,site_hours),columns=['timestamp'])\n",
    "        new_rows['site_id'] = site_id\n",
    "        weather_df = pd.concat([weather_df,new_rows])\n",
    "\n",
    "        weather_df = weather_df.reset_index(drop=True)           \n",
    "\n",
    "    # Add new Features\n",
    "    weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
    "    weather_df[\"day\"] = weather_df[\"datetime\"].dt.day\n",
    "    weather_df[\"week\"] = weather_df[\"datetime\"].dt.week\n",
    "    weather_df[\"month\"] = weather_df[\"datetime\"].dt.month\n",
    "    \n",
    "    # Reset Index for Fast Update\n",
    "    weather_df = weather_df.set_index(['site_id','day','month'])\n",
    "\n",
    "    air_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['air_temperature'].mean(),columns=[\"air_temperature\"])\n",
    "    weather_df.update(air_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    cloud_coverage_filler = weather_df.groupby(['site_id','day','month'])['cloud_coverage'].mean()\n",
    "    # Step 2\n",
    "    cloud_coverage_filler = pd.DataFrame(cloud_coverage_filler.fillna(method='ffill'),columns=[\"cloud_coverage\"])\n",
    "\n",
    "    weather_df.update(cloud_coverage_filler,overwrite=False)\n",
    "\n",
    "    due_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['dew_temperature'].mean(),columns=[\"dew_temperature\"])\n",
    "    weather_df.update(due_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    sea_level_filler = weather_df.groupby(['site_id','day','month'])['sea_level_pressure'].mean()\n",
    "    # Step 2\n",
    "    sea_level_filler = pd.DataFrame(sea_level_filler.fillna(method='ffill'),columns=['sea_level_pressure'])\n",
    "\n",
    "    weather_df.update(sea_level_filler,overwrite=False)\n",
    "\n",
    "    wind_direction_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_direction'].mean(),columns=['wind_direction'])\n",
    "    weather_df.update(wind_direction_filler,overwrite=False)\n",
    "\n",
    "    wind_speed_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_speed'].mean(),columns=['wind_speed'])\n",
    "    weather_df.update(wind_speed_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    precip_depth_filler = weather_df.groupby(['site_id','day','month'])['precip_depth_1_hr'].mean()\n",
    "    # Step 2\n",
    "    precip_depth_filler = pd.DataFrame(precip_depth_filler.fillna(method='ffill'),columns=['precip_depth_1_hr'])\n",
    "\n",
    "    weather_df.update(precip_depth_filler,overwrite=False)\n",
    "\n",
    "    weather_df = weather_df.reset_index()\n",
    "    weather_df = weather_df.drop(['datetime','day','week','month'],axis=1)\n",
    "        \n",
    "    return weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if isinstance(df[col], datetime.datetime) or pd.api.types.is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag_feature(weather_df, window=3):\n",
    "    group_df = weather_df.groupby('site_id')\n",
    "    cols = ['air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', \n",
    "            'sea_level_pressure']\n",
    "    rolled = group_df[cols].rolling(window=window, min_periods=0)\n",
    "    lag_mean = rolled.mean().reset_index().astype(np.float16)\n",
    "    lag_max = rolled.max().reset_index().astype(np.float16)\n",
    "    lag_min = rolled.min().reset_index().astype(np.float16)\n",
    "    lag_std = rolled.std().reset_index().astype(np.float16)\n",
    "    for col in cols:\n",
    "        weather_df[f'{col}_mean_lag{window}'] = lag_mean[col]\n",
    "        weather_df[f'{col}_max_lag{window}'] = lag_max[col]\n",
    "        weather_df[f'{col}_min_lag{window}'] = lag_min[col]\n",
    "        weather_df[f'{col}_std_lag{window}'] = lag_std[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFeatures(df):\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    df.sort_values(\"timestamp\")\n",
    "    df.reset_index(drop=True)\n",
    "    \n",
    "    # Add more features\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    df[\"weekend\"] = df[\"timestamp\"].dt.weekday\n",
    "    holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
    "                    \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
    "                    \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
    "                    \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
    "                    \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
    "                    \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
    "                    \"2019-01-01\"]\n",
    "    df[\"is_holiday\"] = (df.timestamp.isin(holidays)).astype(int)\n",
    "    #df['square_feet'] =  np.log1p(df['square_feet'])\n",
    "    \n",
    "    building_mean = df_group.mean().astype(np.float16)\n",
    "    building_median = df_group.median().astype(np.float16)\n",
    "    building_min = df_group.min().astype(np.float16)\n",
    "    building_max = df_group.max().astype(np.float16)\n",
    "    building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "    df['building_mean'] = df['building_id'].map(building_mean)\n",
    "    df['building_median'] = df['building_id'].map(building_median)\n",
    "    df['building_min'] = df['building_id'].map(building_min)\n",
    "    df['building_max'] = df['building_id'].map(building_max)\n",
    "    df['building_std'] = df['building_id'].map(building_std)\n",
    "    \n",
    "    # Remove Unused Columns\n",
    "    drop = [#\"timestamp\",\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\n",
    "            \"year_built\",\"floor_count\",'timestamp']\n",
    "    df = df.drop(drop, axis=1)\n",
    "    gc.collect()\n",
    "    \n",
    "    # Encode Categorical Data\n",
    "    #le = LabelEncoder()\n",
    "    #df[\"primary_use\"] = le.fit_transform(df[\"primary_use\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.01 MB\n",
      "Decreased by 79.0%\n"
     ]
    }
   ],
   "source": [
    "building_metadata = pd.read_csv('../input/ashrae-energy-prediction/building_metadata.csv')\n",
    "building_metadata['primary_use'] = building_metadata['primary_use'].astype('category')\n",
    "le = LabelEncoder()\n",
    "building_metadata[\"primary_use\"] = le.fit_transform(building_metadata[\"primary_use\"])\n",
    "building_metadata['square_feet'] =  np.log1p(building_metadata['square_feet'])\n",
    "building_metadata = reduce_mem_usage(building_metadata,use_float16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "Int64Index([ 105,  106,  107,  108,  109,  110,  111,  112,  113,  114,\n",
      "            ...\n",
      "            1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324],\n",
      "           dtype='int64', name='building_id', length=403)\n"
     ]
    }
   ],
   "source": [
    "print('train data:')\n",
    "train = pd.read_csv('../input/ashrae-energy-prediction/train.csv')\n",
    "# Remove outliers\n",
    "#train = train[ train['building_id'] != 1099 ]\n",
    "train = train[~((train['meter'] == 2) & (train['building_id'] == 1099))]\n",
    "train = train.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')\n",
    "train['meter_reading_log1p'] = np.log1p(train['meter_reading'])\n",
    "df_group = train.groupby('building_id')['meter_reading_log1p']\n",
    "\n",
    "#Get part of data with full set of timestamps\n",
    "count_full = train.groupby('building_id')['timestamp'].nunique()\n",
    "#Remember count_full is a Series object\n",
    "count_full = count_full[count_full==count_full.max()]\n",
    "#ids with whole length\n",
    "print(count_full.index)\n",
    "train = train[train['building_id'].isin(count_full.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fill Weather Information\n",
    "weather_train = pd.read_csv('../input/ashrae-energy-prediction/weather_train.csv')\n",
    "weather_train = fill_weather_dataset(weather_train)\n",
    "#weather_train = weather_train.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\n",
    "add_lag_feature(weather_train, window=3)\n",
    "add_lag_feature(weather_train, window=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 304.75 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 121.01 MB\n",
      "Decreased by 60.3%\n",
      "Memory usage of dataframe is 20.37 MB\n",
      "Memory usage after optimization is: 13.38 MB\n",
      "Decreased by 34.3%\n"
     ]
    }
   ],
   "source": [
    "#Memory reduction\n",
    "train = reduce_mem_usage(train,use_float16=True)\n",
    "weather_train = reduce_mem_usage(weather_train,use_float16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge data\n",
    "train = train.merge(building_metadata, on='building_id', how='left')\n",
    "train = train.merge(weather_train, on=['site_id', 'timestamp'], how='left')\n",
    "del weather_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>meter_reading_log1p</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>sea_level_pressure_min_lag72</th>\n",
       "      <th>sea_level_pressure_std_lag72</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>building_mean</th>\n",
       "      <th>building_median</th>\n",
       "      <th>building_min</th>\n",
       "      <th>building_max</th>\n",
       "      <th>building_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6657350</th>\n",
       "      <td>1323</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>11.37500</td>\n",
       "      <td>6.101562</td>\n",
       "      <td>0.736816</td>\n",
       "      <td>-6.699219</td>\n",
       "      <td>...</td>\n",
       "      <td>1009.5</td>\n",
       "      <td>8.085938</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.679688</td>\n",
       "      <td>6.531250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.539062</td>\n",
       "      <td>2.28125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6657351</th>\n",
       "      <td>1323</td>\n",
       "      <td>3</td>\n",
       "      <td>1909.329956</td>\n",
       "      <td>7.554688</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>11.37500</td>\n",
       "      <td>6.101562</td>\n",
       "      <td>0.736816</td>\n",
       "      <td>-6.699219</td>\n",
       "      <td>...</td>\n",
       "      <td>1009.5</td>\n",
       "      <td>8.085938</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.679688</td>\n",
       "      <td>6.531250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.539062</td>\n",
       "      <td>2.28125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6657352</th>\n",
       "      <td>1324</td>\n",
       "      <td>0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.708984</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>11.34375</td>\n",
       "      <td>6.101562</td>\n",
       "      <td>0.736816</td>\n",
       "      <td>-6.699219</td>\n",
       "      <td>...</td>\n",
       "      <td>1009.5</td>\n",
       "      <td>8.085938</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.261719</td>\n",
       "      <td>2.398438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.988281</td>\n",
       "      <td>2.31250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6657353</th>\n",
       "      <td>1324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>11.34375</td>\n",
       "      <td>6.101562</td>\n",
       "      <td>0.736816</td>\n",
       "      <td>-6.699219</td>\n",
       "      <td>...</td>\n",
       "      <td>1009.5</td>\n",
       "      <td>8.085938</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.261719</td>\n",
       "      <td>2.398438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.988281</td>\n",
       "      <td>2.31250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6657354</th>\n",
       "      <td>1324</td>\n",
       "      <td>3</td>\n",
       "      <td>364.019012</td>\n",
       "      <td>5.898438</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>11.34375</td>\n",
       "      <td>6.101562</td>\n",
       "      <td>0.736816</td>\n",
       "      <td>-6.699219</td>\n",
       "      <td>...</td>\n",
       "      <td>1009.5</td>\n",
       "      <td>8.085938</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.261719</td>\n",
       "      <td>2.398438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.988281</td>\n",
       "      <td>2.31250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         building_id  meter  meter_reading  meter_reading_log1p  site_id  \\\n",
       "6657350         1323      1       0.000000             0.000000       14   \n",
       "6657351         1323      3    1909.329956             7.554688       14   \n",
       "6657352         1324      0      14.000000             2.708984       14   \n",
       "6657353         1324      1       0.000000             0.000000       14   \n",
       "6657354         1324      3     364.019012             5.898438       14   \n",
       "\n",
       "         primary_use  square_feet  air_temperature  cloud_coverage  \\\n",
       "6657350            6     11.37500         6.101562        0.736816   \n",
       "6657351            6     11.37500         6.101562        0.736816   \n",
       "6657352            1     11.34375         6.101562        0.736816   \n",
       "6657353            1     11.34375         6.101562        0.736816   \n",
       "6657354            1     11.34375         6.101562        0.736816   \n",
       "\n",
       "         dew_temperature  ...  sea_level_pressure_min_lag72  \\\n",
       "6657350        -6.699219  ...                        1009.5   \n",
       "6657351        -6.699219  ...                        1009.5   \n",
       "6657352        -6.699219  ...                        1009.5   \n",
       "6657353        -6.699219  ...                        1009.5   \n",
       "6657354        -6.699219  ...                        1009.5   \n",
       "\n",
       "         sea_level_pressure_std_lag72  hour  weekend  is_holiday  \\\n",
       "6657350                      8.085938    23        5           0   \n",
       "6657351                      8.085938    23        5           0   \n",
       "6657352                      8.085938    23        5           0   \n",
       "6657353                      8.085938    23        5           0   \n",
       "6657354                      8.085938    23        5           0   \n",
       "\n",
       "         building_mean  building_median  building_min  building_max  \\\n",
       "6657350       5.679688         6.531250           0.0      8.539062   \n",
       "6657351       5.679688         6.531250           0.0      8.539062   \n",
       "6657352       2.261719         2.398438           0.0      7.988281   \n",
       "6657353       2.261719         2.398438           0.0      7.988281   \n",
       "6657354       2.261719         2.398438           0.0      7.988281   \n",
       "\n",
       "         building_std  \n",
       "6657350       2.28125  \n",
       "6657351       2.28125  \n",
       "6657352       2.31250  \n",
       "6657353       2.31250  \n",
       "6657354       2.31250  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add features\n",
    "train = addFeatures(train)\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get features and target variables\n",
    "def get_train_data(df, site_id):\n",
    "    df_ = df[df['meter']==mtype]\n",
    "    target = df_[\"meter_reading_log1p\"]\n",
    "    features = df_.drop(['meter_reading','meter_reading_log1p'], axis = 1)\n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training meter: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.849533\tvalid_1's rmse: 0.794057\n",
      "[50]\ttraining's rmse: 0.70118\tvalid_1's rmse: 0.696501\n",
      "[75]\ttraining's rmse: 0.644696\tvalid_1's rmse: 0.676879\n",
      "[100]\ttraining's rmse: 0.592515\tvalid_1's rmse: 0.670296\n",
      "[125]\ttraining's rmse: 0.562388\tvalid_1's rmse: 0.669353\n",
      "[150]\ttraining's rmse: 0.541105\tvalid_1's rmse: 0.671989\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's rmse: 0.575261\tvalid_1's rmse: 0.66859\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.800358\tvalid_1's rmse: 0.894328\n",
      "[50]\ttraining's rmse: 0.644943\tvalid_1's rmse: 0.78661\n",
      "[75]\ttraining's rmse: 0.590428\tvalid_1's rmse: 0.771825\n",
      "[100]\ttraining's rmse: 0.54757\tvalid_1's rmse: 0.770881\n",
      "[125]\ttraining's rmse: 0.517505\tvalid_1's rmse: 0.771491\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's rmse: 0.549164\tvalid_1's rmse: 0.769514\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 0.75812\tvalid_1's rmse: 0.963888\n",
      "[50]\ttraining's rmse: 0.601942\tvalid_1's rmse: 0.896677\n",
      "[75]\ttraining's rmse: 0.552873\tvalid_1's rmse: 0.891997\n",
      "[100]\ttraining's rmse: 0.514063\tvalid_1's rmse: 0.891064\n",
      "[125]\ttraining's rmse: 0.486379\tvalid_1's rmse: 0.890199\n",
      "[150]\ttraining's rmse: 0.467752\tvalid_1's rmse: 0.89085\n",
      "[175]\ttraining's rmse: 0.453543\tvalid_1's rmse: 0.891236\n",
      "Early stopping, best iteration is:\n",
      "[126]\ttraining's rmse: 0.485872\tvalid_1's rmse: 0.890145\n",
      "training meter: 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.53598\tvalid_1's rmse: 1.77896\n",
      "[50]\ttraining's rmse: 1.28864\tvalid_1's rmse: 1.57229\n",
      "[75]\ttraining's rmse: 1.19208\tvalid_1's rmse: 1.54021\n",
      "[100]\ttraining's rmse: 1.12157\tvalid_1's rmse: 1.52921\n",
      "[125]\ttraining's rmse: 1.08086\tvalid_1's rmse: 1.5251\n",
      "[150]\ttraining's rmse: 1.04954\tvalid_1's rmse: 1.52321\n",
      "[175]\ttraining's rmse: 1.02733\tvalid_1's rmse: 1.5193\n",
      "[200]\ttraining's rmse: 1.00871\tvalid_1's rmse: 1.51837\n",
      "[225]\ttraining's rmse: 0.995009\tvalid_1's rmse: 1.51665\n",
      "[250]\ttraining's rmse: 0.982148\tvalid_1's rmse: 1.51595\n",
      "[275]\ttraining's rmse: 0.967274\tvalid_1's rmse: 1.51617\n",
      "Early stopping, best iteration is:\n",
      "[235]\ttraining's rmse: 0.990299\tvalid_1's rmse: 1.51533\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.54377\tvalid_1's rmse: 1.80381\n",
      "[50]\ttraining's rmse: 1.30236\tvalid_1's rmse: 1.54731\n",
      "[75]\ttraining's rmse: 1.22265\tvalid_1's rmse: 1.4775\n",
      "[100]\ttraining's rmse: 1.16353\tvalid_1's rmse: 1.46223\n",
      "[125]\ttraining's rmse: 1.11889\tvalid_1's rmse: 1.46246\n",
      "[150]\ttraining's rmse: 1.09016\tvalid_1's rmse: 1.45775\n",
      "[175]\ttraining's rmse: 1.06763\tvalid_1's rmse: 1.45426\n",
      "[200]\ttraining's rmse: 1.04881\tvalid_1's rmse: 1.44888\n",
      "[225]\ttraining's rmse: 1.03283\tvalid_1's rmse: 1.45032\n",
      "[250]\ttraining's rmse: 1.01744\tvalid_1's rmse: 1.45077\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttraining's rmse: 1.04506\tvalid_1's rmse: 1.44863\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.45169\tvalid_1's rmse: 1.76847\n",
      "[50]\ttraining's rmse: 1.17777\tvalid_1's rmse: 1.65278\n",
      "[75]\ttraining's rmse: 1.09223\tvalid_1's rmse: 1.63353\n",
      "[100]\ttraining's rmse: 1.03981\tvalid_1's rmse: 1.62644\n",
      "[125]\ttraining's rmse: 1.00606\tvalid_1's rmse: 1.62314\n",
      "[150]\ttraining's rmse: 0.981635\tvalid_1's rmse: 1.62053\n",
      "[175]\ttraining's rmse: 0.962406\tvalid_1's rmse: 1.6197\n",
      "[200]\ttraining's rmse: 0.945254\tvalid_1's rmse: 1.6183\n",
      "[225]\ttraining's rmse: 0.931413\tvalid_1's rmse: 1.6175\n",
      "[250]\ttraining's rmse: 0.919042\tvalid_1's rmse: 1.61781\n",
      "[275]\ttraining's rmse: 0.90643\tvalid_1's rmse: 1.61804\n",
      "[300]\ttraining's rmse: 0.895591\tvalid_1's rmse: 1.61816\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's rmse: 0.916235\tvalid_1's rmse: 1.6172\n",
      "training meter: 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.59682\tvalid_1's rmse: 1.80114\n",
      "[50]\ttraining's rmse: 1.36909\tvalid_1's rmse: 1.6866\n",
      "[75]\ttraining's rmse: 1.28986\tvalid_1's rmse: 1.66886\n",
      "[100]\ttraining's rmse: 1.22429\tvalid_1's rmse: 1.65733\n",
      "[125]\ttraining's rmse: 1.1745\tvalid_1's rmse: 1.64861\n",
      "[150]\ttraining's rmse: 1.14327\tvalid_1's rmse: 1.64306\n",
      "[175]\ttraining's rmse: 1.11966\tvalid_1's rmse: 1.62972\n",
      "[200]\ttraining's rmse: 1.09777\tvalid_1's rmse: 1.62203\n",
      "[225]\ttraining's rmse: 1.08135\tvalid_1's rmse: 1.62337\n",
      "Early stopping, best iteration is:\n",
      "[198]\ttraining's rmse: 1.10002\tvalid_1's rmse: 1.62019\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.4979\tvalid_1's rmse: 2.01398\n",
      "[50]\ttraining's rmse: 1.26524\tvalid_1's rmse: 1.8109\n",
      "[75]\ttraining's rmse: 1.17696\tvalid_1's rmse: 1.76264\n",
      "[100]\ttraining's rmse: 1.11925\tvalid_1's rmse: 1.73553\n",
      "[125]\ttraining's rmse: 1.07653\tvalid_1's rmse: 1.72543\n",
      "[150]\ttraining's rmse: 1.04707\tvalid_1's rmse: 1.71555\n",
      "[175]\ttraining's rmse: 1.02545\tvalid_1's rmse: 1.70557\n",
      "[200]\ttraining's rmse: 1.00752\tvalid_1's rmse: 1.6999\n",
      "[225]\ttraining's rmse: 0.991312\tvalid_1's rmse: 1.69379\n",
      "[250]\ttraining's rmse: 0.977294\tvalid_1's rmse: 1.68868\n",
      "[275]\ttraining's rmse: 0.962721\tvalid_1's rmse: 1.68305\n",
      "[300]\ttraining's rmse: 0.951959\tvalid_1's rmse: 1.67924\n",
      "[325]\ttraining's rmse: 0.940849\tvalid_1's rmse: 1.67819\n",
      "[350]\ttraining's rmse: 0.931124\tvalid_1's rmse: 1.67715\n",
      "[375]\ttraining's rmse: 0.921144\tvalid_1's rmse: 1.67736\n",
      "[400]\ttraining's rmse: 0.910613\tvalid_1's rmse: 1.67773\n",
      "[425]\ttraining's rmse: 0.903321\tvalid_1's rmse: 1.67614\n",
      "[450]\ttraining's rmse: 0.897488\tvalid_1's rmse: 1.67547\n",
      "[475]\ttraining's rmse: 0.889481\tvalid_1's rmse: 1.67416\n",
      "[500]\ttraining's rmse: 0.882599\tvalid_1's rmse: 1.67561\n",
      "[525]\ttraining's rmse: 0.874754\tvalid_1's rmse: 1.67531\n",
      "Early stopping, best iteration is:\n",
      "[479]\ttraining's rmse: 0.888478\tvalid_1's rmse: 1.67397\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.47561\tvalid_1's rmse: 1.82532\n",
      "[50]\ttraining's rmse: 1.2219\tvalid_1's rmse: 1.7955\n",
      "[75]\ttraining's rmse: 1.14797\tvalid_1's rmse: 1.80067\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's rmse: 1.2683\tvalid_1's rmse: 1.79123\n",
      "training meter: 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.70574\tvalid_1's rmse: 1.99942\n",
      "[50]\ttraining's rmse: 1.53922\tvalid_1's rmse: 1.93342\n",
      "[75]\ttraining's rmse: 1.46632\tvalid_1's rmse: 1.92173\n",
      "[100]\ttraining's rmse: 1.41876\tvalid_1's rmse: 1.92312\n",
      "[125]\ttraining's rmse: 1.3866\tvalid_1's rmse: 1.92532\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's rmse: 1.46123\tvalid_1's rmse: 1.92092\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.77216\tvalid_1's rmse: 1.78991\n",
      "[50]\ttraining's rmse: 1.61587\tvalid_1's rmse: 1.66113\n",
      "[75]\ttraining's rmse: 1.54367\tvalid_1's rmse: 1.6421\n",
      "[100]\ttraining's rmse: 1.49765\tvalid_1's rmse: 1.63769\n",
      "[125]\ttraining's rmse: 1.46191\tvalid_1's rmse: 1.63026\n",
      "[150]\ttraining's rmse: 1.43354\tvalid_1's rmse: 1.63235\n",
      "[175]\ttraining's rmse: 1.41094\tvalid_1's rmse: 1.63164\n",
      "Early stopping, best iteration is:\n",
      "[126]\ttraining's rmse: 1.4598\tvalid_1's rmse: 1.62935\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.6321\tvalid_1's rmse: 2.00326\n",
      "[50]\ttraining's rmse: 1.44233\tvalid_1's rmse: 1.9593\n",
      "[75]\ttraining's rmse: 1.37421\tvalid_1's rmse: 1.95566\n",
      "[100]\ttraining's rmse: 1.32912\tvalid_1's rmse: 1.95796\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's rmse: 1.41035\tvalid_1's rmse: 1.95434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features = [\"building_id\", \"site_id\", \"meter\", \"is_holiday\", \"weekend\", 'primary_use']\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.85,\n",
    "    \"reg_lambda\": 2,\n",
    "    \"metric\": \"rmse\",\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "models = []\n",
    "for mtype in [0,1,2,3]:\n",
    "    print(f'training meter: {mtype}')\n",
    "    features, target = get_train_data(train, mtype); tmp = []\n",
    "    for train_index,test_index in kf.split(features, target):\n",
    "        train_features = features.iloc[train_index]\n",
    "        train_target = target.iloc[train_index]\n",
    "    \n",
    "        test_features = features.iloc[test_index]\n",
    "        test_target = target.iloc[test_index]\n",
    "    \n",
    "        d_training = lgb.Dataset(train_features, label=train_target,\n",
    "                                 categorical_feature=categorical_features, free_raw_data=False)\n",
    "        d_test = lgb.Dataset(test_features, label=test_target,\n",
    "                             categorical_feature=categorical_features, free_raw_data=False)\n",
    "    \n",
    "        model = lgb.train(params, train_set=d_training, num_boost_round=1000, \n",
    "                          valid_sets=[d_training,d_test], verbose_eval=25, early_stopping_rounds=50)\n",
    "        tmp.append(model)\n",
    "    models.append(tmp)\n",
    "\n",
    "del train_features, train_target, test_features, test_target, d_training, d_test, features, target, train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 954.38 MB\n",
      "Memory usage after optimization is: 199.59 MB\n",
      "Decreased by 79.1%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load test data\n",
    "test = pd.read_csv('../input/ashrae-energy-prediction/test.csv')\n",
    "row_ids = test[\"row_id\"]\n",
    "#ref = test[['row_id','meter']]\n",
    "test = test.drop(\"row_id\", axis=1)\n",
    "test = reduce_mem_usage(test)\n",
    "#td = dd.from_pandas(test, npartitions=20)\n",
    "#del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 19.25 MB\n",
      "Memory usage after optimization is: 9.05 MB\n",
      "Decreased by 53.0%\n"
     ]
    }
   ],
   "source": [
    "weather_test = pd.read_csv('../input/ashrae-energy-prediction/weather_test.csv')\n",
    "weather_test = fill_weather_dataset(weather_test)\n",
    "#weather_test = weather_test.groupby('site_id').apply(lambda group: group.interpolate(limit_direction='both'))\n",
    "weather_test = reduce_mem_usage(weather_test)\n",
    "add_lag_feature(weather_test, window=3)\n",
    "add_lag_feature(weather_test, window=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697595</th>\n",
       "      <td>41697595</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697596</th>\n",
       "      <td>41697596</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697597</th>\n",
       "      <td>41697597</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697598</th>\n",
       "      <td>41697598</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697599</th>\n",
       "      <td>41697599</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41697600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  meter_reading\n",
       "0                0            0.0\n",
       "1                1            0.0\n",
       "2                2            0.0\n",
       "3                3            0.0\n",
       "4                4            0.0\n",
       "...            ...            ...\n",
       "41697595  41697595            0.0\n",
       "41697596  41697596            0.0\n",
       "41697597  41697597            0.0\n",
       "41697598  41697598            0.0\n",
       "41697599  41697599            0.0\n",
       "\n",
       "[41697600 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('../input/ashrae-energy-prediction/sample_submission.csv', \n",
    "                  dtype={'row_id':np.uint16, 'meter_reading':np.float32})\n",
    "sub['row_id'] = row_ids\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(df, models):\n",
    "    yp_total = np.zeros(df.shape[0])\n",
    "    for i, model in enumerate(models):\n",
    "        print(f'predicting model-{i}')\n",
    "        yp = model.predict(df, num_iteration=model.best_iteration)\n",
    "        yp_total += yp\n",
    "\n",
    "    yp_total /= len(models)\n",
    "    return yp_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meter-0 dataframe shape is (24755760, 60)\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicted array has shape (24755760,)\n",
      "meter-1 dataframe shape is (8724960, 60)\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicted array has shape (8724960,)\n",
      "meter-2 dataframe shape is (5676480, 60)\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicted array has shape (5676480,)\n",
      "meter-3 dataframe shape is (2540400, 60)\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicting model-0\n",
      "predicting model-1\n",
      "predicting model-2\n",
      "predicted array has shape (2540400,)\n"
     ]
    }
   ],
   "source": [
    "n = 1000000\n",
    "for mtype in [0,1,2,3]:\n",
    "    tst = test.loc[test['meter']==mtype]\n",
    "    tst = tst.merge(building_metadata, on='building_id', how='left')\n",
    "    tst = tst.merge(weather_test, on=['site_id', 'timestamp'], how='left')\n",
    "    tst = addFeatures(tst)\n",
    "    print(f'meter-{mtype} dataframe shape is {tst.shape}')\n",
    "    #print(tst.columns)\n",
    "    gen = (tst[i:i+n] for i in range(0,tst.shape[0],n))\n",
    "    p_full = []\n",
    "    for x in gen:\n",
    "        p = pred(x, models[mtype])\n",
    "        p_full.append(p)\n",
    "    p_full = np.concatenate(p_full)\n",
    "    print(f'predicted array has shape {p_full.shape}')\n",
    "    sub.loc[test['meter']==mtype, 'meter_reading'] = np.expm1(p_full)\n",
    "    del tst\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>171.363098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>76.235291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18.874214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>172.750534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>217.044647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697595</th>\n",
       "      <td>41697595</td>\n",
       "      <td>11.430673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697596</th>\n",
       "      <td>41697596</td>\n",
       "      <td>10.368989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697597</th>\n",
       "      <td>41697597</td>\n",
       "      <td>6.622452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697598</th>\n",
       "      <td>41697598</td>\n",
       "      <td>138.678101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41697599</th>\n",
       "      <td>41697599</td>\n",
       "      <td>8.388652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41697600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  meter_reading\n",
       "0                0     171.363098\n",
       "1                1      76.235291\n",
       "2                2      18.874214\n",
       "3                3     172.750534\n",
       "4                4     217.044647\n",
       "...            ...            ...\n",
       "41697595  41697595      11.430673\n",
       "41697596  41697596      10.368989\n",
       "41697597  41697597       6.622452\n",
       "41697598  41697598     138.678101\n",
       "41697599  41697599       8.388652\n",
       "\n",
       "[41697600 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", index=False, float_format='%.5f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
