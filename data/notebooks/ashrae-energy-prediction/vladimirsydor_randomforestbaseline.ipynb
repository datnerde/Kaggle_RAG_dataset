{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MonthTimeValidation(object):\n",
    "    def __init__(self, month_to_test_set=2, time_col='timestamp'):\n",
    "        self.month_to_test_set = month_to_test_set\n",
    "        self.time_col = time_col\n",
    "        \n",
    "    def split(self, df):\n",
    "        split_col = df[self.time_col].dt.month\n",
    "        split_col = split_col.reset_index(drop=True)\n",
    "        \n",
    "        for max_month in range(1,13-self.month_to_test_set):\n",
    "            train_idx = split_col[split_col <= max_month].index.tolist()\n",
    "            test_idx = split_col[(split_col > max_month) & (split_col <= max_month+self.month_to_test_set)].index.tolist()\n",
    "            yield train_idx, test_idx\n",
    "            \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def LRMSE(y_true, y_pred):\n",
    "    return (mean_squared_error(y_true,y_pred))**(1/2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NaiveMeanModel(object):\n",
    "    def __init__(self, values_to_count_mean, target_variable_name, value_to_fillna=0):\n",
    "        self.values_to_count_mean = values_to_count_mean\n",
    "        self.target_variable_name = target_variable_name\n",
    "        self.value_to_fillna = value_to_fillna\n",
    "        \n",
    "        self.counted_stats = None \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if len(set(self.values_to_count_mean) & set(X.columns)) < len(self.values_to_count_mean):\n",
    "            raise ValueError('Columns to count stats not in df')\n",
    "            \n",
    "        self.counted_stats = X.groupby(self.values_to_count_mean)[self.target_variable_name].mean().reset_index()\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self.target_variable_name in X.columns:\n",
    "            prediction =  X.merge(self.counted_stats, on=self.values_to_count_mean, how='left')[self.target_variable_name+'_y']\n",
    "        else:\n",
    "            prediction =  X.merge(self.counted_stats, on=self.values_to_count_mean, how='left')[self.target_variable_name]\n",
    "            \n",
    "        print(str(prediction.isna().sum()) + ' Nan detected')\n",
    "        return prediction.fillna(self.value_to_fillna).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class MyRegressor(object):\n",
    "    def __init__(self, ml_params, nmm_params, tgt_variable='meter_reading'):\n",
    "        self.ml = [RandomForestRegressor(**ml_params) for i in range(4)]\n",
    "        self.naive_mean_model = NaiveMeanModel(**nmm_params)\n",
    "        self.tgt_variable = tgt_variable\n",
    "        \n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.naive_mean_model.fit(X)\n",
    "        X['stat'] = self.naive_mean_model.predict(X)\n",
    "        \n",
    "        for i in range(4):\n",
    "            self.ml[i].fit(X[X['meter']==i].drop(columns=['timestamp',self.tgt_variable,'meter']), X.loc[X['meter']==i,self.tgt_variable])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X['stat'] = self.naive_mean_model.predict(X)\n",
    "        cols_to_drop = list({'row_id', 'timestamp', self.tgt_variable} & set(X.columns))\n",
    "        \n",
    "        X['prediction'] = 0\n",
    "        for i in range(4):\n",
    "            X.loc[X['meter']==i, 'prediction'] = self.ml[i].predict(X[X['meter']==i].drop(columns=cols_to_drop+['meter','prediction']))\n",
    "        \n",
    "        return X['prediction']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from os import path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/kaggle/input/ashrae-energy-prediction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 289.19 Mb (53.1% reduction)\n",
      "Mem. usage decreased to 596.49 Mb (53.1% reduction)\n",
      "Mem. usage decreased to  0.03 Mb (60.3% reduction)\n",
      "Mem. usage decreased to 10.74 Mb (66.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(pd.read_csv(path.join(data_path,'train.csv')))\n",
    "test = reduce_mem_usage(pd.read_csv(path.join(data_path,'test.csv')))\n",
    "\n",
    "building_metadata = reduce_mem_usage(pd.read_csv(path.join(data_path,'building_metadata.csv')))\n",
    "weather = reduce_mem_usage(pd.read_csv('/kaggle/input/ashrae/fixed_weather_df.csv')).drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEATHER_FETURES_WITH_NANS = ['air_temperature', 'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, build_metadata, weather_metadata, is_test=False):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df = df.sort_values('timestamp')\n",
    "    \n",
    "    if not is_test:\n",
    "        primary_use_dict = {el:i for i, el in enumerate(build_metadata['primary_use'].unique())}\n",
    "        build_metadata['primary_use'] = build_metadata['primary_use'].map(primary_use_dict)\n",
    "        \n",
    "    if not is_test:\n",
    "        weather_metadata['timestamp'] = pd.to_datetime(weather_metadata['timestamp'])\n",
    "        weather_metadata = weather_metadata.sort_values('timestamp')\n",
    "        \n",
    "        for f in WEATHER_FETURES_WITH_NANS:\n",
    "            weather_metadata[f] = weather_metadata[f].fillna(weather_metadata[f].median())\n",
    "    \n",
    "    df = df.merge(build_metadata, on='building_id', how='left')\n",
    "    df = df.merge(weather_metadata, on=['site_id','timestamp'], how='left')\n",
    "    \n",
    "    df['day_of_week'] = df['timestamp'].dt.weekday\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    \n",
    "    df['year_built'] = df['year_built'].fillna(df['year_built'].median())\n",
    "    df['floor_count'] = df['floor_count'].fillna(df['floor_count'].median())\n",
    "    for f in WEATHER_FETURES_WITH_NANS:\n",
    "            df[f] = df[f].fillna(df[f].median())\n",
    "            \n",
    "    if not is_test:\n",
    "        df['meter_reading'] = np.log1p(df['meter_reading'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = prepare_data(train, building_metadata, weather)\n",
    "test = prepare_data(test, building_metadata, weather, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del building_metadata\n",
    "del weather\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_val(data, model, metric=LRMSE, target_var_name='meter_reading'):\n",
    "    time_validation_split = MonthTimeValidation()\n",
    "    \n",
    "    results = []\n",
    "    for train_idx, test_idx in time_validation_split.split(data):\n",
    "        model.fit(data.iloc[train_idx].reset_index(drop=True))\n",
    "        pred = model.predict(data.iloc[test_idx].reset_index(drop=True))\n",
    "        itter_metric = metric(data.iloc[test_idx][target_var_name], pred)\n",
    "        \n",
    "        print('Itter metric: '+str(itter_metric))\n",
    "        results.append(itter_metric)\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = MyRegressor(ml_params={'n_estimators':50, 'criterion':'mse', 'max_depth':17, 'max_features':'sqrt', 'n_jobs':4}, \n",
    "                       nmm_params={'values_to_count_mean':['building_id','meter','day_of_week','hour'], 'target_variable_name':'meter_reading'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Nan detected\n",
      "32335 Nan detected\n",
      "Itter metric: 1.1681758236305184\n",
      "0 Nan detected\n",
      "36001 Nan detected\n",
      "Itter metric: 1.188940167142598\n",
      "0 Nan detected\n",
      "8174 Nan detected\n",
      "Itter metric: 1.213690719279122\n",
      "0 Nan detected\n",
      "6474 Nan detected\n",
      "Itter metric: 1.487707991236372\n",
      "0 Nan detected\n",
      "2744 Nan detected\n",
      "Itter metric: 1.3847829887046823\n",
      "0 Nan detected\n",
      "1917 Nan detected\n",
      "Itter metric: 1.0534195500860117\n",
      "0 Nan detected\n",
      "6568 Nan detected\n",
      "Itter metric: 1.0031705684226095\n",
      "0 Nan detected\n",
      "4533 Nan detected\n",
      "Itter metric: 1.297020475533684\n",
      "0 Nan detected\n",
      "1520 Nan detected\n",
      "Itter metric: 1.4906479592693327\n",
      "0 Nan detected\n",
      "2276 Nan detected\n",
      "Itter metric: 1.3820539439853434\n",
      "Result: 1.26696 +/- 0.16145\n"
     ]
    }
   ],
   "source": [
    "rf_res = time_val(train, rf_model)\n",
    "print('Result: {} +/- {}'.format(round(np.mean(rf_res),5), round(np.std(rf_res),5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Nan detected\n",
      "0 Nan detected\n"
     ]
    }
   ],
   "source": [
    "rf_model.fit(train)\n",
    "test['meter_reading'] = rf_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['meter_reading'] = np.expm1(test['meter_reading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>stat</th>\n",
       "      <th>prediction</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.601562</td>\n",
       "      <td>...</td>\n",
       "      <td>12.796875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2.099609</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3.347265</td>\n",
       "      <td>1.280242</td>\n",
       "      <td>2.597509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41614356</td>\n",
       "      <td>1393</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>151900</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.800781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4.101562</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.400648</td>\n",
       "      <td>4.342333</td>\n",
       "      <td>75.886744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41614355</td>\n",
       "      <td>1392</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>76153</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.800781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4.101562</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7.538067</td>\n",
       "      <td>7.722743</td>\n",
       "      <td>2258.147224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41614354</td>\n",
       "      <td>1392</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>76153</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.800781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4.101562</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.167542</td>\n",
       "      <td>4.190253</td>\n",
       "      <td>65.039525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41614353</td>\n",
       "      <td>1391</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>68693</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.800781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4.101562</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6.801698</td>\n",
       "      <td>7.077190</td>\n",
       "      <td>1183.634530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id  building_id  meter  timestamp  site_id  primary_use  square_feet  \\\n",
       "0         0            0      0 2017-01-01        0            0         7432   \n",
       "1  41614356         1393      0 2017-01-01       15            3       151900   \n",
       "2  41614355         1392      2 2017-01-01       15            3        76153   \n",
       "3  41614354         1392      0 2017-01-01       15            3        76153   \n",
       "4  41614353         1391      2 2017-01-01       15            3        68693   \n",
       "\n",
       "   year_built  floor_count  air_temperature  ...  dew_temperature  \\\n",
       "0      2008.0          3.0        15.601562  ...        12.796875   \n",
       "1      1990.0          3.0         2.800781  ...         0.000000   \n",
       "2      1963.0          3.0         2.800781  ...         0.000000   \n",
       "3      1963.0          3.0         2.800781  ...         0.000000   \n",
       "4      1956.0          3.0         2.800781  ...         0.000000   \n",
       "\n",
       "   precip_depth_1_hr  sea_level_pressure  wind_direction  wind_speed  \\\n",
       "0                0.0              1022.0           130.0    2.099609   \n",
       "1                0.0              1008.0           210.0    4.101562   \n",
       "2                0.0              1008.0           210.0    4.101562   \n",
       "3                0.0              1008.0           210.0    4.101562   \n",
       "4                0.0              1008.0           210.0    4.101562   \n",
       "\n",
       "   day_of_week  hour      stat  prediction  meter_reading  \n",
       "0            6     0  3.347265    1.280242       2.597509  \n",
       "1            6     0  4.400648    4.342333      75.886744  \n",
       "2            6     0  7.538067    7.722743    2258.147224  \n",
       "3            6     0  4.167542    4.190253      65.039525  \n",
       "4            6     0  6.801698    7.077190    1183.634530  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['row_id','meter_reading']].to_csv('naive_mean_predictor.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
