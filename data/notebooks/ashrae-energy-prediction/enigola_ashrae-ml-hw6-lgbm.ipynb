{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [LGBM baseline](https://www.kaggle.com/morituri/lgbm-baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.7 s, sys: 4.84 s, total: 46.5 s\n",
      "Wall time: 46.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "metadata_dtype = {'site_id':\"uint8\",'building_id':'uint16','square_feet':'float32','year_built':'float32','floor_count':\"float16\"}\n",
    "weather_dtype = {\"site_id\":\"uint8\",'air_temperature':\"float16\",'cloud_coverage':\"float16\",'dew_temperature':\"float16\",'precip_depth_1_hr':\"float16\",\n",
    "                 'sea_level_pressure':\"float32\",'wind_direction':\"float16\",'wind_speed':\"float16\"}\n",
    "train_dtype = {'meter':\"uint8\",'building_id':'uint16'}\n",
    "\n",
    "weather_train = pd.read_csv(\"../input/ashrae-energy-prediction/weather_train.csv\", parse_dates=['timestamp'], dtype=weather_dtype)\n",
    "weather_test = pd.read_csv(\"../input/ashrae-energy-prediction/weather_test.csv\", parse_dates=['timestamp'], dtype=weather_dtype)\n",
    "metadata = pd.read_csv(\"../input/ashrae-energy-prediction/building_metadata.csv\", dtype=metadata_dtype)\n",
    "train = pd.read_csv(\"../input/ashrae-energy-prediction/train.csv\", parse_dates=['timestamp'], dtype=train_dtype)\n",
    "test = pd.read_csv(\"../input/ashrae-energy-prediction/test.csv\", parse_dates=['timestamp'], usecols=['building_id','meter','timestamp'], dtype=train_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from sklearn.utils import resample\n",
    "#train_size = 1_000_000\n",
    "#test_size = 1_000_000\n",
    "#seed = 947\n",
    "#train = resample(train, replace=False, n_samples=train_size, random_state=seed)\n",
    "#test = resample(test, replace=False, n_samples=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['meter'].replace({0:\"Electricity\",1:\"ChilledWater\",2:\"Steam\",3:\"HotWater\"},inplace=True)\n",
    "test['meter'].replace({0:\"Electricity\",1:\"ChilledWater\",2:\"Steam\",3:\"HotWater\"},inplace=True)\n",
    "\n",
    "metadata[\"floor_count\"].fillna(int(metadata[\"floor_count\"].mean()), inplace=True)\n",
    "\n",
    "for df in [train, test]:\n",
    "    df['Month'] = df['timestamp'].dt.month.astype(\"uint8\")\n",
    "    df['DayOfMonth'] = df['timestamp'].dt.day.astype(\"uint8\")\n",
    "    df['DayOfWeek'] = df['timestamp'].dt.dayofweek.astype(\"uint8\")\n",
    "    df['Hour'] = df['timestamp'].dt.hour.astype(\"uint8\")\n",
    "    \n",
    "train['meter_reading'] = np.log1p(train['meter_reading'])\n",
    "\n",
    "metadata['primary_use'].replace({\"Healthcare\":\"Other\",\"Parking\":\"Other\",\"Warehouse/storage\":\"Other\",\"Manufacturing/industrial\":\"Other\",\n",
    "                                \"Retail\":\"Other\",\"Services\":\"Other\",\"Technology/science\":\"Other\",\"Food sales and service\":\"Other\",\n",
    "                                \"Utility\":\"Other\",\"Religious worship\":\"Other\"},inplace=True)\n",
    "metadata['square_feet'] = np.log1p(metadata['square_feet'])\n",
    "metadata['year_built'].fillna(int(metadata[\"year_built\"].mean()), inplace=True)\n",
    "metadata['year_built'] = metadata['year_built'].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.8 s, sys: 14.3 s, total: 41.1 s\n",
      "Wall time: 41.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.merge(train,metadata,on='building_id',how='left')\n",
    "test  = pd.merge(test,metadata,on='building_id',how='left')\n",
    "gc.collect()\n",
    "train = pd.merge(train,weather_train,on=['site_id','timestamp'],how='left')\n",
    "test  = pd.merge(test,weather_test,on=['site_id','timestamp'],how='left')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save space\n",
    "for df in [train,test]:\n",
    "    df['square_feet'] = df['square_feet'].astype('float16')\n",
    "    \n",
    "# Fill NA\n",
    "cols = ['air_temperature','cloud_coverage','dew_temperature','precip_depth_1_hr','sea_level_pressure','wind_speed', \"wind_direction\"]\n",
    "for col in cols:\n",
    "    train[col].fillna(train[col].mean(),inplace=True)\n",
    "    test[col].fillna(test[col].mean(),inplace=True)\n",
    "    \n",
    "# Drop nonsense entries\n",
    "# As per the discussion in the following thread, https://www.kaggle.com/c/ashrae-energy-prediction/discussion/117083, there is some discrepancy in the meter_readings for different ste_id's and buildings. It makes sense to delete them\n",
    "idx_to_drop = list((train[(train['site_id'] == 0) & (train['timestamp'] < \"2016-05-21 00:00:00\")]).index)\n",
    "train.drop(idx_to_drop,axis='rows',inplace=True)\n",
    "\n",
    "# dropping all the electricity meter readings that are 0, after considering them as anomalies.\n",
    "idx_to_drop = list(train[(train['meter'] == \"Electricity\") & (train['meter_reading'] == 0)].index)\n",
    "train.drop(idx_to_drop,axis='rows',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 20.7 s, total: 2min 1s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mean_temperature_per_site = train.groupby(\"site_id\")[\"air_temperature\"].mean()\n",
    "train[\"mean_temperature_per_site\"] = train[\"site_id\"].map(mean_temperature_per_site)\n",
    "test[\"mean_temperature_per_site\"] = test[\"site_id\"].map(mean_temperature_per_site)\n",
    "\n",
    "number_unique_meter_per_building = train.groupby('building_id')['meter'].nunique()\n",
    "train['number_unique_meter_per_building'] = train['building_id'].map(number_unique_meter_per_building)\n",
    "\n",
    "mean_meter_reading_per_building = train.groupby('building_id')['meter_reading'].mean()\n",
    "train['mean_meter_reading_per_building'] = train['building_id'].map(mean_meter_reading_per_building)\n",
    "median_meter_reading_per_building = train.groupby('building_id')['meter_reading'].median()\n",
    "train['median_meter_reading_per_building'] = train['building_id'].map(median_meter_reading_per_building)\n",
    "std_meter_reading_per_building = train.groupby('building_id')['meter_reading'].std()\n",
    "train['std_meter_reading_per_building'] = train['building_id'].map(std_meter_reading_per_building)\n",
    "\n",
    "mean_meter_reading_on_year_built = train.groupby('year_built')['meter_reading'].mean()\n",
    "train['mean_meter_reading_on_year_built'] = train['year_built'].map(mean_meter_reading_on_year_built)\n",
    "median_meter_reading_on_year_built = train.groupby('year_built')['meter_reading'].median()\n",
    "train['median_meter_reading_on_year_built'] = train['year_built'].map(median_meter_reading_on_year_built)\n",
    "std_meter_reading_on_year_built = train.groupby('year_built')['meter_reading'].std()\n",
    "train['std_meter_reading_on_year_built'] = train['year_built'].map(std_meter_reading_on_year_built)\n",
    "\n",
    "mean_meter_reading_per_meter = train.groupby('meter')['meter_reading'].mean()\n",
    "train['mean_meter_reading_per_meter'] = train['meter'].map(mean_meter_reading_per_meter)\n",
    "median_meter_reading_per_meter = train.groupby('meter')['meter_reading'].median()\n",
    "train['median_meter_reading_per_meter'] = train['meter'].map(median_meter_reading_per_meter)\n",
    "std_meter_reading_per_meter = train.groupby('meter')['meter_reading'].std()\n",
    "train['std_meter_reading_per_meter'] = train['meter'].map(std_meter_reading_per_meter)\n",
    "\n",
    "mean_meter_reading_per_primary_usage = train.groupby('primary_use')['meter_reading'].mean()\n",
    "train['mean_meter_reading_per_primary_usage'] = train['primary_use'].map(mean_meter_reading_per_primary_usage)\n",
    "median_meter_reading_per_primary_usage = train.groupby('primary_use')['meter_reading'].median()\n",
    "train['median_meter_reading_per_primary_usage'] = train['primary_use'].map(median_meter_reading_per_primary_usage)\n",
    "std_meter_reading_per_primary_usage = train.groupby('primary_use')['meter_reading'].std()\n",
    "train['std_meter_reading_per_primary_usage'] = train['primary_use'].map(std_meter_reading_per_primary_usage)\n",
    "\n",
    "mean_meter_reading_per_site_id = train.groupby('site_id')['meter_reading'].mean()\n",
    "train['mean_meter_reading_per_site_id'] = train['site_id'].map(mean_meter_reading_per_site_id)\n",
    "median_meter_reading_per_site_id = train.groupby('site_id')['meter_reading'].median()\n",
    "train['median_meter_reading_per_site_id'] = train['site_id'].map(median_meter_reading_per_site_id)\n",
    "std_meter_reading_per_site_id = train.groupby('site_id')['meter_reading'].std()\n",
    "train['std_meter_reading_per_site_id'] = train['site_id'].map(std_meter_reading_per_site_id)\n",
    "\n",
    "\n",
    "test['number_unique_meter_per_building'] = test['building_id'].map(number_unique_meter_per_building)\n",
    "\n",
    "test['mean_meter_reading_per_building'] = test['building_id'].map(mean_meter_reading_per_building)\n",
    "test['median_meter_reading_per_building'] = test['building_id'].map(median_meter_reading_per_building)\n",
    "test['std_meter_reading_per_building'] = test['building_id'].map(std_meter_reading_per_building)\n",
    "\n",
    "test['mean_meter_reading_on_year_built'] = test['year_built'].map(mean_meter_reading_on_year_built)\n",
    "test['median_meter_reading_on_year_built'] = test['year_built'].map(median_meter_reading_on_year_built)\n",
    "test['std_meter_reading_on_year_built'] = test['year_built'].map(std_meter_reading_on_year_built)\n",
    "\n",
    "test['mean_meter_reading_per_meter'] = test['meter'].map(mean_meter_reading_per_meter)\n",
    "test['median_meter_reading_per_meter'] = test['meter'].map(median_meter_reading_per_meter)\n",
    "test['std_meter_reading_per_meter'] = test['meter'].map(std_meter_reading_per_meter)\n",
    "\n",
    "test['mean_meter_reading_per_primary_usage'] = test['primary_use'].map(mean_meter_reading_per_primary_usage)\n",
    "test['median_meter_reading_per_primary_usage'] = test['primary_use'].map(median_meter_reading_per_primary_usage)\n",
    "test['std_meter_reading_per_primary_usage'] = test['primary_use'].map(std_meter_reading_per_primary_usage)\n",
    "\n",
    "test['mean_meter_reading_per_site_id'] = test['site_id'].map(mean_meter_reading_per_site_id)\n",
    "test['median_meter_reading_per_site_id'] = test['site_id'].map(median_meter_reading_per_site_id)\n",
    "test['std_meter_reading_per_site_id'] = test['site_id'].map(std_meter_reading_per_site_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.58 s, sys: 5.52 s, total: 14.1 s\n",
      "Wall time: 14.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "for df in [train, test]:\n",
    "    df['mean_temperature_per_site'] = df['mean_temperature_per_site'].astype(\"float16\")\n",
    "    \n",
    "    df['mean_meter_reading_per_building'] = df['mean_meter_reading_per_building'].astype(\"float16\")\n",
    "    df['median_meter_reading_per_building'] = df['mean_meter_reading_per_building'].astype(\"float16\")\n",
    "    df['std_meter_reading_per_building'] = df['std_meter_reading_per_building'].astype(\"float16\")\n",
    "    \n",
    "    df['mean_meter_reading_on_year_built'] = df['mean_meter_reading_on_year_built'].astype(\"float16\")\n",
    "    df['median_meter_reading_on_year_built'] = df['median_meter_reading_on_year_built'].astype(\"float16\")\n",
    "    df['std_meter_reading_on_year_built'] = df['std_meter_reading_on_year_built'].astype(\"float16\")\n",
    "    \n",
    "    df['mean_meter_reading_per_meter'] = df['mean_meter_reading_per_meter'].astype(\"float16\")\n",
    "    df['median_meter_reading_per_meter'] = df['median_meter_reading_per_meter'].astype(\"float16\")\n",
    "    df['std_meter_reading_per_meter'] = df['std_meter_reading_per_meter'].astype(\"float16\")\n",
    "    \n",
    "    df['mean_meter_reading_per_primary_usage'] = df['mean_meter_reading_per_primary_usage'].astype(\"float16\")\n",
    "    df['median_meter_reading_per_primary_usage'] = df['median_meter_reading_per_primary_usage'].astype(\"float16\")\n",
    "    df['std_meter_reading_per_primary_usage'] = df['std_meter_reading_per_primary_usage'].astype(\"float16\")\n",
    "    \n",
    "    df['mean_meter_reading_per_site_id'] = df['mean_meter_reading_per_site_id'].astype(\"float16\")\n",
    "    df['median_meter_reading_per_site_id'] = df['median_meter_reading_per_site_id'].astype(\"float16\")\n",
    "    df['std_meter_reading_per_site_id'] = df['std_meter_reading_per_site_id'].astype(\"float16\")\n",
    "    \n",
    "    df['number_unique_meter_per_building'] = df['number_unique_meter_per_building'].astype('uint8')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19637651, 36) (41697600, 35)\n"
     ]
    }
   ],
   "source": [
    "train.drop('timestamp',axis=1,inplace=True)\n",
    "test.drop('timestamp',axis=1,inplace=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "train['meter']= le.fit_transform(train['meter']).astype(\"uint8\")\n",
    "test['meter']= le.fit_transform(test['meter']).astype(\"uint8\")\n",
    "train['primary_use']= le.fit_transform(train['primary_use']).astype(\"uint8\")\n",
    "test['primary_use']= le.fit_transform(test['primary_use']).astype(\"uint8\")\n",
    "\n",
    "print (train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 columns to remove.\n",
      "Following columns can be dropped ['site_id', 'median_meter_reading_per_building', 'median_meter_reading_on_year_built', 'median_meter_reading_per_meter', 'median_meter_reading_per_primary_usage', 'median_meter_reading_per_site_id']\n",
      "CPU times: user 1min 2s, sys: 3.7 s, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Let's check the correlation between the variables and eliminate the one's that have high correlation\n",
    "# Threshold for removing correlated variables\n",
    "threshold = 0.90\n",
    "\n",
    "# Absolute value correlation matrix\n",
    "corr_matrix = train.corr().abs()\n",
    "# Upper triangle of correlations\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Select columns with correlations above threshold\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "print('There are %d columns to remove.' % (len(to_drop)))\n",
    "print (\"Following columns can be dropped {}\".format(to_drop))\n",
    "\n",
    "train.drop(to_drop,axis=1,inplace=True)\n",
    "test.drop(to_drop,axis=1,inplace=True)\n",
    "\n",
    "y = train['meter_reading']\n",
    "train.drop('meter_reading',axis=1,inplace=True)\n",
    "categorical_cols = ['building_id','Month','meter','Hour','primary_use','DayOfWeek','DayOfMonth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18655768, 29)\n",
      "(981883, 29)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(train,y,test_size=0.05,random_state=573)\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.802427\tvalid_1's rmse: 0.803498\n",
      "[200]\ttraining's rmse: 0.746415\tvalid_1's rmse: 0.749013\n",
      "[300]\ttraining's rmse: 0.71158\tvalid_1's rmse: 0.714965\n",
      "[400]\ttraining's rmse: 0.689126\tvalid_1's rmse: 0.693335\n",
      "[500]\ttraining's rmse: 0.669897\tvalid_1's rmse: 0.6747\n",
      "[600]\ttraining's rmse: 0.654201\tvalid_1's rmse: 0.659538\n",
      "[700]\ttraining's rmse: 0.639582\tvalid_1's rmse: 0.645291\n",
      "[800]\ttraining's rmse: 0.62621\tvalid_1's rmse: 0.63245\n",
      "[900]\ttraining's rmse: 0.615762\tvalid_1's rmse: 0.622587\n",
      "[1000]\ttraining's rmse: 0.607955\tvalid_1's rmse: 0.615385\n",
      "[1100]\ttraining's rmse: 0.600686\tvalid_1's rmse: 0.608677\n",
      "[1200]\ttraining's rmse: 0.592918\tvalid_1's rmse: 0.601222\n",
      "[1300]\ttraining's rmse: 0.586551\tvalid_1's rmse: 0.595283\n",
      "[1400]\ttraining's rmse: 0.581517\tvalid_1's rmse: 0.590734\n",
      "[1500]\ttraining's rmse: 0.576275\tvalid_1's rmse: 0.586\n",
      "[1600]\ttraining's rmse: 0.571396\tvalid_1's rmse: 0.581713\n",
      "[1700]\ttraining's rmse: 0.566512\tvalid_1's rmse: 0.577451\n",
      "[1800]\ttraining's rmse: 0.562311\tvalid_1's rmse: 0.573657\n",
      "[1900]\ttraining's rmse: 0.558133\tvalid_1's rmse: 0.569885\n",
      "[2000]\ttraining's rmse: 0.554206\tvalid_1's rmse: 0.566454\n",
      "[2100]\ttraining's rmse: 0.550373\tvalid_1's rmse: 0.563196\n",
      "[2200]\ttraining's rmse: 0.546673\tvalid_1's rmse: 0.559908\n",
      "[2300]\ttraining's rmse: 0.543429\tvalid_1's rmse: 0.5571\n",
      "[2400]\ttraining's rmse: 0.539873\tvalid_1's rmse: 0.553947\n",
      "[2500]\ttraining's rmse: 0.536515\tvalid_1's rmse: 0.551154\n",
      "[2600]\ttraining's rmse: 0.533502\tvalid_1's rmse: 0.548658\n",
      "[2700]\ttraining's rmse: 0.530797\tvalid_1's rmse: 0.546388\n",
      "[2800]\ttraining's rmse: 0.527828\tvalid_1's rmse: 0.543885\n",
      "[2900]\ttraining's rmse: 0.525065\tvalid_1's rmse: 0.541694\n",
      "[3000]\ttraining's rmse: 0.52253\tvalid_1's rmse: 0.539677\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.52253\tvalid_1's rmse: 0.539677\n",
      "CPU times: user 2h 29min 12s, sys: 18.7 s, total: 2h 29min 30s\n",
      "Wall time: 39min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_cols)\n",
    "lgb_test = lgb.Dataset(x_test, y_test, categorical_feature=categorical_cols)\n",
    "del x_train, x_test , y_train, y_test\n",
    "\n",
    "params = {'feature_fraction': 0.8,\n",
    "          'bagging_fraction': 0.7,\n",
    "          'objective': 'regression',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.1,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 321,\n",
    "          \"metric\": 'rmse',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 1,\n",
    "          'reg_lambda': 2,\n",
    "          'random_state': 123,\n",
    "          'num_leaves': 70\n",
    "         }\n",
    "\n",
    "reg = lgb.train(params, lgb_train, num_boost_round=3000, valid_sets=[lgb_train, lgb_test], early_stopping_rounds=100, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 30min 55s, sys: 15.3 s, total: 4h 31min 10s\n",
      "Wall time: 1h 9min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "del train, y, lgb_train\n",
    "predictions = []\n",
    "step = 50000\n",
    "for i in range(0, len(test), step):\n",
    "    predictions.extend(np.expm1(reg.predict(test.iloc[i: min(i+step, len(test)), :], num_iteration=reg.best_iteration)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 21s, sys: 3.21 s, total: 4min 25s\n",
      "Wall time: 4min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Submission = pd.DataFrame(test.index,columns=['row_id'])\n",
    "Submission['meter_reading'] = predictions\n",
    "Submission['meter_reading'].clip(lower=0,upper=None,inplace=True)\n",
    "Submission.to_csv(\"lgbm.csv\",index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
