{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.offline as py\n",
    "\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "from IPython.core.display import display, HTML\n",
    "from plotly import tools, subplots\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "py.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true, y_pred):\n",
    "    return mean_squared_error(np.log1p(y_true), np.log1p(y_pred))**(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prior Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_STACKING = False\n",
    "USE_HYPEROPT = False\n",
    "USE_GENETIC_ALG = True\n",
    "EXCLUDE_LIST =[\n",
    "    'bland-nn-on-pp-leaks-train-fe_version3',\n",
    "    'bland-lgbt-on-leaks_version1',\n",
    "    'bland-lgbt-on-leaks_version2',\n",
    "    'ashrae-exploiting-leak-site-5',\n",
    "    'ashrae-1-1-to-1-06-with-ucl',\n",
    "    'ashrae-divide-and-conquer-fix0'\n",
    "               ]\n",
    "\n",
    "ADD_LIST = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce MEM usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "# Modified to support timestamp type, categorical type\n",
    "# Modified to add option to use float16 or not. feather format does not support float16.\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            # skip datetime type or categorical type\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD Leak data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n"
     ]
    }
   ],
   "source": [
    "leak_df = reduce_mem_usage(pd.read_csv('/kaggle/input/leakaggregator/leaked_test_target.csv'))\n",
    "\n",
    "not_nan_values_in_leak_df = ~leak_df['meter_reading'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.710775\n",
       "True     0.289225\n",
       "Name: meter_reading, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_nan_values_in_leak_df.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>173.370300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53.512718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.143042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>101.701469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1141.240723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  meter_reading\n",
       "0       0     173.370300\n",
       "1       1      53.512718\n",
       "2       2       6.143042\n",
       "3       3     101.701469\n",
       "4       4    1141.240723"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leak_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_to_take = [\n",
    "    '/kaggle/input/ashrae-submissions/*.csv',\n",
    "    '/kaggle/input/ashrae-submissions-1/*.csv',\n",
    "    '/kaggle/input/ashrae-submissions-2/*.csv',\n",
    "    '/kaggle/input/ashrae-submissions-3/*.csv',\n",
    "    '/kaggle/input/ashrae-submissions-4/*.csv',\n",
    "    '/kaggle/input/ashrae-submissions-5/*.csv',\n",
    "    '/kaggle/input/ashrae-submissions-6/*.csv'\n",
    "]\n",
    "\n",
    "files_to_take = []\n",
    "for dtt in datasets_to_take:\n",
    "    files_to_take += glob(dtt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXCLUDE MODE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: TqdmDeprecationWarning:\n",
      "\n",
      "This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f95a30bbd148f0a38365927ff60810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ashrae-submissions/bland-lgbt-folds_version_1.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions/ashrae-half-and-half.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions/ashrae-highway-kernel-route4.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions/ashrae-kfold-lightgbm-without-leak-1-08.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions/bland-lgbt-folds_version_2.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions/pp-lgbt-refactored_version_7.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions/pp-lgbt-refactored_version_5.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions/pp-lgbt-refactored_version_3.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-1/another-1-08-lb-no-leak.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-1/ashrae-stacked-regression-lasso-ridge-lgbm.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-1/ashrae-simple-data-cleanup-lb-1-08-no-leaks.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-1/new-ucf-starter-kernel.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-2/ashrae-energy-prediction-using-stratified-kfold.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-2/bland-lgbt-on-pp-leaks-train-fe_version1.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-2/ashrae-lightgbm-without-leak-data.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-3/bland-nn-on-pp-leaks-train-fe_version1.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-3/Bland LGBT on PP  Leaks Train  FE_version4.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-3/Bland LGBT on PP  Leaks Train  FE_version3.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-3/bland-nn-on-pp-leaks-train-fe_version2.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-3/Bland LGBT on PP  Leaks Train  FE_version2.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-4/bland-nn-on-pp-leaks-train-fe_version4.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-5/bland-lgbt-on-leaks_version3.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-5/bland-lgbt-on-pp-leaks-train-fe_version5.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-5/bland-lgbt-on-pp-leaks-train-fe_version6.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-6/bland-nn-on-pp-leaks-train-fe_version6.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "/kaggle/input/ashrae-submissions-6/bland-nn-on-pp-leaks-train-fe_version7.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 318.13 MB\n",
      "Decreased by 50.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_sumbissions = pd.DataFrame()\n",
    "all_sumbissions['row_id'] = leak_df['row_id']\n",
    "\n",
    "if ADD_LIST:\n",
    "    print('ADD MODE')\n",
    "    for df_name in tqdm(files_to_take):\n",
    "        if os.path.basename(df_name).split('.')[0] in ADD_LIST:\n",
    "            print(df_name)\n",
    "            all_sumbissions[os.path.basename(df_name).split('.')[0]] = reduce_mem_usage(pd.read_csv(df_name)).sort_values('row_id')['meter_reading']\n",
    "            gc.collect()\n",
    "else:\n",
    "    print('EXCLUDE MODE')\n",
    "    for df_name in tqdm(files_to_take):\n",
    "        if os.path.basename(df_name).split('.')[0] in EXCLUDE_LIST:\n",
    "            continue\n",
    "        print(df_name)\n",
    "        all_sumbissions[os.path.basename(df_name).split('.')[0]] = reduce_mem_usage(pd.read_csv(df_name)).sort_values('row_id')['meter_reading']\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_id', 'bland-lgbt-folds_version_1', 'ashrae-half-and-half',\n",
       "       'ashrae-highway-kernel-route4',\n",
       "       'ashrae-kfold-lightgbm-without-leak-1-08', 'bland-lgbt-folds_version_2',\n",
       "       'pp-lgbt-refactored_version_7', 'pp-lgbt-refactored_version_5',\n",
       "       'pp-lgbt-refactored_version_3', 'another-1-08-lb-no-leak',\n",
       "       'ashrae-stacked-regression-lasso-ridge-lgbm',\n",
       "       'ashrae-simple-data-cleanup-lb-1-08-no-leaks', 'new-ucf-starter-kernel',\n",
       "       'ashrae-energy-prediction-using-stratified-kfold',\n",
       "       'bland-lgbt-on-pp-leaks-train-fe_version1',\n",
       "       'ashrae-lightgbm-without-leak-data',\n",
       "       'bland-nn-on-pp-leaks-train-fe_version1',\n",
       "       'Bland LGBT on PP  Leaks Train  FE_version4',\n",
       "       'Bland LGBT on PP  Leaks Train  FE_version3',\n",
       "       'bland-nn-on-pp-leaks-train-fe_version2',\n",
       "       'Bland LGBT on PP  Leaks Train  FE_version2',\n",
       "       'bland-nn-on-pp-leaks-train-fe_version4',\n",
       "       'bland-lgbt-on-leaks_version3',\n",
       "       'bland-lgbt-on-pp-leaks-train-fe_version5',\n",
       "       'bland-lgbt-on-pp-leaks-train-fe_version6',\n",
       "       'bland-nn-on-pp-leaks-train-fe_version6',\n",
       "       'bland-nn-on-pp-leaks-train-fe_version7'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sumbissions.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in all_sumbissions.columns[all_sumbissions.min() < 0]:\n",
    "    all_sumbissions.loc[all_sumbissions[col] < 0, col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leak Validation for public kernels(not used leak data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bland-lgbt-folds_version_1\n",
      "score1= 0.9741138735243069\n",
      "ashrae-half-and-half\n",
      "score1= 1.00535324844152\n",
      "ashrae-highway-kernel-route4\n",
      "score1= 0.9965969535013234\n",
      "ashrae-kfold-lightgbm-without-leak-1-08\n",
      "score1= 0.9854716897862866\n",
      "bland-lgbt-folds_version_2\n",
      "score1= 0.9754504777039272\n",
      "pp-lgbt-refactored_version_7\n",
      "score1= 0.9711899026175357\n",
      "pp-lgbt-refactored_version_5\n",
      "score1= 0.9825898589957469\n",
      "pp-lgbt-refactored_version_3\n",
      "score1= 0.9755424054488605\n",
      "another-1-08-lb-no-leak\n",
      "score1= 0.9826493653965951\n",
      "ashrae-stacked-regression-lasso-ridge-lgbm\n",
      "score1= 1.020556464244743\n",
      "ashrae-simple-data-cleanup-lb-1-08-no-leaks\n",
      "score1= 0.9942115503578347\n",
      "new-ucf-starter-kernel\n",
      "score1= 0.9155438800589935\n",
      "ashrae-energy-prediction-using-stratified-kfold\n",
      "score1= 0.9738057096849434\n",
      "bland-lgbt-on-pp-leaks-train-fe_version1\n",
      "score1= 0.973867956173972\n",
      "ashrae-lightgbm-without-leak-data\n",
      "score1= 0.9971452436397115\n",
      "bland-nn-on-pp-leaks-train-fe_version1\n",
      "score1= 0.9934921997889125\n",
      "Bland LGBT on PP  Leaks Train  FE_version4\n",
      "score1= 0.982542330143042\n",
      "Bland LGBT on PP  Leaks Train  FE_version3\n",
      "score1= 0.9825721458950141\n",
      "bland-nn-on-pp-leaks-train-fe_version2\n",
      "score1= 0.993966587623784\n",
      "Bland LGBT on PP  Leaks Train  FE_version2\n",
      "score1= 0.9739801367020869\n",
      "bland-nn-on-pp-leaks-train-fe_version4\n",
      "score1= 0.9725300350797567\n",
      "bland-lgbt-on-leaks_version3\n",
      "score1= 0.9737529164026975\n",
      "bland-lgbt-on-pp-leaks-train-fe_version5\n",
      "score1= 0.982542330143042\n",
      "bland-lgbt-on-pp-leaks-train-fe_version6\n",
      "score1= 0.9725862960478315\n",
      "bland-nn-on-pp-leaks-train-fe_version6\n",
      "score1= 0.9719653452496032\n",
      "bland-nn-on-pp-leaks-train-fe_version7\n",
      "score1= 0.9701992392664978\n"
     ]
    }
   ],
   "source": [
    "for col in all_sumbissions.columns[1:]:\n",
    "    print(col)\n",
    "    leak_score = metric(leak_df.loc[not_nan_values_in_leak_df, 'meter_reading'],\n",
    "                        all_sumbissions.loc[not_nan_values_in_leak_df, col])\n",
    "    print ('score1=', leak_score)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score= 0.9599516859413998\n"
     ]
    }
   ],
   "source": [
    "leak_score = metric(leak_df.loc[not_nan_values_in_leak_df, 'meter_reading'], all_sumbissions.loc[not_nan_values_in_leak_df].iloc[:,1:].mean(axis=1))\n",
    "print ('mean score=', leak_score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean score= 0.961676894639849\n"
     ]
    }
   ],
   "source": [
    "leak_score = metric(leak_df.loc[not_nan_values_in_leak_df, 'meter_reading'], all_sumbissions.loc[not_nan_values_in_leak_df].iloc[:,1:].median(axis=1))\n",
    "print ('mean score=', leak_score) # 0.963450549517071"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Alg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "class GenerativeAlgorithm(object):\n",
    "    def __init__(self, \n",
    "                 x_shape,\n",
    "                 amout_ind_to_mutate,\n",
    "                 population_size, \n",
    "                 target_function, \n",
    "                 num_generations, \n",
    "                 populations_to_take,\n",
    "                 available_indices,\n",
    "                 mode='min'):\n",
    "        self.amout_ind_to_mutate = amout_ind_to_mutate\n",
    "        self.x_shape = x_shape\n",
    "        self.population_size = population_size\n",
    "        self.target_function = target_function\n",
    "        self.num_generations = num_generations\n",
    "        self.populations_to_take = populations_to_take\n",
    "        self.available_indices = available_indices\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.gen_initial_generation()\n",
    "        \n",
    "        if self.mode == 'min':\n",
    "            self.best_score = 1000000\n",
    "        if self.mode == 'max':\n",
    "            self.best_score = -1000000\n",
    "            \n",
    "    def gen_initial_generation(self):\n",
    "        self.initial_generation = []\n",
    "        for i, el in enumerate(permutations(self.available_indices, self.x_shape)):\n",
    "            if i == self.population_size:\n",
    "                break\n",
    "            self.initial_generation.append(list(el))\n",
    "\n",
    "        self.initial_generation = np.array(self.initial_generation)\n",
    "        \n",
    "    def select_mating_pool(self, population, fitness):\n",
    "        \n",
    "        parents = np.empty((self.populations_to_take, population.shape[1]))\n",
    "\n",
    "        for parent_num in range(self.populations_to_take):\n",
    "            \n",
    "            if self.mode == 'min':\n",
    "                fitness_idx = np.argmin(fitness)\n",
    "            elif self.mode == 'max':\n",
    "                fitness_idx = np.argmax(fitness)\n",
    "            else:\n",
    "                raise ValueError('Not implemented!')\n",
    "                \n",
    "            parents[parent_num, :] = population[fitness_idx, :]\n",
    "            \n",
    "                        \n",
    "            if self.mode == 'min':\n",
    "                fitness[fitness_idx] = 1000000\n",
    "            elif self.mode == 'max':\n",
    "                fitness[fitness_idx] = - 1000000\n",
    "\n",
    "        return parents\n",
    "    \n",
    "    def crossover(self, parents, offspring_size):\n",
    "        offspring = np.empty(offspring_size)\n",
    "        crossover_point = np.uint8(offspring_size[1]/2)\n",
    "\n",
    "        for k in range(offspring_size[0]):\n",
    "            parent1_idx = np.random.randint(0, parents.shape[0])\n",
    "            parent2_idx = np.random.randint(0, parents.shape[0])\n",
    "\n",
    "            offspring[k, :crossover_point] = parents[parent1_idx, :crossover_point]\n",
    "            offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "            \n",
    "        return offspring\n",
    "\n",
    "    def mutation(self, offspring_crossover):\n",
    "\n",
    "        for idx in range(offspring_crossover.shape[0]):\n",
    "            \n",
    "            \n",
    "            for i in range(self.amout_ind_to_mutate):\n",
    "                cur_available_idices = list(set(self.available_indices) - set(offspring_crossover[idx,:]))\n",
    "                \n",
    "                value = np.random.choice(cur_available_idices)\n",
    "                idx_1 = np.random.randint(0,offspring_crossover.shape[1])\n",
    "            \n",
    "                offspring_crossover[idx, idx_1] = value\n",
    "                                \n",
    "        return offspring_crossover\n",
    "\n",
    "    def apply_function_on_array(self, ar):\n",
    "        return np.array([self.target_function(ar[i,:]) for i in range(ar.shape[0])])\n",
    "\n",
    "    def fit(self):\n",
    "        cur_population = self.initial_generation\n",
    "        history = {'best_points':[], 'best_fits':[]}\n",
    "        generation = 0\n",
    "        \n",
    "        while generation < self.num_generations:\n",
    "\n",
    "            fitness = self.apply_function_on_array(cur_population)\n",
    "                        \n",
    "            if self.mode == 'min':\n",
    "                best_idx = np.argmin(fitness)\n",
    "            elif self.mode == 'max':\n",
    "                best_idx = np.argmax(fitness)\n",
    "                \n",
    "            history['best_points'].append(cur_population[best_idx,:])\n",
    "            history['best_fits'].append(fitness[best_idx])\n",
    "            self.best_score = fitness[best_idx]\n",
    "            \n",
    "            print('Itteration {} best score: {}'.format(generation, self.best_score))\n",
    "            \n",
    "            parents = self.select_mating_pool(cur_population, fitness)\n",
    "            \n",
    "            offspring_crossover = self.crossover(parents,\n",
    "                                                 offspring_size=(self.population_size-parents.shape[0], cur_population.shape[1]))\n",
    "            \n",
    "            offspring_mutation = self.mutation(offspring_crossover)\n",
    "            \n",
    "            cur_population[:parents.shape[0], :] = parents\n",
    "            cur_population[parents.shape[0]:, :] = offspring_mutation\n",
    "                        \n",
    "            generation+=1 \n",
    "            \n",
    "        fitness = self.apply_function_on_array(cur_population)\n",
    "        \n",
    "        if self.mode == 'min':\n",
    "            best_idx = np.argmin(fitness)\n",
    "        elif self.mode == 'max':\n",
    "            best_idx == np.argmax(fitness)\n",
    "            \n",
    "        history['best_points'].append(cur_population[best_idx,:])\n",
    "        history['best_fits'].append(fitness[best_idx])\n",
    "            \n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itteration 0 best score: 0.9591404618849355\n",
      "Itteration 1 best score: 0.9572810878452788\n"
     ]
    }
   ],
   "source": [
    "if USE_GENETIC_ALG:\n",
    "    def tgt_f(col_idx):\n",
    "        sc = metric(leak_df.loc[not_nan_values_in_leak_df, 'meter_reading'], \n",
    "                                   all_sumbissions.loc[not_nan_values_in_leak_df].iloc[:,col_idx].median(axis=1))\n",
    "        return sc\n",
    "\n",
    "\n",
    "    a_ind = np.array(range(1, all_sumbissions.shape[1]-1))\n",
    "    \n",
    "    alg = GenerativeAlgorithm(\n",
    "    amout_ind_to_mutate=6,\n",
    "    population_size=20,\n",
    "    x_shape=11,\n",
    "    target_function=tgt_f, \n",
    "    num_generations=2, \n",
    "    populations_to_take=6,\n",
    "    available_indices=a_ind\n",
    "    )\n",
    "    \n",
    "    h = alg.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_comb: Index(['pp-lgbt-refactored_version_5', 'ashrae-half-and-half',\n",
      "       'ashrae-highway-kernel-route4',\n",
      "       'ashrae-kfold-lightgbm-without-leak-1-08', 'new-ucf-starter-kernel',\n",
      "       'bland-nn-on-pp-leaks-train-fe_version6',\n",
      "       'bland-nn-on-pp-leaks-train-fe_version2',\n",
      "       'pp-lgbt-refactored_version_3',\n",
      "       'bland-lgbt-on-pp-leaks-train-fe_version1',\n",
      "       'bland-lgbt-on-pp-leaks-train-fe_version6',\n",
      "       'ashrae-lightgbm-without-leak-data'],\n",
      "      dtype='object')\n",
      "best_metric: 0.9507548771306062\n"
     ]
    }
   ],
   "source": [
    "if USE_GENETIC_ALG:\n",
    "    best_cols = h['best_points'][-1]\n",
    "    \n",
    "    m = metric(leak_df.loc[not_nan_values_in_leak_df, 'meter_reading'], all_sumbissions.loc[not_nan_values_in_leak_df].iloc[:,best_cols].median(axis=1))\n",
    "    print('best_comb: {}\\nbest_metric: {}'.format(all_sumbissions.columns[best_cols], m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_HYPEROPT:\n",
    "    import hyperopt as hp\n",
    "    \n",
    "    score_comb = []\n",
    "    \n",
    "    def objective(x):\n",
    "        cols_idx = [el[1] for el in x]\n",
    "        \n",
    "        if len(set(cols_idx)) != len(cols_idx):\n",
    "            return 100\n",
    "        \n",
    "        m = metric(leak_df.loc[not_nan_values_in_leak_df, 'meter_reading'], all_sumbissions[not_nan_values_in_leak_df].iloc[:,cols_idx].median(axis=1))\n",
    "        gc.collect()\n",
    "        score_comb.append([cols_idx,m])\n",
    "        return m\n",
    "    \n",
    "    space = [(str(i),1 + hp.hp.randint(str(i), all_sumbissions.shape[1]-1)) for i in range(10)]\n",
    "\n",
    "    best = hp.fmin(objective, space, algo=hp.tpe.suggest, max_evals=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_HYPEROPT:\n",
    "    best_cols = pd.DataFrame(score_comb).sort_values(1).iloc[0,0]\n",
    "    \n",
    "    m = metric(leak_df.loc[not_nan_values_in_leak_df, 'meter_reading'], all_sumbissions.loc[not_nan_values_in_leak_df].iloc[:,best_cols].median(axis=1))\n",
    "    print('best_comb: {}\\nbest_metric: {}'.format(all_sumbissions.columns[best_cols], m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_STACKING:\n",
    "    for col in all_sumbissions.columns[1:]:\n",
    "        all_sumbissions[col] = np.log1p(all_sumbissions[col])\n",
    "\n",
    "    leak_df['meter_reading'] = np.log1p(leak_df['meter_reading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_STACKING:\n",
    "    all_sumbissions['target'] = leak_df['meter_reading']\n",
    "\n",
    "    del leak_df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_STACKING:\n",
    "    train = all_sumbissions[not_nan_values_in_leak_df]\n",
    "\n",
    "    test = all_sumbissions[~not_nan_values_in_leak_df]\n",
    "\n",
    "    del all_sumbissions\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_STACKING:\n",
    "    train = train.set_index('row_id')\n",
    "    test = test.set_index('row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNModel(object):\n",
    "    def __init__(self, model, target_variable='target'):\n",
    "        self.model = model\n",
    "        \n",
    "        self.es = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=EARLY_STOPPING, verbose=False, mode='auto', restore_best_weights=True)\n",
    "        self.rlr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, mode='auto', verbose=False)\n",
    "        \n",
    "        self.target_variable = target_variable\n",
    "        \n",
    "        self.scaling_stats = {}\n",
    "        self.predictors = ['bland-lgbt-folds_version_1', 'bland-lgbt-folds_version_2',\n",
    "       'pp-lgbt-refactored_version_7',\n",
    "       'bland-lgbt-on-pp-leaks-train-fe_version1',\n",
    "       'bland-nn-on-pp-leaks-train-fe_version1',\n",
    "       'Bland LGBT on PP  Leaks Train  FE_version4',\n",
    "       'bland-nn-on-pp-leaks-train-fe_version2',\n",
    "       'Bland LGBT on PP  Leaks Train  FE_version2']\n",
    "        \n",
    "    def train_preprocessing(self, data):\n",
    "\n",
    "        y = data[self.target_variable]\n",
    "        \n",
    "        data = data[self.predictors]\n",
    "        print(data.shape)\n",
    "        \n",
    "        for col in self.predictors:\n",
    "            self.scaling_stats[col] = {'mean':data[col].mean(), 'std':data[col].std()}\n",
    "            data[col] = (data[col] - self.scaling_stats[col]['mean']) / self.scaling_stats[col]['std']\n",
    "            \n",
    "        print(data.isna().sum().sum())\n",
    "        print('Scaling completed!')\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        return data.values, y.values\n",
    "    \n",
    "    def test_preprocessing(self, data, is_val=False):\n",
    "        \n",
    "        if is_val:\n",
    "            y = data[self.target_variable]\n",
    "            \n",
    "        data = data[self.predictors]\n",
    "        gc.collect()\n",
    "        \n",
    "        for col in self.predictors:\n",
    "            data[col] = (data[col] - self.scaling_stats[col]['mean']) / self.scaling_stats[col]['std']\n",
    "        \n",
    "        gc.collect()\n",
    "        if is_val:\n",
    "            return data.values, y.values\n",
    "        else:\n",
    "            return data.values\n",
    "        \n",
    "    def fit(self, data, data_val):\n",
    "        \n",
    "        data, y_train = self.train_preprocessing(data)\n",
    "        data_val, y_val = self.test_preprocessing(data_val, is_val=True)\n",
    "        \n",
    "        self.model.fit(\n",
    "            data, y_train, epochs=N_EPOCHS, batch_size=BATCH_SIZE, validation_data=(data_val, y_val), verbose=True, callbacks=[self.es, self.rlr]\n",
    "        )\n",
    "            \n",
    "    def predict(self, data):\n",
    "        \n",
    "        data = self.test_preprocessing(data, is_val=False)\n",
    "        \n",
    "        return self.model.predict(data, batch_size=BATCH_SIZE, verbose=True).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def time_val(data, model_create_func, metric_to_use=mean_squared_error, target_var_name='target', test_to_predict=None):\n",
    "    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "    print('Starting Validation')\n",
    "    results = []\n",
    "    data['pred'] = 0\n",
    "    if test_to_predict is not None:\n",
    "        test_prediction = []\n",
    "        \n",
    "    for train_idx, test_idx in kf.split(data):\n",
    "        print('New Itter')\n",
    "        model = model_create_func()\n",
    "        model.fit(data.iloc[train_idx].reset_index(drop=True), \n",
    "                  data.iloc[test_idx].reset_index(drop=True))\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        data['pred'].iloc[test_idx] = model.predict(data.iloc[test_idx].reset_index(drop=True))\n",
    "        \n",
    "        gc.collect()\n",
    "        itter_metric = metric_to_use(data.iloc[test_idx][target_var_name], data['pred'].iloc[test_idx])\n",
    "        print('Itter metric: '+str(itter_metric))\n",
    "        results.append(itter_metric)\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        if test_to_predict is not None:\n",
    "            test_prediction.append(model.predict(test_to_predict))\n",
    "        \n",
    "        gc.collect()\n",
    "     \n",
    "    if test_to_predict is not None:\n",
    "        return results, sum(test_prediction)/NUM_FOLDS\n",
    "    else:\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, Concatenate, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras import callbacks\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def create_model(inp_dim):\n",
    "    inps = Input(shape=(inp_dim,))\n",
    "    \n",
    "    x = Dense(1)(inps)\n",
    "    model = Model(inputs=inps, outputs=x)\n",
    "    model.compile(\n",
    "        optimizer=Nadam(lr=1e-3),\n",
    "        loss=root_mean_squared_error\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_STACKING:\n",
    "    NUM_FOLDS = 5\n",
    "    N_EPOCHS = 3\n",
    "    BATCH_SIZE = 256\n",
    "    EARLY_STOPPING = 2\n",
    "\n",
    "    my_model_create_f = lambda : NNModel(model = create_model(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_STACKING:\n",
    "    rf_res, test['target'] = time_val(train, my_model_create_f, test_to_predict=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_STACKING:\n",
    "    print('Result: {} +/- {}'.format(round(np.mean(rf_res),5), round(np.std(rf_res),5)))\n",
    "    print(mean_squared_error(train['pred'], train['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_STACKING:\n",
    "    train = train.rename(columns={'pred':'meter_reading'})\n",
    "    test = test.rename(columns={'target':'meter_reading'})\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    sub = pd.concat([train['meter_reading'], test['meter_reading']], axis=0)\n",
    "    sub = sub.reset_index()\n",
    "\n",
    "    sub['meter_reading'] = np.expm1(sub['meter_reading'])\n",
    "    sub.loc[sub['meter_reading'] < 0, 'meter_reading'] = 0\n",
    "\n",
    "    sub = sub.sort_values('row_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GENETIC_ALG or USE_HYPEROPT:\n",
    "    all_sumbissions['meter_reading'] = all_sumbissions.iloc[:,best_cols].median(axis=1)\n",
    "    all_sumbissions = all_sumbissions[['row_id','meter_reading']]\n",
    "    gc.collect()\n",
    "    all_sumbissions[['row_id','meter_reading']].to_csv('submission_blend.csv', index=False)\n",
    "elif USE_STACKING:\n",
    "    sub.to_csv('submission_blend.csv', index=False)\n",
    "else:\n",
    "    raise ValueError('Not ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "502cf08ef91649c6a844d372533adece": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "6077a4d6ff6f4eb9b5d342a5a8081ec3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_61ff1cc88e1548a5a5af24bc9be7f50a",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_d8a199054ce941d9acef8baceaa178d8",
       "value": " 32/32 [07:21&lt;00:00, 13.81s/it]"
      }
     },
     "61ff1cc88e1548a5a5af24bc9be7f50a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "84ff079023324532bd5a40d29d47a8b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a5f95a30bbd148f0a38365927ff60810": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dc779c5c70314abeb1e09a7a1e4f0538",
        "IPY_MODEL_6077a4d6ff6f4eb9b5d342a5a8081ec3"
       ],
       "layout": "IPY_MODEL_cbaa0e288f034b2aaad5c37fbcd6752a"
      }
     },
     "cbaa0e288f034b2aaad5c37fbcd6752a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8a199054ce941d9acef8baceaa178d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dc779c5c70314abeb1e09a7a1e4f0538": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_84ff079023324532bd5a40d29d47a8b9",
       "max": 32,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_502cf08ef91649c6a844d372533adece",
       "value": 32
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
