{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5add4be9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-13T12:05:18.364775Z",
     "iopub.status.busy": "2025-03-13T12:05:18.364537Z",
     "iopub.status.idle": "2025-03-13T12:05:24.118662Z",
     "shell.execute_reply": "2025-03-13T12:05:24.117585Z"
    },
    "papermill": {
     "duration": 5.75855,
     "end_time": "2025-03-13T12:05:24.120228",
     "exception": false,
     "start_time": "2025-03-13T12:05:18.361678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training features count: 25\n",
      "Testing features count: 23\n",
      "Common features count: 23\n",
      "NaN values in test data before processing: 5\n",
      "Filling NaN values with column means\n",
      "Using input dimension: 23\n",
      "Normalized race mapping: {'more than one race': 'More_than_one_race', 'asian': 'Asian', 'white': 'White', 'american indian or alaska native': 'American_Indian_or_Alaska_Native', 'native hawaiian or other pacific islander': 'Native_Hawaiian_or_other_Pacific_Islander', 'black or african american': 'Black_or_African-American'}\n",
      "Using race-specific models based on 'race_group' column\n",
      "Unique normalized races in test data: ['more than one race' 'asian']\n",
      "Patients by race: normalized_race\n",
      "more than one race    2\n",
      "asian                 1\n",
      "Name: count, dtype: int64\n",
      "Processing More_than_one_race model (normalized: more than one race)...\n",
      "Found 2 patients matching 'More_than_one_race'\n",
      "Made predictions for 2 patients of More_than_one_race race\n",
      "Sample predictions: [-0.07788242  0.15458201]\n",
      "Processing Asian model (normalized: asian)...\n",
      "Found 1 patients matching 'Asian'\n",
      "Made predictions for 1 patients of Asian race\n",
      "Sample predictions: [-0.30814743]\n",
      "Processing White model (normalized: white)...\n",
      "No patients found for race: White\n",
      "Processing American_Indian_or_Alaska_Native model (normalized: american indian or alaska native)...\n",
      "No patients found for race: American_Indian_or_Alaska_Native\n",
      "Processing Native_Hawaiian_or_other_Pacific_Islander model (normalized: native hawaiian or other pacific islander)...\n",
      "No patients found for race: Native_Hawaiian_or_other_Pacific_Islander\n",
      "Processing Black_or_African-American model (normalized: black or african american)...\n",
      "No patients found for race: Black_or_African-American\n",
      "Final predictions stats: min=-0.15458200871944427, max=0.3081474304199219, mean=0.07714927941560745\n",
      "Submission saved to submission.csv\n",
      "      ID  prediction\n",
      "0  28800    0.077882\n",
      "1  28801    0.308147\n",
      "2  28802   -0.154582\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# Define your RankNet model class\n",
    "class RankNet(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RankNet, self).__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Function to normalize race strings\n",
    "def normalize_race(race_str):\n",
    "    \"\"\"Remove underscores and hyphens from race strings for comparison.\"\"\"\n",
    "    if isinstance(race_str, str):\n",
    "        return race_str.replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "    return str(race_str).lower()\n",
    "\n",
    "# Function to predict with feature alignment\n",
    "def generate_predictions_with_feature_alignment():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load data\n",
    "    test_df = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n",
    "    submission_template = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\")\n",
    "    \n",
    "    # Store original IDs\n",
    "    patient_ids = test_df['ID'].values\n",
    "    \n",
    "    # Load a sample training file to get original feature set\n",
    "    train_df = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\n",
    "    \n",
    "    # Get numeric features from both datasets\n",
    "    train_numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    test_numeric_cols = test_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    print(f\"Training features count: {len(train_numeric_cols)}\")\n",
    "    print(f\"Testing features count: {len(test_numeric_cols)}\")\n",
    "    \n",
    "    # Find common features\n",
    "    common_features = list(set(train_numeric_cols) & set(test_numeric_cols))\n",
    "    print(f\"Common features count: {len(common_features)}\")\n",
    "    \n",
    "    # Check for NaN values before preprocessing\n",
    "    print(f\"NaN values in test data before processing: {test_df[common_features].isna().sum().sum()}\")\n",
    "    \n",
    "    # Prepare test data using only common features\n",
    "    test_features = test_df[common_features].copy()\n",
    "    \n",
    "    # Handle any NaN values\n",
    "    if test_features.isna().sum().sum() > 0:\n",
    "        print(\"Filling NaN values with column means\")\n",
    "        test_features = test_features.fillna(test_features.mean())\n",
    "    \n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    test_data_scaled = scaler.fit_transform(test_features)\n",
    "    \n",
    "    # Check for NaN values after scaling\n",
    "    nan_count = np.isnan(test_data_scaled).sum()\n",
    "    if nan_count > 0:\n",
    "        print(f\"Found {nan_count} NaN values after scaling, replacing with zeros\")\n",
    "        test_data_scaled = np.nan_to_num(test_data_scaled)\n",
    "    \n",
    "    # Define the input dimension based on common features\n",
    "    input_dim = len(common_features)\n",
    "    print(f\"Using input dimension: {input_dim}\")\n",
    "    \n",
    "    # Paths to your trained models\n",
    "    model_dir = \"/kaggle/input/race-groups/pytorch/default/1/\"\n",
    "    race_models = {\n",
    "        \"More_than_one_race\": f\"{model_dir}More_than_one_race.pth\",\n",
    "        \"Asian\": f\"{model_dir}Asian.pth\",\n",
    "        \"White\": f\"{model_dir}White.pth\",\n",
    "        \"American_Indian_or_Alaska_Native\": f\"{model_dir}American_Indian_or_Alaska_Native.pth\",\n",
    "        \"Native_Hawaiian_or_other_Pacific_Islander\": f\"{model_dir}Native_Hawaiian_or_other_Pacific_Islander.pth\", \n",
    "        \"Black_or_African-American\": f\"{model_dir}Black_or_African-American.pth\"\n",
    "    }\n",
    "    \n",
    "    # Create a mapping between normalized race names and model names\n",
    "    normalized_race_mapping = {normalize_race(race): race for race in race_models.keys()}\n",
    "    print(f\"Normalized race mapping: {normalized_race_mapping}\")\n",
    "    \n",
    "    # Get race information if available\n",
    "    race_column = 'race_group'\n",
    "    \n",
    "    # Initialize results\n",
    "    all_predictions = np.zeros(len(test_df))\n",
    "    model_count = 0\n",
    "    \n",
    "    if race_column in test_df.columns:\n",
    "        # Apply race-specific models\n",
    "        print(f\"Using race-specific models based on '{race_column}' column\")\n",
    "        \n",
    "        # Create a normalized version of the race column\n",
    "        test_df['normalized_race'] = test_df[race_column].apply(normalize_race)\n",
    "        \n",
    "        # Show unique race values in test data\n",
    "        unique_races = test_df['normalized_race'].unique()\n",
    "        print(f\"Unique normalized races in test data: {unique_races}\")\n",
    "        \n",
    "        # Count number of patients by race\n",
    "        race_counts = test_df['normalized_race'].value_counts()\n",
    "        print(f\"Patients by race: {race_counts}\")\n",
    "        \n",
    "        for model_race, model_path in race_models.items():\n",
    "            if os.path.exists(model_path):\n",
    "                normalized_model_race = normalize_race(model_race)\n",
    "                print(f\"Processing {model_race} model (normalized: {normalized_model_race})...\")\n",
    "                \n",
    "                # Create a new model with the correct input dimension\n",
    "                model = RankNet(input_dim).to(device)\n",
    "                \n",
    "                # Try loading with modified first layer\n",
    "                try:\n",
    "                    # Apply a quick fix to the model - rebuild first layer\n",
    "                    orig_model = RankNet(24).to(device)  # Original dimension\n",
    "                    orig_model.load_state_dict(torch.load(model_path))\n",
    "                    \n",
    "                    # Copy parameters except first layer\n",
    "                    for i, (new_param, old_param) in enumerate(zip(model.parameters(), orig_model.parameters())):\n",
    "                        if i == 0:  # First layer weights\n",
    "                            if input_dim < 24:\n",
    "                                # If fewer features, take subset\n",
    "                                new_param.data.copy_(old_param.data[:, :input_dim])\n",
    "                            else:\n",
    "                                # If more features, pad with zeros\n",
    "                                new_param.data[:, :24].copy_(old_param.data)\n",
    "                        else:\n",
    "                            # Copy other layers directly\n",
    "                            new_param.data.copy_(old_param.data)\n",
    "                    \n",
    "                    model.eval()\n",
    "                    \n",
    "                    # Filter test data for this race using normalized comparison\n",
    "                    race_mask = test_df['normalized_race'] == normalized_model_race\n",
    "                    if race_mask.any():\n",
    "                        race_indices = np.where(race_mask)[0]\n",
    "                        race_data = test_data_scaled[race_mask]\n",
    "                        \n",
    "                        print(f\"Found {len(race_indices)} patients matching '{model_race}'\")\n",
    "                        \n",
    "                        # Make predictions\n",
    "                        with torch.no_grad():\n",
    "                            inputs = torch.tensor(race_data, dtype=torch.float32).to(device)\n",
    "                            outputs = model(inputs).cpu().numpy().flatten()\n",
    "                            \n",
    "                            # Check for NaN values in predictions\n",
    "                            nan_preds = np.isnan(outputs).sum()\n",
    "                            if nan_preds > 0:\n",
    "                                print(f\"WARNING: Found {nan_preds} NaN predictions for {model_race}\")\n",
    "                                # Replace NaNs with zeros\n",
    "                                outputs = np.nan_to_num(outputs)\n",
    "                        \n",
    "                        # Store predictions\n",
    "                        all_predictions[race_indices] = outputs\n",
    "                        print(f\"Made predictions for {len(race_indices)} patients of {model_race} race\")\n",
    "                        print(f\"Sample predictions: {outputs[:5] if len(outputs) >= 5 else outputs}\")\n",
    "                        model_count += 1\n",
    "                    else:\n",
    "                        print(f\"No patients found for race: {model_race}\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error with {model_race} model: {e}\")\n",
    "    else:\n",
    "        # Ensemble approach if no race information\n",
    "        print(\"No race information found. Using ensemble approach...\")\n",
    "        ensemble_predictions = np.zeros(len(test_df))\n",
    "        valid_models = 0\n",
    "        \n",
    "        for race, model_path in race_models.items():\n",
    "            if os.path.exists(model_path):\n",
    "                try:\n",
    "                    # Same model adaptation as above\n",
    "                    model = RankNet(input_dim).to(device)\n",
    "                    orig_model = RankNet(24).to(device)\n",
    "                    orig_model.load_state_dict(torch.load(model_path))\n",
    "                    \n",
    "                    # Copy parameters\n",
    "                    for i, (new_param, old_param) in enumerate(zip(model.parameters(), orig_model.parameters())):\n",
    "                        if i == 0:\n",
    "                            if input_dim < 24:\n",
    "                                new_param.data.copy_(old_param.data[:, :input_dim])\n",
    "                            else:\n",
    "                                new_param.data[:, :24].copy_(old_param.data)\n",
    "                        else:\n",
    "                            new_param.data.copy_(old_param.data)\n",
    "                    \n",
    "                    model.eval()\n",
    "                    \n",
    "                    # Make predictions\n",
    "                    with torch.no_grad():\n",
    "                        inputs = torch.tensor(test_data_scaled, dtype=torch.float32).to(device)\n",
    "                        outputs = model(inputs).cpu().numpy().flatten()\n",
    "                        \n",
    "                        # Check for NaN values\n",
    "                        nan_count = np.isnan(outputs).sum()\n",
    "                        if nan_count > 0:\n",
    "                            print(f\"WARNING: Found {nan_count} NaN values in {race} predictions\")\n",
    "                            outputs = np.nan_to_num(outputs)\n",
    "                    \n",
    "                    ensemble_predictions += outputs\n",
    "                    valid_models += 1\n",
    "                    print(f\"Added {race} model to ensemble\")\n",
    "                    print(f\"Sample predictions: {outputs[:5] if len(outputs) >= 5 else outputs}\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error with {race} model: {e}\")\n",
    "        \n",
    "        if valid_models > 0:\n",
    "            all_predictions = ensemble_predictions / (valid_models + 1e-10)  # Add small epsilon to avoid division by zero\n",
    "            model_count = valid_models\n",
    "    \n",
    "    # Final check for NaN values\n",
    "    nan_count = np.isnan(all_predictions).sum()\n",
    "    if nan_count > 0:\n",
    "        print(f\"WARNING: Final predictions contain {nan_count} NaN values, replacing with zeros\")\n",
    "        all_predictions = np.nan_to_num(all_predictions)\n",
    "    \n",
    "    if model_count > 0:\n",
    "        # Create submission file\n",
    "        submission = submission_template.copy()\n",
    "        submission['prediction'] = -all_predictions  # Negative sign for correct ranking\n",
    "        \n",
    "        # Check the final predictions\n",
    "        print(f\"Final predictions stats: min={submission['prediction'].min()}, max={submission['prediction'].max()}, mean={submission['prediction'].mean()}\")\n",
    "        \n",
    "        # Save submission\n",
    "        submission_path = \"submission.csv\"\n",
    "        submission.to_csv(submission_path, index=False)\n",
    "        print(f\"Submission saved to {submission_path}\")\n",
    "        return submission\n",
    "    else:\n",
    "        print(\"No valid models were able to make predictions.\")\n",
    "        return None\n",
    "\n",
    "# Run the prediction function\n",
    "if __name__ == \"__main__\":\n",
    "    predictions = generate_predictions_with_feature_alignment()\n",
    "    if predictions is not None:\n",
    "        print(predictions.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10381525,
     "isSourceIdPinned": false,
     "sourceId": 70942,
     "sourceType": "competition"
    },
    {
     "datasetId": 6854398,
     "sourceId": 11009609,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6854605,
     "sourceId": 11009893,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 264912,
     "modelInstanceId": 243302,
     "sourceId": 283931,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.46238,
   "end_time": "2025-03-13T12:05:25.340489",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-13T12:05:15.878109",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
