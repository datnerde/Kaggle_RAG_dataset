{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1102f305",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:41:58.203122Z",
     "iopub.status.busy": "2025-03-04T23:41:58.202757Z",
     "iopub.status.idle": "2025-03-04T23:42:22.909425Z",
     "shell.execute_reply": "2025-03-04T23:42:22.907731Z"
    },
    "id": "4Utmups-GWqo",
    "outputId": "66358cd0-eac1-46d1-98c5-69f3efeaef59",
    "papermill": {
     "duration": 24.714735,
     "end_time": "2025-03-04T23:42:22.911211",
     "exception": false,
     "start_time": "2025-03-04T23:41:58.196476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autograd==1.7.0) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->autograd==1.7.0) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->autograd==1.7.0) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->autograd==1.7.0) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->autograd==1.7.0) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->autograd==1.7.0) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->autograd==1.7.0) (2024.2.0)\r\n",
      "autograd is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Processing /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: autograd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autograd-gamma==0.5.0) (1.7.0)\r\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autograd-gamma==0.5.0) (1.13.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autograd>=1.2.0->autograd-gamma==0.5.0) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->autograd>=1.2.0->autograd-gamma==0.5.0) (2024.2.0)\r\n",
      "Building wheels for collected packages: autograd-gamma\r\n",
      "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=58bf5ae5c518273509bab702f5133f7488730e5ca47004d18311b0b620368c67\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6b/b5/e0/4c79e15c0b5f2c15ecf613c720bb20daab20a666eb67135155\r\n",
      "Successfully built autograd-gamma\r\n",
      "Installing collected packages: autograd-gamma\r\n",
      "Successfully installed autograd-gamma-0.5.0\r\n",
      "Processing /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\r\n",
      "Installing collected packages: interface-meta\r\n",
      "Successfully installed interface-meta-1.3.0\r\n",
      "Processing /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\r\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (2.2.3)\r\n",
      "Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.17.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.5->formulaic==1.0.2) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2025.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->formulaic==1.0.2) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.5->formulaic==1.0.2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.5->formulaic==1.0.2) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.5->formulaic==1.0.2) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.16.5->formulaic==1.0.2) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.16.5->formulaic==1.0.2) (2024.2.0)\r\n",
      "Installing collected packages: formulaic\r\n",
      "Successfully installed formulaic-1.0.2\r\n",
      "Processing /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.13.1)\r\n",
      "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (2.2.3)\r\n",
      "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (3.7.5)\r\n",
      "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.7.0)\r\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (0.5.0)\r\n",
      "Requirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.0.2)\r\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.17.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->lifelines==0.30.0) (2.4.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines==0.30.0) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines==0.30.0) (2025.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines==0.30.0) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.0->lifelines==0.30.0) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.0->lifelines==0.30.0) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->lifelines==0.30.0) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.14.0->lifelines==0.30.0) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.14.0->lifelines==0.30.0) (2024.2.0)\r\n",
      "Installing collected packages: lifelines\r\n",
      "Successfully installed lifelines-0.30.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n",
    "!pip install /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n",
    "!pip install /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n",
    "!pip install /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n",
    "!pip install /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc79743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:42:22.924987Z",
     "iopub.status.busy": "2025-03-04T23:42:22.924547Z",
     "iopub.status.idle": "2025-03-04T23:42:26.004856Z",
     "shell.execute_reply": "2025-03-04T23:42:26.003812Z"
    },
    "id": "4mEJuBB6K_XP",
    "outputId": "1fcd6f97-4b78-48cd-a773-b58b8bef99fa",
    "papermill": {
     "duration": 3.089014,
     "end_time": "2025-03-04T23:42:26.006755",
     "exception": false,
     "start_time": "2025-03-04T23:42:22.917741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "train=pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/train.csv')\n",
    "test=pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d1acc8",
   "metadata": {
    "id": "rlwQdD9Is5OG",
    "papermill": {
     "duration": 0.005435,
     "end_time": "2025-03-04T23:42:26.018030",
     "exception": false,
     "start_time": "2025-03-04T23:42:26.012595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "TESTING VALUES OF NUMERICALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e776daf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:42:26.030676Z",
     "iopub.status.busy": "2025-03-04T23:42:26.030301Z",
     "iopub.status.idle": "2025-03-04T23:42:26.061321Z",
     "shell.execute_reply": "2025-03-04T23:42:26.059999Z"
    },
    "id": "gNRlTwaxs4oP",
    "outputId": "2c30afc8-721e-4aa4-9bcf-d06dc0142dbe",
    "papermill": {
     "duration": 0.039321,
     "end_time": "2025-03-04T23:42:26.063085",
     "exception": false,
     "start_time": "2025-03-04T23:42:26.023764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hla_match_c_high: 3 unique values → [0.0, 1.0, 2.0]\n",
      "hla_high_res_8: 7 unique values → [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]\n",
      "hla_low_res_6: 5 unique values → [2.0, 3.0, 4.0, 5.0, 6.0]\n",
      "hla_high_res_6: 6 unique values → [0.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
      "hla_high_res_10: 8 unique values → [3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
      "hla_match_dqb1_high: 3 unique values → [0.0, 1.0, 2.0]\n",
      "hla_nmdp_6: 5 unique values → [2.0, 3.0, 4.0, 5.0, 6.0]\n",
      "hla_match_c_low: 3 unique values → [0.0, 1.0, 2.0]\n",
      "hla_match_drb1_low: 2 unique values → [1.0, 2.0]\n",
      "hla_match_dqb1_low: 3 unique values → [0.0, 1.0, 2.0]\n",
      "hla_match_a_high: 3 unique values → [0.0, 1.0, 2.0]\n",
      "hla_match_b_low: 3 unique values → [0.0, 1.0, 2.0]\n",
      "hla_match_a_low: 3 unique values → [0.0, 1.0, 2.0]\n",
      "hla_match_b_high: 3 unique values → [0.0, 1.0, 2.0]\n",
      "hla_low_res_8: 7 unique values → [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]\n",
      "hla_match_drb1_high: 3 unique values → [0.0, 1.0, 2.0]\n",
      "hla_low_res_10: 7 unique values → [4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n"
     ]
    }
   ],
   "source": [
    "hla_cols = [col for col in train.columns if col.startswith(\"hla\")]\n",
    "for col in hla_cols:\n",
    "    unique_values = train[col].dropna().unique()\n",
    "    print(f\"{col}: {len(unique_values)} unique values → {sorted(unique_values)[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538810f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:42:26.076225Z",
     "iopub.status.busy": "2025-03-04T23:42:26.075771Z",
     "iopub.status.idle": "2025-03-04T23:42:26.086497Z",
     "shell.execute_reply": "2025-03-04T23:42:26.085494Z"
    },
    "id": "1aszx8jK2FQm",
    "papermill": {
     "duration": 0.019221,
     "end_time": "2025-03-04T23:42:26.088237",
     "exception": false,
     "start_time": "2025-03-04T23:42:26.069016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train[\"year_hct\"] -= 2000\n",
    "test[\"year_hct\"] -= 2000\n",
    "\n",
    "\n",
    "numerical_cols = [\n",
    "    'year_hct', 'donor_age', 'age_at_hct', 'comorbidity_score',\n",
    "    'karnofsky_score'\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    'dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'tbi_status',\n",
    "    'arrhythmia', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe',\n",
    "    'prim_disease_hct', 'cmv_status', 'tce_imm_match', 'rituximab',\n",
    "    'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity',\n",
    "    'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hepatic_severe',\n",
    "    'prior_tumor', 'peptic_ulcer', 'gvhd_proph', 'rheum_issue', 'sex_match',\n",
    "    'race_group', 'hepatic_mild', 'tce_div_match', 'donor_related',\n",
    "    'melphalan_dose', 'cardiac', 'pulm_moderate'\n",
    "]\n",
    "\n",
    "hla_cols = [\n",
    "    'hla_match_c_high', 'hla_high_res_8', 'hla_low_res_6', 'hla_high_res_6',\n",
    "    'hla_high_res_10', 'hla_match_dqb1_high', 'hla_nmdp_6', 'hla_match_c_low',\n",
    "    'hla_match_drb1_low', 'hla_match_dqb1_low', 'hla_match_a_high',\n",
    "    'hla_match_b_low', 'hla_match_a_low', 'hla_match_b_high',\n",
    "    'hla_low_res_8', 'hla_match_drb1_high', 'hla_low_res_10'\n",
    "]\n",
    "\n",
    "\n",
    "targets = ['efs', 'efs_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e657a2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:42:26.113759Z",
     "iopub.status.busy": "2025-03-04T23:42:26.113439Z",
     "iopub.status.idle": "2025-03-04T23:42:26.251911Z",
     "shell.execute_reply": "2025-03-04T23:42:26.250879Z"
    },
    "id": "1uuyRrO4c2u9",
    "papermill": {
     "duration": 0.159705,
     "end_time": "2025-03-04T23:42:26.253777",
     "exception": false,
     "start_time": "2025-03-04T23:42:26.094072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_cols = categorical_cols + hla_cols\n",
    "for col in categorical_cols:\n",
    "    train[col] = train[col].astype(\"category\")\n",
    "    test[col] = test[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f605a",
   "metadata": {
    "id": "hyByJuvUBTo8",
    "papermill": {
     "duration": 0.005381,
     "end_time": "2025-03-04T23:42:26.264994",
     "exception": false,
     "start_time": "2025-03-04T23:42:26.259613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "LABEL ENCODING + KNN IMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b2c33fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:42:26.277714Z",
     "iopub.status.busy": "2025-03-04T23:42:26.277239Z",
     "iopub.status.idle": "2025-03-04T23:42:39.305382Z",
     "shell.execute_reply": "2025-03-04T23:42:39.304474Z"
    },
    "id": "Ya337CK7nz3N",
    "papermill": {
     "duration": 13.036528,
     "end_time": "2025-03-04T23:42:39.307242",
     "exception": false,
     "start_time": "2025-03-04T23:42:26.270714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_imputed = train.copy()\n",
    "test_imputed = test.copy()\n",
    "categorical_cols = train.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if train_imputed[col].dtype.name == 'category':\n",
    "        le = LabelEncoder()\n",
    "        train_imputed[col] = le.fit_transform(train_imputed[col].astype(str))\n",
    "        test_imputed[col] = le.transform(test_imputed[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "all_cols = numerical_cols + categorical_cols\n",
    "train_imputed[all_cols] = knn_imputer.fit_transform(train_imputed[all_cols])\n",
    "test_imputed[all_cols] = knn_imputer.transform(test_imputed[all_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec671547",
   "metadata": {
    "id": "WysKrWBEC2MP",
    "papermill": {
     "duration": 0.005603,
     "end_time": "2025-03-04T23:42:39.318764",
     "exception": false,
     "start_time": "2025-03-04T23:42:39.313161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "SEPARATION BETWEEN GROUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b2217bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:42:39.331576Z",
     "iopub.status.busy": "2025-03-04T23:42:39.331145Z",
     "iopub.status.idle": "2025-03-04T23:42:39.339201Z",
     "shell.execute_reply": "2025-03-04T23:42:39.338376Z"
    },
    "id": "xOXV03fVESxp",
    "outputId": "c1aac5f5-db40-4d4b-e201-a286f9e6308b",
    "papermill": {
     "duration": 0.016222,
     "end_time": "2025-03-04T23:42:39.340796",
     "exception": false,
     "start_time": "2025-03-04T23:42:39.324574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['More than one race', 'Asian', 'White', 'American Indian or Alaska Native', 'Native Hawaiian or other Pacific Islander', 'Black or African-American']\n",
       "Categories (6, object): ['American Indian or Alaska Native', 'Asian', 'Black or African-American', 'More than one race', 'Native Hawaiian or other Pacific Islander', 'White']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['race_group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4171ed98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:42:39.354362Z",
     "iopub.status.busy": "2025-03-04T23:42:39.353933Z",
     "iopub.status.idle": "2025-03-04T23:42:39.357913Z",
     "shell.execute_reply": "2025-03-04T23:42:39.356953Z"
    },
    "id": "D-5FgmGWC0jq",
    "outputId": "2493ff8e-8ece-4aeb-8ee0-23127e1feac8",
    "papermill": {
     "duration": 0.012861,
     "end_time": "2025-03-04T23:42:39.359716",
     "exception": false,
     "start_time": "2025-03-04T23:42:39.346855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train['race_group_encoded'] = train['race_group'].astype('category').cat.codes\n",
    "# correlation_efs = train['race_group_encoded'].corr(train['efs'])\n",
    "# correlation_efs_time = train['race_group_encoded'].corr(train['efs_time'])\n",
    "\n",
    "# print(f\"Correlation between race_group and efs: {correlation_efs:.4f}\")\n",
    "# print(f\"Correlation between race_group and efs_time: {correlation_efs_time:.4f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Correlation between race_group and efs: 0.0393\n",
    "# Correlation between race_group and efs_time: -0.0123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf475bbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:42:39.373004Z",
     "iopub.status.busy": "2025-03-04T23:42:39.372686Z",
     "iopub.status.idle": "2025-03-04T23:42:39.376210Z",
     "shell.execute_reply": "2025-03-04T23:42:39.375426Z"
    },
    "id": "5GUC6pZoEfEG",
    "outputId": "b869ea72-4db6-49e5-876f-212775157fc4",
    "papermill": {
     "duration": 0.011893,
     "end_time": "2025-03-04T23:42:39.377754",
     "exception": false,
     "start_time": "2025-03-04T23:42:39.365861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import scipy.stats as stats\n",
    "# import pandas as pd\n",
    "\n",
    "# anova_efs = stats.f_oneway(*(train[train['race_group'] == group]['efs'] for group in train['race_group'].unique()))\n",
    "# anova_efs_time = stats.f_oneway(*(train[train['race_group'] == group]['efs_time'] for group in train['race_group'].unique()))\n",
    "\n",
    "# print(f\"ANOVA p-value for race_group and efs: {anova_efs.pvalue:.4f}\")\n",
    "# print(f\"ANOVA p-value for race_group and efs_time: {anova_efs_time.pvalue:.4f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# ANOVA p-value for race_group and efs: 0.0000\n",
    "# ANOVA p-value for race_group and efs_time: 0.0000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51df15d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:42:39.390911Z",
     "iopub.status.busy": "2025-03-04T23:42:39.390581Z",
     "iopub.status.idle": "2025-03-04T23:42:39.394432Z",
     "shell.execute_reply": "2025-03-04T23:42:39.393366Z"
    },
    "id": "UFm5K4klMP27",
    "outputId": "0c26f4f5-fcfc-4ee3-ff56-0ec4ec6e895f",
    "papermill": {
     "duration": 0.012527,
     "end_time": "2025-03-04T23:42:39.396181",
     "exception": false,
     "start_time": "2025-03-04T23:42:39.383654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# race_group_counts = Counter(train['race_group'])\n",
    "\n",
    "# for race, count in race_group_counts.items():\n",
    "#     print(f\"Race Group {race}: {count} data points\")\n",
    "\n",
    "# ---------------------------\n",
    "# Race Group More than one race: 4845 data points\n",
    "# Race Group Asian: 4832 data points\n",
    "# Race Group White: 4831 data points\n",
    "# Race Group American Indian or Alaska Native: 4790 data points\n",
    "# Race Group Native Hawaiian or other Pacific Islander: 4707 data points\n",
    "# Race Group Black or African-American: 4795 data points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b1135f",
   "metadata": {
    "id": "76cCgRqeGvWs",
    "papermill": {
     "duration": 0.005579,
     "end_time": "2025-03-04T23:42:39.407911",
     "exception": false,
     "start_time": "2025-03-04T23:42:39.402332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "SEPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef3ff473",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:42:39.420913Z",
     "iopub.status.busy": "2025-03-04T23:42:39.420595Z",
     "iopub.status.idle": "2025-03-04T23:43:02.819431Z",
     "shell.execute_reply": "2025-03-04T23:43:02.818121Z"
    },
    "id": "ar5qE-ACGpS_",
    "outputId": "c1b30151-5b35-4d26-8e38-17999dca0f3a",
    "papermill": {
     "duration": 23.407525,
     "end_time": "2025-03-04T23:43:02.821290",
     "exception": false,
     "start_time": "2025-03-04T23:42:39.413765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for race group: 3.0\n",
      "Race Group: 3.0 - Epoch 0: Train Loss = 7.9791, Val Loss = 6.5718, C-index = 0.5595\n",
      "Race Group: 3.0 - Epoch 10: Train Loss = 7.9173, Val Loss = 6.5127, C-index = 0.6218\n",
      "Race Group: 3.0 - Epoch 20: Train Loss = 7.8780, Val Loss = 6.4722, C-index = 0.6256\n",
      "Race Group: 3.0 - Epoch 30: Train Loss = 7.8514, Val Loss = 6.4563, C-index = 0.6295\n",
      "Race Group: 3.0 - Epoch 40: Train Loss = 7.8276, Val Loss = 6.4487, C-index = 0.6362\n",
      "Race Group: 3.0 - Epoch 50: Train Loss = 7.8101, Val Loss = 6.4463, C-index = 0.6387\n",
      "Race Group: 3.0 - Epoch 60: Train Loss = 7.7997, Val Loss = 6.4472, C-index = 0.6391\n",
      "Race Group: 3.0 - Epoch 70: Train Loss = 7.7762, Val Loss = 6.4502, C-index = 0.6395\n",
      "Race Group: 3.0 - Epoch 80: Train Loss = 7.7700, Val Loss = 6.4559, C-index = 0.6388\n",
      "Race Group: 3.0 - Epoch 90: Train Loss = 7.7548, Val Loss = 6.4629, C-index = 0.6380\n",
      "Race Group: 3.0 - Final C-index on validation set: 0.6364\n",
      "Training model for race group: 1.0\n",
      "Race Group: 1.0 - Epoch 0: Train Loss = 7.9118, Val Loss = 6.5340, C-index = 0.5328\n",
      "Race Group: 1.0 - Epoch 10: Train Loss = 7.8575, Val Loss = 6.4768, C-index = 0.6240\n",
      "Race Group: 1.0 - Epoch 20: Train Loss = 7.8178, Val Loss = 6.4297, C-index = 0.6367\n",
      "Race Group: 1.0 - Epoch 30: Train Loss = 7.7958, Val Loss = 6.3982, C-index = 0.6455\n",
      "Race Group: 1.0 - Epoch 40: Train Loss = 7.7687, Val Loss = 6.3864, C-index = 0.6512\n",
      "Race Group: 1.0 - Epoch 50: Train Loss = 7.7524, Val Loss = 6.3846, C-index = 0.6534\n",
      "Race Group: 1.0 - Epoch 60: Train Loss = 7.7407, Val Loss = 6.3830, C-index = 0.6538\n",
      "Race Group: 1.0 - Epoch 70: Train Loss = 7.7258, Val Loss = 6.3825, C-index = 0.6540\n",
      "Race Group: 1.0 - Epoch 80: Train Loss = 7.7131, Val Loss = 6.3847, C-index = 0.6535\n",
      "Race Group: 1.0 - Epoch 90: Train Loss = 7.7036, Val Loss = 6.3872, C-index = 0.6532\n",
      "Race Group: 1.0 - Final C-index on validation set: 0.6534\n",
      "Training model for race group: 5.0\n",
      "Race Group: 5.0 - Epoch 0: Train Loss = 7.8517, Val Loss = 6.4612, C-index = 0.5152\n",
      "Race Group: 5.0 - Epoch 10: Train Loss = 7.8125, Val Loss = 6.4249, C-index = 0.5835\n",
      "Race Group: 5.0 - Epoch 20: Train Loss = 7.7855, Val Loss = 6.3973, C-index = 0.5943\n",
      "Race Group: 5.0 - Epoch 30: Train Loss = 7.7607, Val Loss = 6.3829, C-index = 0.5995\n",
      "Race Group: 5.0 - Epoch 40: Train Loss = 7.7432, Val Loss = 6.3788, C-index = 0.6026\n",
      "Race Group: 5.0 - Epoch 50: Train Loss = 7.7294, Val Loss = 6.3738, C-index = 0.6064\n",
      "Race Group: 5.0 - Epoch 60: Train Loss = 7.7211, Val Loss = 6.3701, C-index = 0.6112\n",
      "Race Group: 5.0 - Epoch 70: Train Loss = 7.7133, Val Loss = 6.3684, C-index = 0.6131\n",
      "Race Group: 5.0 - Epoch 80: Train Loss = 7.7044, Val Loss = 6.3683, C-index = 0.6150\n",
      "Race Group: 5.0 - Epoch 90: Train Loss = 7.6933, Val Loss = 6.3684, C-index = 0.6157\n",
      "Race Group: 5.0 - Final C-index on validation set: 0.6164\n",
      "Training model for race group: 0.0\n",
      "Race Group: 0.0 - Epoch 0: Train Loss = 7.9301, Val Loss = 6.5397, C-index = 0.5534\n",
      "Race Group: 0.0 - Epoch 10: Train Loss = 7.8391, Val Loss = 6.4589, C-index = 0.6231\n",
      "Race Group: 0.0 - Epoch 20: Train Loss = 7.7919, Val Loss = 6.4327, C-index = 0.6325\n",
      "Race Group: 0.0 - Epoch 30: Train Loss = 7.7589, Val Loss = 6.4285, C-index = 0.6395\n",
      "Race Group: 0.0 - Epoch 40: Train Loss = 7.7340, Val Loss = 6.4315, C-index = 0.6419\n",
      "Race Group: 0.0 - Epoch 50: Train Loss = 7.7156, Val Loss = 6.4366, C-index = 0.6425\n",
      "Race Group: 0.0 - Epoch 60: Train Loss = 7.6835, Val Loss = 6.4408, C-index = 0.6433\n",
      "Race Group: 0.0 - Epoch 70: Train Loss = 7.6578, Val Loss = 6.4496, C-index = 0.6435\n",
      "Race Group: 0.0 - Epoch 80: Train Loss = 7.6401, Val Loss = 6.4581, C-index = 0.6430\n",
      "Race Group: 0.0 - Epoch 90: Train Loss = 7.6116, Val Loss = 6.4647, C-index = 0.6430\n",
      "Race Group: 0.0 - Final C-index on validation set: 0.6428\n",
      "Training model for race group: 4.0\n",
      "Race Group: 4.0 - Epoch 0: Train Loss = 7.8916, Val Loss = 6.5237, C-index = 0.5591\n",
      "Race Group: 4.0 - Epoch 10: Train Loss = 7.8328, Val Loss = 6.4859, C-index = 0.5870\n",
      "Race Group: 4.0 - Epoch 20: Train Loss = 7.7984, Val Loss = 6.4720, C-index = 0.5922\n",
      "Race Group: 4.0 - Epoch 30: Train Loss = 7.7738, Val Loss = 6.4670, C-index = 0.6036\n",
      "Race Group: 4.0 - Epoch 40: Train Loss = 7.7521, Val Loss = 6.4599, C-index = 0.6125\n",
      "Race Group: 4.0 - Epoch 50: Train Loss = 7.7397, Val Loss = 6.4619, C-index = 0.6134\n",
      "Race Group: 4.0 - Epoch 60: Train Loss = 7.7123, Val Loss = 6.4652, C-index = 0.6146\n",
      "Race Group: 4.0 - Epoch 70: Train Loss = 7.7000, Val Loss = 6.4675, C-index = 0.6150\n",
      "Race Group: 4.0 - Epoch 80: Train Loss = 7.6905, Val Loss = 6.4684, C-index = 0.6159\n",
      "Race Group: 4.0 - Epoch 90: Train Loss = 7.6629, Val Loss = 6.4729, C-index = 0.6170\n",
      "Race Group: 4.0 - Final C-index on validation set: 0.6179\n",
      "Training model for race group: 2.0\n",
      "Race Group: 2.0 - Epoch 0: Train Loss = 7.8903, Val Loss = 6.5001, C-index = 0.5533\n",
      "Race Group: 2.0 - Epoch 10: Train Loss = 7.8397, Val Loss = 6.4517, C-index = 0.6011\n",
      "Race Group: 2.0 - Epoch 20: Train Loss = 7.8023, Val Loss = 6.4271, C-index = 0.6054\n",
      "Race Group: 2.0 - Epoch 30: Train Loss = 7.7753, Val Loss = 6.4260, C-index = 0.6073\n",
      "Race Group: 2.0 - Epoch 40: Train Loss = 7.7581, Val Loss = 6.4295, C-index = 0.6093\n",
      "Race Group: 2.0 - Epoch 50: Train Loss = 7.7438, Val Loss = 6.4355, C-index = 0.6080\n",
      "Race Group: 2.0 - Epoch 60: Train Loss = 7.7235, Val Loss = 6.4395, C-index = 0.6088\n",
      "Race Group: 2.0 - Epoch 70: Train Loss = 7.7129, Val Loss = 6.4429, C-index = 0.6089\n",
      "Race Group: 2.0 - Epoch 80: Train Loss = 7.6868, Val Loss = 6.4463, C-index = 0.6083\n",
      "Race Group: 2.0 - Epoch 90: Train Loss = 7.6715, Val Loss = 6.4523, C-index = 0.6082\n",
      "Race Group: 2.0 - Final C-index on validation set: 0.6064\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "race_groups = train_imputed['race_group'].unique()\n",
    "class DeepSurv(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, dropout_rate):\n",
    "        super(DeepSurv, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1) \n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2) \n",
    "        self.fc3 = nn.Linear(hidden_dim2, 1) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x.squeeze()  \n",
    "\n",
    "def cox_loss(hazards, efs, efs_time):\n",
    "    \"\"\"Computes Cox proportional hazards loss.\"\"\"\n",
    "    risk_order = torch.argsort(efs_time, descending=True)\n",
    "    hazards = hazards[risk_order]\n",
    "    efs = efs[risk_order]\n",
    "\n",
    "    exp_hazards = torch.exp(hazards)\n",
    "    cum_sum = torch.cumsum(exp_hazards, dim=0)\n",
    "    log_risk = torch.log(cum_sum)\n",
    "    loss = -torch.sum((hazards - log_risk) * efs)\n",
    "\n",
    "    return loss / torch.sum(efs)\n",
    "\n",
    "def train_race_group_model(race_group, train_imputed, numerical_cols, categorical_cols, targets, best_params):\n",
    "    race_group_data = train_imputed[train_imputed['race_group'] == race_group]\n",
    "\n",
    "    X = race_group_data.drop(columns=targets).values\n",
    "    efs = race_group_data['efs'].values\n",
    "    efs_time = race_group_data['efs_time'].values\n",
    "\n",
    "    X_train, X_val, efs_train, efs_val, efs_time_train, efs_time_val = train_test_split(\n",
    "        X, efs, efs_time, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    efs_train_tensor = torch.tensor(efs_train, dtype=torch.float32)\n",
    "    efs_val_tensor = torch.tensor(efs_val, dtype=torch.float32)\n",
    "    efs_time_train_tensor = torch.tensor(efs_time_train, dtype=torch.float32)\n",
    "    efs_time_val_tensor = torch.tensor(efs_time_val, dtype=torch.float32)\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    model = DeepSurv(input_dim, best_params['hidden_dim1'], best_params['hidden_dim2'], best_params['dropout_rate'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_params['lr'], weight_decay=best_params['weight_decay'])\n",
    "\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        hazards_train = model(X_train_tensor)\n",
    "        loss = cox_loss(hazards_train, efs_train_tensor, efs_time_train_tensor)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            hazards_val = model(X_val_tensor)\n",
    "            val_loss = cox_loss(hazards_val, efs_val_tensor, efs_time_val_tensor)\n",
    "            c_index = concordance_index(efs_time_val, -hazards_val.numpy(), efs_val)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Race Group: {race_group} - Epoch {epoch}: Train Loss = {loss.item():.4f}, Val Loss = {val_loss.item():.4f}, C-index = {c_index:.4f}\")\n",
    "\n",
    "    print(f\"Race Group: {race_group} - Final C-index on validation set: {c_index:.4f}\")\n",
    "\n",
    "    return model, scaler, c_index\n",
    "\n",
    "# Best parameters for each race group\n",
    "best_params_dict = {\n",
    "    3.0: {'dropout_rate': 0.3, 'hidden_dim1': 128, 'hidden_dim2': 128, 'lr': 0.0005, 'weight_decay': 0.0001},\n",
    "    1.0: {'dropout_rate': 0.3, 'hidden_dim1': 128, 'hidden_dim2': 128, 'lr': 0.0005, 'weight_decay': 0.0001},\n",
    "    5.0: {'dropout_rate': 0.3, 'hidden_dim1': 128, 'hidden_dim2': 64, 'lr': 0.0005, 'weight_decay': 1e-05},\n",
    "    0.0: {'dropout_rate': 0.3, 'hidden_dim1': 256, 'hidden_dim2': 128, 'lr': 0.0005, 'weight_decay': 1e-05},\n",
    "    4.0: {'dropout_rate': 0.2, 'hidden_dim1': 128, 'hidden_dim2': 128, 'lr': 0.0005, 'weight_decay': 1e-05},\n",
    "    2.0: {'dropout_rate': 0.2, 'hidden_dim1': 128, 'hidden_dim2': 128, 'lr': 0.0005, 'weight_decay': 1e-05}\n",
    "}\n",
    "\n",
    "race_group_models = {}\n",
    "race_group_scalers = {}\n",
    "for race_group in race_groups:\n",
    "    if race_group in best_params_dict:\n",
    "        print(f\"Training model for race group: {race_group}\")\n",
    "        model, scaler, _ = train_race_group_model(race_group, train_imputed, numerical_cols, categorical_cols, ['efs', 'efs_time'], best_params_dict[race_group])\n",
    "        race_group_models[race_group] = model\n",
    "        race_group_scalers[race_group] = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42851689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:43:02.845489Z",
     "iopub.status.busy": "2025-03-04T23:43:02.844817Z",
     "iopub.status.idle": "2025-03-04T23:43:02.863720Z",
     "shell.execute_reply": "2025-03-04T23:43:02.862668Z"
    },
    "papermill": {
     "duration": 0.032162,
     "end_time": "2025-03-04T23:43:02.865647",
     "exception": false,
     "start_time": "2025-03-04T23:43:02.833485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions saved successfully.\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for idx, row in test_imputed.iterrows():\n",
    "    race_group = row['race_group'] \n",
    "\n",
    "    if race_group in race_group_models and race_group in race_group_scalers:\n",
    "        model = race_group_models[race_group]  \n",
    "        scaler = race_group_scalers[race_group] \n",
    "\n",
    "        # Extract features and apply scaling\n",
    "        X_row = row.drop(columns=['ID', 'race_group']) \n",
    "        X_row_scaled = scaler.transform([X_row])  \n",
    "\n",
    "        # Convert to PyTorch tensor and predict\n",
    "        X_row_tensor = torch.tensor(X_row_scaled, dtype=torch.float32)\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            hazard_score = model(X_row_tensor)  \n",
    "            prediction = hazard_score.item() \n",
    "        predictions.append((row['ID'], prediction))\n",
    "\n",
    "submission_df = pd.DataFrame(predictions, columns=['ID', 'prediction'])\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Test predictions saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1776c2f8",
   "metadata": {
    "id": "j2KIIltBUWLG",
    "papermill": {
     "duration": 0.009425,
     "end_time": "2025-03-04T23:43:02.884825",
     "exception": false,
     "start_time": "2025-03-04T23:43:02.875400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6641a95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:43:02.905188Z",
     "iopub.status.busy": "2025-03-04T23:43:02.904824Z",
     "iopub.status.idle": "2025-03-04T23:43:02.910365Z",
     "shell.execute_reply": "2025-03-04T23:43:02.909441Z"
    },
    "id": "RpOWXT3UMdfC",
    "outputId": "310e380a-f28f-43fd-a33e-20e250188944",
    "papermill": {
     "duration": 0.01801,
     "end_time": "2025-03-04T23:43:02.912059",
     "exception": false,
     "start_time": "2025-03-04T23:43:02.894049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from lifelines.utils import concordance_index\n",
    "# from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# # Assuming train_imputed is already preprocessed and available\n",
    "# race_groups = train_imputed['race_group'].unique()\n",
    "\n",
    "# # DeepSurv Model\n",
    "# class DeepSurv(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim1=256, hidden_dim2=128, dropout_rate=0.2):\n",
    "#         super(DeepSurv, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "#         self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "#         self.fc3 = nn.Linear(hidden_dim2, 1)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.relu(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x.squeeze()\n",
    "\n",
    "# # Cox loss function\n",
    "# def cox_loss(hazards, efs, efs_time):\n",
    "#     \"\"\"Computes Cox proportional hazards loss.\"\"\"\n",
    "#     risk_order = torch.argsort(efs_time, descending=True)\n",
    "#     hazards = hazards[risk_order]\n",
    "#     efs = efs[risk_order]\n",
    "\n",
    "#     exp_hazards = torch.exp(hazards)\n",
    "#     cum_sum = torch.cumsum(exp_hazards, dim=0)\n",
    "#     log_risk = torch.log(cum_sum)\n",
    "#     loss = -torch.sum((hazards - log_risk) * efs)\n",
    "\n",
    "#     return loss / torch.sum(efs)\n",
    "\n",
    "# # Training function for each race group model\n",
    "# def train_race_group_model(race_group, train_imputed, numerical_cols, categorical_cols, targets, hidden_dim1=256, hidden_dim2=128, dropout_rate=0.2, lr=0.001, weight_decay=1e-4, num_epochs=100):\n",
    "#     race_group_data = train_imputed[train_imputed['race_group'] == race_group]\n",
    "\n",
    "#     X = race_group_data.drop(columns=targets).values\n",
    "#     efs = race_group_data['efs'].values\n",
    "#     efs_time = race_group_data['efs_time'].values\n",
    "\n",
    "#     # Train-validation split\n",
    "#     X_train, X_val, efs_train, efs_val, efs_time_train, efs_time_val = train_test_split(\n",
    "#         X, efs, efs_time, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Standardize the data\n",
    "#     scaler = StandardScaler()\n",
    "#     X_train = scaler.fit_transform(X_train)\n",
    "#     X_val = scaler.transform(X_val)\n",
    "\n",
    "#     # Convert data to tensors\n",
    "#     X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "#     X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "#     efs_train_tensor = torch.tensor(efs_train, dtype=torch.float32)\n",
    "#     efs_val_tensor = torch.tensor(efs_val, dtype=torch.float32)\n",
    "#     efs_time_train_tensor = torch.tensor(efs_time_train, dtype=torch.float32)\n",
    "#     efs_time_val_tensor = torch.tensor(efs_time_val, dtype=torch.float32)\n",
    "\n",
    "#     # Initialize model and optimizer\n",
    "#     input_dim = X_train.shape[1]\n",
    "#     model = DeepSurv(input_dim, hidden_dim1, hidden_dim2, dropout_rate)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "#     # Training loop\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "#         hazards_train = model(X_train_tensor)\n",
    "#         loss = cox_loss(hazards_train, efs_train_tensor, efs_time_train_tensor)\n",
    "\n",
    "#         # Backward pass\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         hazards_val = model(X_val_tensor)\n",
    "#         val_loss = cox_loss(hazards_val, efs_val_tensor, efs_time_val_tensor)\n",
    "#         c_index = concordance_index(efs_time_val, -hazards_val.numpy(), efs_val)\n",
    "\n",
    "#     return c_index\n",
    "\n",
    "# # Grid search parameters for each model\n",
    "# param_grid = {\n",
    "#     'hidden_dim1': [128, 256],\n",
    "#     'hidden_dim2': [64, 128],\n",
    "#     'dropout_rate': [0.2, 0.3],\n",
    "#     'lr': [0.001, 0.0005],\n",
    "#     'weight_decay': [1e-4, 1e-5]\n",
    "# }\n",
    "\n",
    "# # Function to perform grid search for all race groups\n",
    "# def grid_search_for_race_groups(train_imputed, race_groups, numerical_cols, categorical_cols, targets):\n",
    "#     race_group_models = {}\n",
    "#     race_group_scalers = {}\n",
    "#     race_group_c_indexes = {}\n",
    "#     race_group_best_params = {}\n",
    "\n",
    "#     for race_group in race_groups:\n",
    "#         print(f\"Training model for race group: {race_group}\")\n",
    "\n",
    "#         best_c_index = -1\n",
    "#         best_model = None\n",
    "#         best_scaler = None\n",
    "#         best_params = {}\n",
    "\n",
    "#         # Iterate through the grid search space\n",
    "#         for params in ParameterGrid(param_grid):\n",
    "#             c_index = train_race_group_model(race_group, train_imputed, numerical_cols, categorical_cols, targets, **params)\n",
    "#             if c_index > best_c_index:\n",
    "#                 best_c_index = c_index\n",
    "#                 best_model = model\n",
    "#                 best_scaler = scaler\n",
    "#                 best_params = params\n",
    "\n",
    "#         # Store the best model, scaler, and parameters\n",
    "#         race_group_models[race_group] = best_model\n",
    "#         race_group_scalers[race_group] = best_scaler\n",
    "#         race_group_c_indexes[race_group] = best_c_index\n",
    "#         race_group_best_params[race_group] = best_params\n",
    "\n",
    "#         print(f\"Race Group: {race_group} - Final C-index on validation set: {best_c_index:.4f} with params: {best_params}\")\n",
    "\n",
    "#     return race_group_models, race_group_scalers, race_group_c_indexes, race_group_best_params\n",
    "\n",
    "# # Run the grid search for each race group\n",
    "# race_group_models, race_group_scalers, race_group_c_indexes, race_group_best_params = grid_search_for_race_groups(train_imputed, race_groups, numerical_cols, categorical_cols, targets)\n",
    "\n",
    "# # Print C-index and best parameters for each race group\n",
    "# print(\"C-index and best parameters for each race group:\")\n",
    "# for race_group in race_group_best_params:\n",
    "#     print(f\"Race group {race_group}:\")\n",
    "#     print(f\"  Best C-index: {race_group_c_indexes[race_group]:.4f}\")\n",
    "#     print(f\"  Best Params: {race_group_best_params[race_group]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44b723d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T23:43:02.932202Z",
     "iopub.status.busy": "2025-03-04T23:43:02.931862Z",
     "iopub.status.idle": "2025-03-04T23:43:02.936074Z",
     "shell.execute_reply": "2025-03-04T23:43:02.935000Z"
    },
    "id": "hMyMGVLsUSvE",
    "papermill": {
     "duration": 0.016221,
     "end_time": "2025-03-04T23:43:02.937922",
     "exception": false,
     "start_time": "2025-03-04T23:43:02.921701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# C-index and best parameters for each race group:\n",
    "# Race group 3.0:\n",
    "#   Best C-index: 0.6412\n",
    "#   Best Params: {'dropout_rate': 0.3, 'hidden_dim1': 128, 'hidden_dim2': 128, 'lr': 0.0005, 'weight_decay': 0.0001}\n",
    "# Race group 1.0:\n",
    "#   Best C-index: 0.6550\n",
    "#   Best Params: {'dropout_rate': 0.3, 'hidden_dim1': 128, 'hidden_dim2': 128, 'lr': 0.0005, 'weight_decay': 0.0001}\n",
    "# Race group 5.0:\n",
    "#   Best C-index: 0.6268\n",
    "#   Best Params: {'dropout_rate': 0.3, 'hidden_dim1': 128, 'hidden_dim2': 64, 'lr': 0.0005, 'weight_decay': 1e-05}\n",
    "# Race group 0.0:\n",
    "#   Best C-index: 0.6520\n",
    "#   Best Params: {'dropout_rate': 0.3, 'hidden_dim1': 256, 'hidden_dim2': 128, 'lr': 0.0005, 'weight_decay': 1e-05}\n",
    "# Race group 4.0:\n",
    "#   Best C-index: 0.6235\n",
    "#   Best Params: {'dropout_rate': 0.2, 'hidden_dim1': 128, 'hidden_dim2': 128, 'lr': 0.0005, 'weight_decay': 1e-05}\n",
    "# Race group 2.0:\n",
    "#   Best C-index: 0.6145\n",
    "#   Best Params: {'dropout_rate': 0.2, 'hidden_dim1': 128, 'hidden_dim2': 128, 'lr': 0.0005, 'weight_decay': 1e-05}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10381525,
     "sourceId": 70942,
     "sourceType": "competition"
    },
    {
     "sourceId": 211322530,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 69.541173,
   "end_time": "2025-03-04T23:43:04.873237",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-04T23:41:55.332064",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
