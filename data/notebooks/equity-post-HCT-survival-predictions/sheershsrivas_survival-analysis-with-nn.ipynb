{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1449d900",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:37.896633Z",
     "iopub.status.busy": "2025-03-04T01:33:37.896212Z",
     "iopub.status.idle": "2025-03-04T01:33:45.207833Z",
     "shell.execute_reply": "2025-03-04T01:33:45.206834Z"
    },
    "id": "-cdAvuciJPOb",
    "papermill": {
     "duration": 7.321645,
     "end_time": "2025-03-04T01:33:45.209893",
     "exception": false,
     "start_time": "2025-03-04T01:33:37.888248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f83cc1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:45.223856Z",
     "iopub.status.busy": "2025-03-04T01:33:45.223228Z",
     "iopub.status.idle": "2025-03-04T01:33:45.649942Z",
     "shell.execute_reply": "2025-03-04T01:33:45.648487Z"
    },
    "id": "EORakV1rzJ85",
    "outputId": "a8815535-8753-4ca6-b903-cd8fb268ec1c",
    "papermill": {
     "duration": 0.435561,
     "end_time": "2025-03-04T01:33:45.651941",
     "exception": false,
     "start_time": "2025-03-04T01:33:45.216380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'hla_match_c_high', 'hla_high_res_8', 'tbi_status', 'arrhythmia', 'hla_low_res_6', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'hla_high_res_6', 'cmv_status', 'hla_high_res_10', 'hla_match_dqb1_high', 'tce_imm_match', 'hla_nmdp_6', 'hla_match_c_low', 'rituximab', 'hla_match_drb1_low', 'hla_match_dqb1_low', 'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity', 'year_hct', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hla_match_a_high', 'hepatic_severe', 'donor_age', 'prior_tumor', 'hla_match_b_low', 'peptic_ulcer', 'age_at_hct', 'hla_match_a_low', 'gvhd_proph', 'rheum_issue', 'sex_match', 'hla_match_b_high', 'race_group', 'comorbidity_score', 'karnofsky_score', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'hla_low_res_8', 'cardiac', 'hla_match_drb1_high', 'pulm_moderate', 'hla_low_res_10', 'efs', 'efs_time']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df=pd.read_csv('/kaggle/input/equity-post-HCT-survival-predictions/train.csv')\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "630a6a16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:45.665497Z",
     "iopub.status.busy": "2025-03-04T01:33:45.665063Z",
     "iopub.status.idle": "2025-03-04T01:33:45.685422Z",
     "shell.execute_reply": "2025-03-04T01:33:45.684086Z"
    },
    "id": "KADofN360QL8",
    "outputId": "4637abb3-087a-41b8-a2b2-ae32bdc18e98",
    "papermill": {
     "duration": 0.029236,
     "end_time": "2025-03-04T01:33:45.687297",
     "exception": false,
     "start_time": "2025-03-04T01:33:45.658061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     35\n",
      "float64    23\n",
      "int64       2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3200b574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:45.701178Z",
     "iopub.status.busy": "2025-03-04T01:33:45.700842Z",
     "iopub.status.idle": "2025-03-04T01:33:45.717238Z",
     "shell.execute_reply": "2025-03-04T01:33:45.715981Z"
    },
    "id": "D9A-JOAr1Mc9",
    "outputId": "c367ca55-3a22-45d1-c183-6ad0616f6dae",
    "papermill": {
     "duration": 0.025268,
     "end_time": "2025-03-04T01:33:45.719013",
     "exception": false,
     "start_time": "2025-03-04T01:33:45.693745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 5 17\n"
     ]
    }
   ],
   "source": [
    "# creating seperate var for categorical and numerical columns for embeddings\n",
    "categorical_cols=df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols=df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "hla_cols = [col for col in df.columns if col.startswith('hla_')]\n",
    "\n",
    "# Remove hla_ columns from numerical_cols\n",
    "numerical_cols = [col for col in numerical_cols if col not in hla_cols]\n",
    "\n",
    "# Remove specific columns: 'ID', 'efs', 'efs_time'\n",
    "cols_to_remove = ['ID', 'efs', 'efs_time']\n",
    "numerical_cols = [col for col in numerical_cols if col not in cols_to_remove]\n",
    "\n",
    "print(len(categorical_cols), len(numerical_cols), len(hla_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05326435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:45.732834Z",
     "iopub.status.busy": "2025-03-04T01:33:45.732459Z",
     "iopub.status.idle": "2025-03-04T01:33:45.738086Z",
     "shell.execute_reply": "2025-03-04T01:33:45.736925Z"
    },
    "id": "AQuWstVnTYSc",
    "outputId": "f9b066cb-58c5-41b0-b638-aa3b35c37084",
    "papermill": {
     "duration": 0.014525,
     "end_time": "2025-03-04T01:33:45.739882",
     "exception": false,
     "start_time": "2025-03-04T01:33:45.725357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'tbi_status', 'arrhythmia', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'cmv_status', 'tce_imm_match', 'rituximab', 'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hepatic_severe', 'prior_tumor', 'peptic_ulcer', 'gvhd_proph', 'rheum_issue', 'sex_match', 'race_group', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'cardiac', 'pulm_moderate']\n"
     ]
    }
   ],
   "source": [
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eccb0cf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:45.753970Z",
     "iopub.status.busy": "2025-03-04T01:33:45.753622Z",
     "iopub.status.idle": "2025-03-04T01:33:45.837114Z",
     "shell.execute_reply": "2025-03-04T01:33:45.835464Z"
    },
    "id": "Tzn-8ixo-viD",
    "outputId": "c036923a-9ea8-406c-c286-15b7e38a6659",
    "papermill": {
     "duration": 0.092792,
     "end_time": "2025-03-04T01:33:45.839087",
     "exception": false,
     "start_time": "2025-03-04T01:33:45.746295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Data Type  Missing Values  Missing Percentage\n",
      "tce_match                 object           18996           65.958333\n",
      "mrd_hct                   object           16597           57.628472\n",
      "cyto_score_detail         object           11923           41.399306\n",
      "tce_div_match             object           11396           39.569444\n",
      "tce_imm_match             object           11133           38.656250\n",
      "cyto_score                object            8068           28.013889\n",
      "hla_high_res_10          float64            7163           24.871528\n",
      "hla_high_res_8           float64            5829           20.239583\n",
      "hla_high_res_6           float64            5284           18.347222\n",
      "hla_match_dqb1_high      float64            5199           18.052083\n",
      "hla_low_res_10           float64            5064           17.583333\n",
      "conditioning_intensity    object            4789           16.628472\n",
      "hla_match_c_high         float64            4620           16.041667\n",
      "hla_match_a_high         float64            4301           14.934028\n",
      "hla_nmdp_6               float64            4197           14.572917\n",
      "hla_match_dqb1_low       float64            4194           14.562500\n",
      "hla_match_b_high         float64            4088           14.194444\n",
      "hla_low_res_8            float64            3653           12.684028\n",
      "hla_match_drb1_high      float64            3352           11.638889\n",
      "hla_low_res_6            float64            3270           11.354167\n",
      "hla_match_c_low          float64            2800            9.722222\n",
      "hla_match_drb1_low       float64            2643            9.177083\n",
      "hla_match_b_low          float64            2565            8.906250\n",
      "cardiac                   object            2542            8.826389\n",
      "peptic_ulcer              object            2419            8.399306\n",
      "hla_match_a_low          float64            2390            8.298611\n",
      "arrhythmia                object            2202            7.645833\n",
      "rheum_issue               object            2183            7.579861\n",
      "rituximab                 object            2148            7.458333\n",
      "pulm_severe               object            2135            7.413194\n",
      "diabetes                  object            2119            7.357639\n",
      "psych_disturb             object            2062            7.159722\n",
      "pulm_moderate             object            2047            7.107639\n",
      "hepatic_mild              object            1917            6.656250\n",
      "renal_issue               object            1915            6.649306\n",
      "hepatic_severe            object            1871            6.496528\n",
      "donor_age                float64            1808            6.277778\n",
      "obesity                   object            1760            6.111111\n",
      "prior_tumor               object            1678            5.826389\n",
      "melphalan_dose            object            1405            4.878472\n",
      "karnofsky_score          float64             870            3.020833\n",
      "cmv_status                object             634            2.201389\n",
      "ethnicity                 object             587            2.038194\n",
      "comorbidity_score        float64             477            1.656250\n",
      "sex_match                 object             261            0.906250\n",
      "vent_hist                 object             259            0.899306\n",
      "in_vivo_tcd               object             225            0.781250\n",
      "gvhd_proph                object             225            0.781250\n",
      "donor_related             object             158            0.548611\n",
      "dri_score                 object             154            0.534722\n",
      "efs                      float64               0            0.000000\n",
      "ID                         int64               0            0.000000\n",
      "race_group                object               0            0.000000\n",
      "age_at_hct               float64               0            0.000000\n",
      "year_hct                   int64               0            0.000000\n",
      "prod_type                 object               0            0.000000\n",
      "prim_disease_hct          object               0            0.000000\n",
      "graft_type                object               0            0.000000\n",
      "tbi_status                object               0            0.000000\n",
      "efs_time                 float64               0            0.000000\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "# Get data types of each column\n",
    "data_types = df.dtypes\n",
    "\n",
    "# Combine everything into a DataFrame\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Data Type': data_types,\n",
    "    'Missing Values': missing_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "\n",
    "# Display the result\n",
    "print(missing_summary.sort_values(by='Missing Percentage', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94b301bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:45.853499Z",
     "iopub.status.busy": "2025-03-04T01:33:45.853110Z",
     "iopub.status.idle": "2025-03-04T01:33:45.857969Z",
     "shell.execute_reply": "2025-03-04T01:33:45.856906Z"
    },
    "id": "4_B6vwXLCz4A",
    "papermill": {
     "duration": 0.014349,
     "end_time": "2025-03-04T01:33:45.859987",
     "exception": false,
     "start_time": "2025-03-04T01:33:45.845638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we drop 5 columns as they have more than 38% values missing\n",
    "#                        Data Type  Missing Values  Missing Percentage\n",
    "# tce_match                 object           18996           65.958333\n",
    "# mrd_hct                   object           16597           57.628472\n",
    "# cyto_score_detail         object           11923           41.399306\n",
    "# tce_div_match             object           11396           39.569444\n",
    "# tce_imm_match             object           11133           38.656250\n",
    "# Columns to remove\n",
    "cols_to_remove = ['tce_match', 'mrd_hct', 'cyto_score_detail', 'tce_div_match', 'tce_imm_match']\n",
    "\n",
    "# Remove specified columns from categorical_cols\n",
    "categorical_cols = [col for col in categorical_cols if col not in cols_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a06784e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:45.875195Z",
     "iopub.status.busy": "2025-03-04T01:33:45.874846Z",
     "iopub.status.idle": "2025-03-04T01:33:48.139243Z",
     "shell.execute_reply": "2025-03-04T01:33:48.138163Z"
    },
    "id": "bh0RryBG-wVs",
    "papermill": {
     "duration": 2.27438,
     "end_time": "2025-03-04T01:33:48.141154",
     "exception": false,
     "start_time": "2025-03-04T01:33:45.866774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "# encoded categorical cloumns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))  # Convert categories to numbers\n",
    "    label_encoders[col] = le  # Store encoder for inverse transformation later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85e7d981",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:48.155557Z",
     "iopub.status.busy": "2025-03-04T01:33:48.155022Z",
     "iopub.status.idle": "2025-03-04T01:33:48.169133Z",
     "shell.execute_reply": "2025-03-04T01:33:48.168199Z"
    },
    "id": "KTg_xYpQGfHZ",
    "papermill": {
     "duration": 0.023214,
     "end_time": "2025-03-04T01:33:48.170867",
     "exception": false,
     "start_time": "2025-03-04T01:33:48.147653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of numeric columns to convert\n",
    "numeric_to_categorical = ['donor_age', 'karnofsky_score', 'comorbidity_score']\n",
    "\n",
    "bins_dict = {\n",
    "    'donor_age': [0, 20, 40, 60, 80, 100],   # Custom bins for donor_age\n",
    "    'karnofsky_score': [0, 40, 60, 80, 100],  # Custom bins for karnofsky_score\n",
    "    'comorbidity_score': [0, 1, 2, 3, 4]      # Custom bins for comorbidity_score\n",
    "}\n",
    "\n",
    "# Convert each column to categorical using pd.cut\n",
    "for col in numeric_to_categorical:\n",
    "    df[col] = pd.cut(df[col], bins=bins_dict[col], labels=False, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ddbf8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:48.185540Z",
     "iopub.status.busy": "2025-03-04T01:33:48.185158Z",
     "iopub.status.idle": "2025-03-04T01:33:48.191183Z",
     "shell.execute_reply": "2025-03-04T01:33:48.189737Z"
    },
    "id": "KxOyWhXnHWkP",
    "outputId": "10456b9a-347b-45ab-8ae9-fa30b50cc95c",
    "papermill": {
     "duration": 0.015492,
     "end_time": "2025-03-04T01:33:48.192971",
     "exception": false,
     "start_time": "2025-03-04T01:33:48.177479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(df['donor_age'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "881d6a76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:48.207285Z",
     "iopub.status.busy": "2025-03-04T01:33:48.206959Z",
     "iopub.status.idle": "2025-03-04T01:33:48.252855Z",
     "shell.execute_reply": "2025-03-04T01:33:48.251760Z"
    },
    "id": "MIGxMCJXDB8u",
    "papermill": {
     "duration": 0.055282,
     "end_time": "2025-03-04T01:33:48.254818",
     "exception": false,
     "start_time": "2025-03-04T01:33:48.199536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# after calculating distribution we can make custom bins for each column\n",
    "hla_bins = {\n",
    "    'hla_match_c_high': [0.0, 1.0, 2.0],\n",
    "    'hla_high_res_8': [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0],\n",
    "    'hla_low_res_6': [2.0, 3.0, 4.0, 5.0, 6.0],\n",
    "    'hla_high_res_6': [0.0, 2.0, 3.0, 4.0, 5.0, 6.0],\n",
    "    'hla_high_res_10': [3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0],\n",
    "    'hla_match_dqb1_high': [0.0, 1.0, 2.0],\n",
    "    'hla_nmdp_6': [2.0, 3.0, 4.0, 5.0, 6.0],\n",
    "    'hla_match_c_low': [0.0, 1.0, 2.0],\n",
    "    'hla_match_drb1_low': [1.0, 2.0],\n",
    "    'hla_match_dqb1_low': [0.0, 1.0, 2.0],\n",
    "    'hla_match_a_high': [0.0, 1.0, 2.0],\n",
    "    'hla_match_b_low': [0.0, 1.0, 2.0],\n",
    "    'hla_match_a_low': [0.0, 1.0, 2.0],\n",
    "    'hla_match_b_high': [0.0, 1.0, 2.0],\n",
    "    'hla_low_res_8': [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0],\n",
    "    'hla_match_drb1_high': [0.0, 1.0, 2.0],\n",
    "    'hla_low_res_10': [4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "}\n",
    "# Apply binning using `pd.cut`\n",
    "for col, bins in hla_bins.items():\n",
    "    df[col] = pd.cut(df[col], bins=bins, labels=False, include_lowest=True)\n",
    "\n",
    "# Create binary indicators for missing hla_ variable values\n",
    "for col in hla_cols:\n",
    "    df[col + '_present'] = np.where(df[col].notna(), 1, 0)\n",
    "\n",
    "hla_present_cols = [col + '_present' for col in hla_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "197eaf45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:48.269134Z",
     "iopub.status.busy": "2025-03-04T01:33:48.268746Z",
     "iopub.status.idle": "2025-03-04T01:33:48.295324Z",
     "shell.execute_reply": "2025-03-04T01:33:48.294083Z"
    },
    "id": "8H2XlH5wLBpj",
    "papermill": {
     "duration": 0.036056,
     "end_time": "2025-03-04T01:33:48.297467",
     "exception": false,
     "start_time": "2025-03-04T01:33:48.261411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace NaN with -1 for numeric and hla columns\n",
    "df[numerical_cols + hla_cols] = df[numerical_cols + hla_cols].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b5a6560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:48.312001Z",
     "iopub.status.busy": "2025-03-04T01:33:48.311622Z",
     "iopub.status.idle": "2025-03-04T01:33:48.318802Z",
     "shell.execute_reply": "2025-03-04T01:33:48.317578Z"
    },
    "id": "8WgeyYBlrzBU",
    "outputId": "905d8a6c-4981-414e-d644-1915b6faa69c",
    "papermill": {
     "duration": 0.016236,
     "end_time": "2025-03-04T01:33:48.320385",
     "exception": false,
     "start_time": "2025-03-04T01:33:48.304149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       -1.0\n",
      "1        1.0\n",
      "2        1.0\n",
      "3        1.0\n",
      "4        1.0\n",
      "        ... \n",
      "28795    1.0\n",
      "28796    0.0\n",
      "28797    1.0\n",
      "28798    0.0\n",
      "28799    1.0\n",
      "Name: hla_match_c_high, Length: 28800, dtype: float64\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(df['hla_match_c_high'])\n",
    "print(df['hla_match_c_high'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39535d93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:48.335002Z",
     "iopub.status.busy": "2025-03-04T01:33:48.334649Z",
     "iopub.status.idle": "2025-03-04T01:33:48.410431Z",
     "shell.execute_reply": "2025-03-04T01:33:48.409196Z"
    },
    "id": "g7oJqWyCLNfh",
    "papermill": {
     "duration": 0.085285,
     "end_time": "2025-03-04T01:33:48.412443",
     "exception": false,
     "start_time": "2025-03-04T01:33:48.327158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating embeddings\n",
    "\n",
    "# Define Embedding Layers for Categorical Variables\n",
    "embedding_layers = nn.ModuleList([\n",
    "    nn.Embedding(len(le.classes_), min(50, (len(le.classes_) + 1) // 2))  # min(50, (len + 1) // 2) is an example\n",
    "    for le in label_encoders.values()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Define Embedding Layers for 'hla_' columns based on the length of bins\n",
    "hla_embedding_layers = nn.ModuleList([\n",
    "    nn.Embedding(int(df[col].max()) + 2, 3)  # Embedding size is 3; len(bins) is the number of unique bins for each column\n",
    "    for col in hla_cols # Create an embedding for each HLA column\n",
    "])\n",
    "\n",
    "# For hla_present columns, we will use binary embeddings (i.e., 0 or 1)\n",
    "# hla_present_embedding_layers = nn.ModuleList([\n",
    "#     nn.Embedding(2, 1)  # Binary embedding (0 or 1)\n",
    "#     for _ in hla_present_cols\n",
    "# ])\n",
    "\n",
    "# Define Embedding Layers for Numeric (Binned) Variables\n",
    "numeric_embedding_layers = nn.ModuleList([\n",
    "    nn.Embedding(int(df[col].max()) + 1, min(50, (df[col].nunique() + 1) // 2))  # Adjust embedding size\n",
    "    for col in numerical_cols\n",
    "])\n",
    "\n",
    "# Forward pass function (a simplified version)\n",
    "def forward(data1,data2,data4):\n",
    "    # Embed categorical columns\n",
    "    print(\"Entered categorical embedding\")\n",
    "    embedded_categoricals = [embedding_layers[i](data1[:, i]) for i in range(len(categorical_cols))]\n",
    "    # print(embedded_categoricals)\n",
    "    embedded_categoricals = torch.cat(embedded_categoricals, dim=1)\n",
    "    # print(embedded_categoricals)\n",
    "    # Embed hla_ columns\n",
    "    # data_hla = data[:, len(categorical_cols):len(categorical_cols) + len(hla_cols)]  # Slice data for hla_cols\n",
    "    data2+=1\n",
    "    # print(data_hla.shape)\n",
    "    print(\"Entered hla embedding\")\n",
    "    embedded_hla = [hla_embedding_layers[i](data2[:,i]) for i in range(len(hla_cols))]\n",
    "    print(\"done with hla_\")\n",
    "    embedded_hla = torch.cat(embedded_hla, dim=1)\n",
    "\n",
    "    # Embed hla_present columns\n",
    "    # print(\"Entered hla_presence embedding\")\n",
    "    # embedded_hla_present = [hla_present_embedding_layers[i](data3[:, i])\n",
    "    #                         for i in range(len(hla_present_cols))]\n",
    "    # embedded_hla_present = torch.cat(embedded_hla_present, dim=1)\n",
    "\n",
    "    # Embed numeric columns (binned)\n",
    "    print(\"Entered numeric embedding\")\n",
    "    embedded_numeric = [numeric_embedding_layers[i](data4[:,i].clamp(0, int(df[numerical_cols[i]].max())))\n",
    "                        for i in range(len(numerical_cols))]\n",
    "    embedded_numeric = torch.cat(embedded_numeric, dim=1)\n",
    "\n",
    "    # Concatenate all embeddings (categoricals, hla, hla_present, and numeric)\n",
    "    concatenated = torch.cat([embedded_categoricals, embedded_hla, embedded_numeric], dim=1)\n",
    "\n",
    "    return concatenated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7be043",
   "metadata": {
    "id": "sMP7yOO75yDY",
    "papermill": {
     "duration": 0.006331,
     "end_time": "2025-03-04T01:33:48.425433",
     "exception": false,
     "start_time": "2025-03-04T01:33:48.419102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "print(embedded_categoricals.shape)\n",
    "print(embedded_hla.shape)\n",
    "print(embedded_hla_present.shape)\n",
    "print(embedded_numeric.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dfe705b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:48.440113Z",
     "iopub.status.busy": "2025-03-04T01:33:48.439684Z",
     "iopub.status.idle": "2025-03-04T01:33:48.654531Z",
     "shell.execute_reply": "2025-03-04T01:33:48.653176Z"
    },
    "id": "8VcbaFPfPGOZ",
    "outputId": "c347bf7f-24dd-4ae6-f764-e0aabc1e6fa0",
    "papermill": {
     "duration": 0.224411,
     "end_time": "2025-03-04T01:33:48.656403",
     "exception": false,
     "start_time": "2025-03-04T01:33:48.431992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered categorical embedding\n",
      "Entered hla embedding\n",
      "done with hla_\n",
      "Entered numeric embedding\n",
      "torch.Size([28800, 202])\n"
     ]
    }
   ],
   "source": [
    "# Data must be properly encoded for categorical columns and numeric columns\n",
    "input_data = torch.tensor(df[categorical_cols + hla_cols+numerical_cols].values,dtype=torch.long)\n",
    "\n",
    "# Call the forward function\n",
    "embeddedTensor = forward(torch.tensor(df[categorical_cols].values,dtype=torch.long),torch.tensor(df[hla_cols].values,dtype=torch.long),\n",
    "                 torch.tensor(df[numerical_cols].values,dtype=torch.long))\n",
    "\n",
    "\n",
    "# Print the shape of the output embeddings\n",
    "print(embeddedTensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf356bf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:48.672775Z",
     "iopub.status.busy": "2025-03-04T01:33:48.672366Z",
     "iopub.status.idle": "2025-03-04T01:33:48.702948Z",
     "shell.execute_reply": "2025-03-04T01:33:48.701740Z"
    },
    "id": "VhNSMzxDKtDq",
    "outputId": "9eef620c-1288-4a9c-d6f9-d3c6c0b8144d",
    "papermill": {
     "duration": 0.041163,
     "end_time": "2025-03-04T01:33:48.705095",
     "exception": false,
     "start_time": "2025-03-04T01:33:48.663932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SurvivalNN(\n",
      "  (fc1): Linear(in_features=202, out_features=128, bias=True)\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc4): Linear(in_features=32, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the model\n",
    "class SurvivalNN(nn.Module):\n",
    "    def __init__(self, input_size=202, hidden_size=128, output_size=2, dropout_rate=0.3):\n",
    "        super(SurvivalNN, self).__init__()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # Input → Hidden\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)  # Normalize hidden layer\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)  # Hidden → Hidden\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, hidden_size // 4)  # Additional layer\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_size // 4)\n",
    "        self.fc4 = nn.Linear(hidden_size // 4, output_size)  # Hidden → Output\n",
    "        # Activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.fc1(x)))  # Apply FC + BN + ReLU\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn3(self.fc3(x)))  # Additional layer\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)  # Linear output for regression task\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = SurvivalNN()\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Example input for the model (size = [28800, 219] as per the embeddings)\n",
    "# dummy_input = torch.randn(28800, 219)\n",
    "\n",
    "# # Forward pass\n",
    "# output = model(dummy_input)\n",
    "\n",
    "# # Print output shape (For regression, output should be continuous)\n",
    "# print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81913829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:48.720799Z",
     "iopub.status.busy": "2025-03-04T01:33:48.720452Z",
     "iopub.status.idle": "2025-03-04T01:33:53.938628Z",
     "shell.execute_reply": "2025-03-04T01:33:53.937446Z"
    },
    "id": "Yiu0iMpNQ2pd",
    "papermill": {
     "duration": 5.228612,
     "end_time": "2025-03-04T01:33:53.940686",
     "exception": false,
     "start_time": "2025-03-04T01:33:48.712074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "\n",
    "criterion = nn.HuberLoss()\n",
    "# MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a376afd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:53.957384Z",
     "iopub.status.busy": "2025-03-04T01:33:53.956807Z",
     "iopub.status.idle": "2025-03-04T01:33:54.032357Z",
     "shell.execute_reply": "2025-03-04T01:33:54.031178Z"
    },
    "id": "LHj8G29lQ3E9",
    "outputId": "43f1ec17-a41f-44c4-c32b-373bdef0be99",
    "papermill": {
     "duration": 0.085594,
     "end_time": "2025-03-04T01:33:54.034377",
     "exception": false,
     "start_time": "2025-03-04T01:33:53.948783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-81ae61e71be0>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.embeddings = torch.tensor(embeddings, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "\n",
    "# Define custom dataset\n",
    "class SurvivalDataset(Dataset):\n",
    "    def __init__(self, embeddings, efs, efs_time):\n",
    "        self.embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "        # Normalize efs and efs_time\n",
    "        self.efs_mean, self.efs_std = efs.mean(), efs.std()\n",
    "        self.efs_time_mean, self.efs_time_std = efs_time.mean(), efs_time.std()\n",
    "\n",
    "        self.efs = torch.tensor((efs - self.efs_mean) / self.efs_std, dtype=torch.float32).unsqueeze(1)\n",
    "        self.efs_time = torch.tensor((efs_time - self.efs_time_mean) / self.efs_time_std, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.efs[idx], self.efs_time[idx]\n",
    "\n",
    "    def denormalize(self, efs, efs_time):\n",
    "        \"\"\"Denormalize predictions to original scale.\"\"\"\n",
    "        efs_original = efs * self.efs_std + self.efs_mean\n",
    "        efs_time_original = efs_time * self.efs_time_std + self.efs_time_mean\n",
    "        return efs_original, efs_time_original\n",
    "\n",
    "# Convert dataset to PyTorch tensors\n",
    "dataset = SurvivalDataset(embeddedTensor, df['efs'].values, df['efs_time'].values)\n",
    "\n",
    "\n",
    "# Split dataset into train and validation sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "val_size = len(dataset) - train_size  # 20% for validation\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# # Define DataLoaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3e72b20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:33:54.049210Z",
     "iopub.status.busy": "2025-03-04T01:33:54.048853Z",
     "iopub.status.idle": "2025-03-04T01:34:31.497038Z",
     "shell.execute_reply": "2025-03-04T01:34:31.495735Z"
    },
    "id": "QrOH4hvKRjA_",
    "outputId": "5f1f259f-6f58-456a-a512-4912709b9388",
    "papermill": {
     "duration": 37.457779,
     "end_time": "2025-03-04T01:34:31.499007",
     "exception": false,
     "start_time": "2025-03-04T01:33:54.041228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 0.8155, Val Loss: 0.3951\n",
      "Epoch [2/30], Train Loss: 0.7528, Val Loss: 0.3867\n",
      "Epoch [3/30], Train Loss: 0.7374, Val Loss: 0.3812\n",
      "Epoch [4/30], Train Loss: 0.7223, Val Loss: 0.3783\n",
      "Epoch [5/30], Train Loss: 0.7149, Val Loss: 0.3794\n",
      "Epoch [6/30], Train Loss: 0.7077, Val Loss: 0.3784\n",
      "Epoch [7/30], Train Loss: 0.6971, Val Loss: 0.3761\n",
      "Epoch [8/30], Train Loss: 0.6927, Val Loss: 0.3789\n",
      "Epoch [9/30], Train Loss: 0.6865, Val Loss: 0.3769\n",
      "Epoch [10/30], Train Loss: 0.6806, Val Loss: 0.3785\n",
      "Epoch [11/30], Train Loss: 0.6758, Val Loss: 0.3787\n",
      "Epoch [12/30], Train Loss: 0.6709, Val Loss: 0.3793\n",
      "Epoch [13/30], Train Loss: 0.6691, Val Loss: 0.3778\n",
      "Epoch [14/30], Train Loss: 0.6609, Val Loss: 0.3793\n",
      "Epoch [15/30], Train Loss: 0.6551, Val Loss: 0.3836\n",
      "Epoch [16/30], Train Loss: 0.6519, Val Loss: 0.3849\n",
      "Epoch [17/30], Train Loss: 0.6465, Val Loss: 0.3831\n",
      "Epoch [18/30], Train Loss: 0.6399, Val Loss: 0.3840\n",
      "Epoch [19/30], Train Loss: 0.6340, Val Loss: 0.3883\n",
      "Epoch [20/30], Train Loss: 0.6305, Val Loss: 0.3860\n",
      "Epoch [21/30], Train Loss: 0.6259, Val Loss: 0.3883\n",
      "Epoch [22/30], Train Loss: 0.6231, Val Loss: 0.3875\n",
      "Epoch [23/30], Train Loss: 0.6131, Val Loss: 0.3920\n",
      "Epoch [24/30], Train Loss: 0.6121, Val Loss: 0.3883\n",
      "Epoch [25/30], Train Loss: 0.6050, Val Loss: 0.3912\n",
      "Epoch [26/30], Train Loss: 0.6069, Val Loss: 0.3917\n",
      "Epoch [27/30], Train Loss: 0.6012, Val Loss: 0.3893\n",
      "Epoch [28/30], Train Loss: 0.5968, Val Loss: 0.3943\n",
      "Epoch [29/30], Train Loss: 0.5921, Val Loss: 0.3937\n",
      "Epoch [30/30], Train Loss: 0.5892, Val Loss: 0.3930\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        X_batch, efs_batch, efs_time_batch = batch  # Unpack batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        predicted_efs, predicted_efs_time = outputs[:, 0], outputs[:, 1]\n",
    "\n",
    "        loss_efs = criterion(predicted_efs,  efs_batch.squeeze())\n",
    "        loss_efs_time = criterion(predicted_efs_time, efs_time_batch.squeeze())\n",
    "        loss = loss_efs + loss_efs_time  # Combined loss\n",
    "        # print(\"Loss:\", loss.item())\n",
    "        # Backward pass and optimization\n",
    "\n",
    "        loss.backward()  # Compute gradients\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()  # Update parameters\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        # predicted_hazard = predicted_hazard.detach()\n",
    "\n",
    "     # Compute average train loss\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            X_batch, efs_batch, efs_time_batch = batch\n",
    "            outputs = model(X_batch)\n",
    "            predicted_efs, predicted_efs_time = outputs[:, 0], outputs[:, 1]\n",
    "\n",
    "            loss_efs = criterion(predicted_efs, efs_batch.squeeze())\n",
    "            loss_efs_time = criterion(predicted_efs_time, efs_time_batch.squeeze())\n",
    "            loss = 0.8 * loss_efs + 0.2 * loss_efs_time # Combined loss\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # Compute average validation loss\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Update scheduler\n",
    "    # scheduler.step(val_loss)\n",
    "\n",
    "\n",
    "    # if epoch % 5 == 0:  # Print every 5 epochs\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa0fe9",
   "metadata": {
    "id": "zHd3e4-Zlqzt",
    "papermill": {
     "duration": 0.008061,
     "end_time": "2025-03-04T01:34:31.515514",
     "exception": false,
     "start_time": "2025-03-04T01:34:31.507453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce4a418b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:34:31.533659Z",
     "iopub.status.busy": "2025-03-04T01:34:31.533202Z",
     "iopub.status.idle": "2025-03-04T01:34:31.540049Z",
     "shell.execute_reply": "2025-03-04T01:34:31.538885Z"
    },
    "id": "U28khrn5iHJk",
    "papermill": {
     "duration": 0.017883,
     "end_time": "2025-03-04T01:34:31.541839",
     "exception": false,
     "start_time": "2025-03-04T01:34:31.523956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_test_data(df, categorical_cols, numeric_to_categorical, bins_dict, hla_bins, numerical_cols, hla_cols, hla_present_cols):\n",
    "    \"\"\"\n",
    "    Preprocess the test data:\n",
    "    1. Encode categorical columns.\n",
    "    2. Convert numeric columns to categorical using binning.\n",
    "    3. Apply binning for HLA columns.\n",
    "    4. Replace NaN values with -1.\n",
    "    \"\"\"\n",
    "    # Encode categorical columns\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))  # Convert categories to numbers\n",
    "        label_encoders[col] = le  # Store encoder for inverse transformation later\n",
    "\n",
    "    # Convert numeric columns to categorical using pd.cut\n",
    "    for col in numeric_to_categorical:\n",
    "        df[col] = pd.cut(df[col], bins=bins_dict[col], labels=False, include_lowest=True)\n",
    "\n",
    "    # Apply binning for HLA columns\n",
    "    for col, bins in hla_bins.items():\n",
    "        df[col] = pd.cut(df[col], bins=bins, labels=False, include_lowest=True)\n",
    "\n",
    "    # Replace NaN with -1 for numeric and HLA columns\n",
    "    df[numerical_cols + hla_cols] = df[numerical_cols + hla_cols].fillna(-1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d762f145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:34:31.560103Z",
     "iopub.status.busy": "2025-03-04T01:34:31.559750Z",
     "iopub.status.idle": "2025-03-04T01:34:31.565423Z",
     "shell.execute_reply": "2025-03-04T01:34:31.564019Z"
    },
    "id": "c7IgbWHNh-zl",
    "papermill": {
     "duration": 0.01701,
     "end_time": "2025-03-04T01:34:31.567397",
     "exception": false,
     "start_time": "2025-03-04T01:34:31.550387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define custom dataset for test set\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, embeddings):\n",
    "        self.embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27d026f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:34:31.585176Z",
     "iopub.status.busy": "2025-03-04T01:34:31.584839Z",
     "iopub.status.idle": "2025-03-04T01:34:31.635609Z",
     "shell.execute_reply": "2025-03-04T01:34:31.634226Z"
    },
    "id": "nymOs6uMkOzc",
    "outputId": "7887779d-d9ed-4294-be9d-9206ac092226",
    "papermill": {
     "duration": 0.061875,
     "end_time": "2025-03-04T01:34:31.637615",
     "exception": false,
     "start_time": "2025-03-04T01:34:31.575740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered categorical embedding\n",
      "Entered hla embedding\n",
      "done with hla_\n",
      "Entered numeric embedding\n",
      "Embedded Test Tensor Shape: torch.Size([3, 202])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-6a380e6e17d9>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.embeddings = torch.tensor(embeddings, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n",
    "\n",
    "# Preprocess test data\n",
    "test_df = preprocess_test_data(test_df, categorical_cols, numeric_to_categorical, bins_dict, hla_bins, numerical_cols, hla_cols, hla_present_cols)\n",
    "\n",
    "# Generate embeddings using the forward function\n",
    "embeddedTestTensor = forward(\n",
    "    torch.tensor(test_df[categorical_cols].values, dtype=torch.long),\n",
    "    torch.tensor(test_df[hla_cols].values, dtype=torch.long),\n",
    "    torch.tensor(test_df[numerical_cols].values, dtype=torch.long)\n",
    ")\n",
    "\n",
    "print(\"Embedded Test Tensor Shape:\", embeddedTestTensor.shape)\n",
    "# Create a dataset for the test set\n",
    "test_dataset = TestDataset(embeddedTestTensor)\n",
    "\n",
    "# Create a DataLoader for the test set\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9151caed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T01:34:31.656175Z",
     "iopub.status.busy": "2025-03-04T01:34:31.655811Z",
     "iopub.status.idle": "2025-03-04T01:34:31.701373Z",
     "shell.execute_reply": "2025-03-04T01:34:31.699819Z"
    },
    "id": "GHK9j8IBkYgU",
    "outputId": "2cfb0e50-64f7-4709-a1fc-d12fb7a5a9f0",
    "papermill": {
     "duration": 0.057484,
     "end_time": "2025-03-04T01:34:31.703565",
     "exception": false,
     "start_time": "2025-03-04T01:34:31.646081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted efs: tensor([ 0.5703,  0.2841, -0.8277])\n",
      "Denormalized Predicted efs_time: tensor([-0.4305,  0.0663, -0.1497])\n",
      "Risk Scores: [0.07961421 0.0401891  0.05121618]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predicted_efs = []\n",
    "predicted_efs_times = []\n",
    "\n",
    "efs_mean, efs_std = df['efs'].mean(), df['efs'].std()\n",
    "efs_time_mean, efs_time_std = df['efs_time'].mean(), df['efs_time'].std()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        outputs = model(batch)\n",
    "        predicted_efs, predicted_efs_time = outputs[:, 0], outputs[:, 1]\n",
    "        # predicted_efs.extend(predicted_efs.cpu().numpy())\n",
    "        predicted_efs_times.extend(predicted_efs_time.cpu().numpy())\n",
    "\n",
    "print(\"Predicted efs:\", predicted_efs)\n",
    "# print(\"Predicted efs_time:\", predicted_efs_times\n",
    "# Convert predictions to a numpy array\n",
    "# predicted_efs = np.array(predicted_efs)\n",
    "predicted_efs_times = np.array(predicted_efs_times)\n",
    "\n",
    "# Denormalize it\n",
    "predicted_efs_times = predicted_efs_times* efs_time_std + efs_time_mean\n",
    "# predicted_efs = predicted_efs * efs_std + efs_mean\n",
    "# print(\"Denormalized Predicted efs:\", predicted_efs)\n",
    "print(\"Denormalized Predicted efs_time:\", predicted_efs_time)\n",
    "\n",
    "# Calculate risk scores (inverse of predicted efs_time)\n",
    "risk_scores = 1 / predicted_efs_times\n",
    "\n",
    "# Print risk scores\n",
    "print(\"Risk Scores:\", risk_scores)\n",
    "\n",
    "submission_df = pd.DataFrame({'ID': test_df['ID'].astype(int), 'prediction': risk_scores})\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "# If you have true efs_time values for evaluation (e.g., in a validation set), calculate C-index\n",
    "# from lifelines.utils import concordance_index\n",
    "\n",
    "# # Example true efs_time values (replace with actual values if available)\n",
    "# true_efs_times = np.random.rand(len(predicted_efs_times))  # Replace with actual values\n",
    "\n",
    "# # Calculate C-index\n",
    "# c_index = concordance_index(true_efs_times, -predicted_efs_times)  # Negative for correct ranking\n",
    "# print(f\"Concordance Index (C-index): {c_index:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42800291",
   "metadata": {
    "id": "jBJeIZ9qlOGS",
    "papermill": {
     "duration": 0.00835,
     "end_time": "2025-03-04T01:34:31.720779",
     "exception": false,
     "start_time": "2025-03-04T01:34:31.712429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10381525,
     "sourceId": 70942,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 59.695448,
   "end_time": "2025-03-04T01:34:34.208682",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-04T01:33:34.513234",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
