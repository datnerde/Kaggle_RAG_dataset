{"cells":[
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\ntrain = pd.read_csv('../input/train.csv', header = 0)\ntrain.info()\ntest = pd.read_csv('../input/test.csv', header = 0)\ntest.info()\n\ndef data_cleaning (df):\n    # create a new column as \"Gender\" and replace 'female' and 'male' as 0 and\n    # 1, respectively\n    df['Gender'] = df['Sex'].map({'female' : 0, 'male' : 1}).astype(int)\n\n    # do the same to \"Embarked\"\n    # df['Boarding'] = df['Embarked'].map({'S' : 0, 'C' : 1, 'Q' :\n    # 2}).astype(int)\n\n    # df.apply(lambda x : sum(x.isnull()), axis = 0)\n\n    # use the pivot table to calculate the median of 'Age' based on 'Gender'\n    # and 'Pclass', learned this trick from\n    # http://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/\n    pv_table = df.pivot_table (values='Age', index='Gender', \\\n            columns='Pclass', aggfunc=np.median)\n\n    # make a copy of 'Age'\n    df['AgeFill'] = df['Age']\n\n    # OMG I hate this freaking long line\n    df['AgeFill'].fillna(df[df['AgeFill'].isnull()].apply(lambda x :\n        pv_table.loc[x['Gender'], x['Pclass']], axis=1), inplace=True)\n\n    # create a feature of recording that the 'Age' was originally missing\n    df['AgeIsNull'] = pd.isnull(df.Age).astype(int)\n\n    # Combining 'SibSp' and 'Parch'\n    df['FamilySize'] = df['SibSp'] + df['Parch']\n\n    # Artificial feature of 'Age * Pclass'\n    df['Age*Class'] = df.AgeFill * df.Pclass\n\n    # This shows which ones are 'objects' that we will drop\n    df.dtypes[df.dtypes.map(lambda x: x=='object')]\n    df = df.drop(['Name', 'Sex','Ticket', 'Cabin', 'Embarked', 'Age'], \\\n            axis=1)\n    return df\n\ntrain = data_cleaning(train).drop(['PassengerId'], axis=1)\ntrain_data = train.values\n# train.info()\n\ntest_copy = data_cleaning(test.copy()).drop(['PassengerId'], axis=1)\ntest_copy['Fare'].fillna(test_copy['Fare'].median(), inplace=True)\ntest_data = test_copy.values\n# test.info()\n\n\n# Import the random forest package\nfrom sklearn.ensemble import RandomForestClassifier\n\nforest = RandomForestClassifier(max_depth = 10, min_samples_split=2, n_estimators = 100)\n\nforest = forest.fit(train_data[0::, 1::], train_data[0::, 0])\n\noutput = forest.predict(test_data)\nprint(train_data[0::, 1::])\nprint (forest.score(train_data[0::, 1::], train_data[0::,0]))\n\n# make a data frame for saving as csv file\nPassengerId = np.array(test['PassengerId']).astype(int)\nmy_solution = pd.DataFrame(output, PassengerId, columns = [\"Survived\"])\n\nmy_solution.to_csv(\"my_solution.csv\", index_label = [\"PassengerId\"])\n# Any results you write to the current directory are saved as output.\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": " "
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": ""
 }
],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}, "nbformat": 4, "nbformat_minor": 0}